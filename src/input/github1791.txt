did you get a chance to follow up on the issue? If not, I can take a look in the next 24hrs.
Thank you for this PR.  This is an interesting idea, but unfortunately I don't think the additional API is worthwhile to include. This is because of a few reasons:   *  is intended as a wholesale measure to prevent accidental JIT usage of anything.  OTOHrequireExplicitBindings(Class...)bind(ThatClass.class)binder.restrictBindingSource(RestrictionInfo, ClassOrAnnotation...)`, or something similar to that, which could potentially prevent usage + other bindings. This may not make sense, though, because folks could just bind the types by removing that module altogether.   * Overall, this feels like something that's better suited to a test: use the Guice SPI to iterate over what's injected and confirm that no "bad" types are used.
, oh sorry for this,  my fault, i'll be more careful 
I've added  so that we can add documentation regarding this as part of merging the PR.
Applications can still use  or qualifiers to get a specific bean, even if primary is being used. I'm sorry but we need to decline this change as removing this now would break existing applications relying on this behavior.
Sorry, I didn't realize it wasn't you.  I addressed your comments, could you have another look, please?
I think so too. Since this is the first time I look at Dagger 2 and this example gave me confusion.
What are your plans for Zabbix support? If things are uncertain I would prefer to close this one as it's unactionable at the moment.
OMG‚ùóÔ∏è‚ùóÔ∏è Thanks for merge.
I dont think that this would be a problem. The method/s is/are very straight-forward and the use-cases would outweight the "confusion". For me this was an instant issue when first looking at the implementation. This isn't code that every user should have to write. There also exists another unfinished pull request that lets JsonArray implement the List interface. (Which I'm also strongly in favour of.) In newer versions of Java this could also be done with a pattern switch-statement, but for me it was important to use the fastest implementation for java 1.5. Fair point.
, thinking out loud I'm not sure whether a subclass would be a good way to go or not, but happy to discuss further. Thanks!
Thanks for another contribution  !! This has now been merged to master. I've add a polish commit that makes some of the new classes package private just to reduce the surface area of the public API.
Still open üòÖ 
Lol  Same here, already completed a full JPMS xD Migrated the Microsoft SQL Server driver to JPMS, shit you not 40 minutes approved and merged. It's like opposite world, since when does google not give a shit xD
Thanks for the proposal. Unfortunately, ignoring the exception isn't the right thing to do. The intention is that a restart that fails due to an application context refresh failure will be retried once the user has made a change to the application. This retry is triggered by . If the  is ignored entirely, an application using Devtools won't recover from a restart failure caused by an application context refresh failure and the JVM will exit instead.
Bulk closing all pull requests that are listed as needing CLA signing. If you'd like us to look at your pull request, you'll need to sign the CLA and report back here. If this is a false positive, I apologize. Please reopen the pull request, and we'll have a look.
Yes, though because of the switch to a dimensional system, the format necessarily changed. There are some inadequacies in the /metrics endpoint that shipped with Boot 2 M4 that will be addressed in the M5 release (micrometer 1.0.0-rc.2) next week. See .
Thanks , Your contribution is now merged in  with a polish commit.
I don't know enough about . Can you comment on this suggested change?
Quick check using python awscli
I ended up tweaking your PR..  sending for review internally, will show up externally soon.  Thanks!
Thanks for the PR!  In preparation for merging, would you please update your commit message to include the issue that you fixed as well? Something like:
Sorry, duplicate to #903 ! 
Thanks . I left one more comment and after that we are ready to merge. But before we merge, can you please squash the commits to 1 and ensure the commit message follows this format. Thanks for your work on this!
I did polish it a bit more, thanks Eddu!
Oops, sorry, I didn't realise that one of my examples above prints the wrong value! Here's my updated code snippet:
My bad. When using the dirties context approach a new  is created, which is what I meant with context. Would it make sense to create an  with a separate namespace (like the  which could be preconfigured to use a different default for the ? and maybe some other defaults to optimize an ElasticSearch instance for testing? maybe with reusing parts of the current ?
The fix is done
I'm sorry! I don't see any of your comments. Can you please check it?
Created a separate PR with README only changes - 
We do run a lot of jvms that frequently exceed a threshold of 95% used mem and everything is fine since the GC kicks in and frees some of the heap. So I'd guess this health indicator would often raise an (false) alarm... Are you using this indicator already in a production environment? Can you share some experience?
Thanks, ! 
Thanks!
The change LGTM. As for the removals, I know  had plans for addressing some of these, but I can't find the doc (if there was one) and he's currently out on leave.
Thanks , I've backported the suggestion to Maven in  and added the exclusion to .
Thanks for the PR. This change is now in 1.2.x and master.
We avoid the problem for the Dependency Management plugin by making the Spring Boot plugin pull it in transitively. That lets us control the version of the Dependency Management plugin and allows a user to just apply the plugin without worrying about its version. We could do the same for the Kotlin plugin, but then everyone building a Gradle project would download the Kotlin plugin even if they weren't using it. That's similar to what we did for Jackson's Kotlin module so we could decide that it's a reasonable thing to do, probably depending on the weight of the Kotlin plugin and its dependencies.
Thanks for your feedback and changes,  I checked  and unfortunately, those changes are not enough to avoid reflection at all.  Could you please add the following changes?  must be public as well. Add reset method to , similar to verify but for reset.  'reset'  just clears and sets  to null. Ideally,  this class should be removed. Thanks in advance
docs/docs/how-tos/redis.md is probably the best place, IMO.
till now you still working on 1.5.x release train Kindly any dates when release 1.6.0 containing this PR will be released ?
I didnt know you trying to use "documents" to protect you from the world. I would'nt pull again. Anyway you can't protect yourself using this technique sign - and enter. I can prove I made this code having it before the code come to the repository, and since it get there without my sign it be equals staling code. So, sign or no sign - always possible to make you/google guilty and violating copyright slavery... Just make it simple, opensource and fun. BTW i'm not going to sue anyway. Just show you how stupid "CLA" is.
Sorry for the delay on this  .  I'm still trying to figure out how much value this adds if  doesn't contain the equivalent functionality. My understanding of this feature is that it will take a user-provided Single/Completable and convert that into a . I'm writing a unit test to check that submitting a  even works in vanilla Hystrix
Hi!  Yes, so sorry.  I've been rather unwell this last 2 months or so (almost co-inciding with my renewed interest in opensource... hmmmm) but I'm sort of alive again.  I'll try to get to this over the weekend.  Sorry again for just vanishing!
The idea to provide a way to retrieve the total size for downloading before actually starting the download makes sense, but I'm a bit wary that calculating it here using the available information may be wrong or misleading. This is because the selected tracks don't necessarily correspond to downloadable data streams. This mapping happens when we call  to identify the streams that we need to load. These streams and the manifest and potential extra data loads to obtain initilization data (e.g. for the DASH segment index) can then be used to calculate a total download size. This functionality is already part of the  implementations (specifically ) and it also takes into account that some of the media chunks have already been downloaded. A down-side of the existing implementation is that it doesn't do any estimation if the actual stream length is unknown (for example for text) and it requires extra data loads. That means we should probably still provide a way to get an estimated download size in  even if it may not be 100% correct. To keep it simple, it may be better to keep out hard-coded estimates, for example for text tracks as they are likely to be only a small part of the downloaded data anyway.
That should be the contract so the current behavior (no null-check) of the  is intentional. If the span is not sampled, there is no reason to include it in the Exemplar because won't be in the span store. Also,  is a newer addition; before that, we needed to do the same checks in the getters (hence the NPE above). I think it is fine doing the checks since: 1. We can't stop anyone calling it 2. Older versions of the client don't have  so they call the getters I can also file a PR in Prometheus Client and call this out in the javadocs so that it will be explicit.
Thanks,  I spent a lot of time to find a way to rework this to use ,  and telling the truth I don't know how it can be done at the moment.  does not include  dependencies. Here is a small background why excluding is not working for WAR. :   a source  has already had  folder which has been added by  before. filters all dependencies using the filters. (such as , ) creates  which includes only filtered libraries.  then,  tries to repackage the  using the given libraries and other parameters: :  Source  has already had  folder with dependencies, as  includes all  dependencies and put them beneath  folder. adds all jar entries from  into the . (including ) Write libraries  So, summarizing the above I can not understand how  can help here.  In my opinion,  should avoid any libraries, because for this purpose  is responsible. Currently, there is no way to exclude/filter jar entries during the  process.
Thanks very much, .
I'll most likely close this PR due to my poor design and my wrong assumptions. Once I patched the collection type adapter factory for , I realized that now it can be serialized, but cannot be deserialized without a custom deserializer: there is no way to add elements to the iterable that is not a collection. In the force-pushed commit, there is a test that serializes `Chars implements Iterable<Character I believe this is the biggest "why" why Gson does not support it out of box due to the symmetry issues and I feel ashamed to be blind not seeing it earlier.
Relates to  
Can you please give a short update when do you think the next Guice release will be cut? Are there any plans?
It's on the backlog which means we'd like to include it in the next release but I'm afraid I can't give you an estimate for when it might be reviewed.
Most welcome, now we have to wait until the PR will be merged
Ok  , please take over if time is short. Let me know if it is not clear what I meant to improve/fix, which by the way is a minor problem, type safety is only at risk if the source code is modified, not during regular use.
I have updated PR. But still I am no sure about that link to Spring Boot documentation. Should I remove that link to SNAPSHOT?
Looks good to me. Thanks.
Sorry for the trouble that this caused you. This is indeed intentional. The best documentation I know of at the moment is Error Prone's. We do want to extend Error Prone to catch bugs not just with the use of JDK collections but also with , but we haven't gotten there yet. Our hope is to do so by introducing some kind of  annotation. If we do that, then IntelliJ could read the annotation and provide the same warning. (Or they could just special-case  today.)
No, I don't think so. The install command is implemented as a  under the covers so it should be using the exact same logic. What makes you think that install may be ignoring ?
Merged commit 94dd510
I don't suppose you happen to know a way to make the CLA bot work with "Keep my email addresses private" ?  We've signed the Corp CLA, and I'm covered by it, but it looks like you might have to commit on the exact, public email you're listed on the CLA with, which would be annoying.  Let me know. Thanks!
Sorry, test case was mistaken.
We'll do our best.  /   any concerns about this PR since you've both touched that code in the past?
Unclear whether we both commented on this at the same time, or if you just replied really fast :). See inline comment I just posted in any case; I think it's probably the simplest thing to be going on with.
Thanks for the PR. I am not sure that we can safely mark  as incremental. The Gradle documentation says the following: The  API is used to determine the default values of a configuration property field for inclusion in the generated metadata. While we use reflection, I expect the wrapping that's done by Gradle to stop this from working. Have you tried your proposed changes with Gradle 5.4 and verified that the annotation processor works correctly?
FYI I'm leaving for vacation on Wednesday. Back July 5. Sorry that I can't comment while I'm away.
I am not a Googler, but I can't see this PR being merged. You've reformatted the entire source code, so there is no way to tell what was actually changed. In general, pull requests should touch as little surrounding code as possible.  Because of all this reformatting, the diff is useless. I cannot check if the removed deprecated methods are actually allowed to be removed. According to the guava philosophy, deprecated api will not be removed anymore unless it is marked as beta:
: Changes looks good to me.
I agree with you on this wholeheartedly except the very end: no matter what you do, software is insanely complex and we are all humans, we all make mistakes, you can't really avoid it (sometimes software and also hardware make mistakes too). This is why we have logs, metrics, distributed tracing, this is why write tests, and also this is why we have Spring Boot Actuator. You can call it information leakage but I would call it "observability" instead. Again, I agree on disabling this by default but I disagree on not having it at all.
Thanks for your first contribution -to-you !
The 5% is more of a straw man than anything I'm wedded to, but it's also important to note that it's calculated against the hard maximum memory limits rather than the committed memory.  This requirement is driven by usage that we're seeing on Cloud Foundry where very few JVMs run within 5% of their maximum.  It's very common for these applications to bump up against their committed limits and either  themselves back down or increase the committed limit to approach the maximum, neither of which would trigger a  status.  In cases where applications would trigger  for this , we've seen that the applications are typically very close to going OOM on the next surge in request load anyway. That being said, we are aware of users who run close to the maximum memory limits (within the 5% default) just in the same way we are aware of users who run close to the maximum disk space limits (within the 10MB default).  For these users, configuration and disabling is available just as it is for the .
The APR lifecycle listener does NOT use the APR library directly to accelerate TLS. You need the Tomcat Native library (which depends on APR and OpenSSL) to do that. The APR lifecycle listener only looks for the Tomcat Native library. Also, there are NO benefits w.r.t threading. The Tomcat Native connector enables two features: - the APR/native connector - the ability to use OpenSSL with the NIO and NIO2 connectors In Tomcat 9 and 8.5 you need the Tomcat Native library to use HTTP/2 if you are running on Java 8 or earlier. In Tomcat 9 (and soon in Tomcat 8.5) on Java 9 or later, HTTP/2 is supported without the Tomcat Native Library. If you are using TLS, the Tomcat Native library generally offers performance improvements compared to JSSE (either via the APR/Native connector or with NIO[2] with OpenSSL). However those performance differences vary with configuration and exact Java version so it is worth testing to see what the benefit is for any given scenario. Generally, I would recommend using the Tomcat Native library if you need to support TLS. In terms of APR/native vs NIO+OpenSSL, the Tomcat community is leaning towards NIO+OpenSSL with the possibility that the APR/native connector will be removed in Tomcat 10.
I see. On line 158 it adds it back again, but it's absent for the whole period of loading config files. Has to be a bug.
Hi , thanks for the PR. Unfortunately we reject use of Stream and Optional in the code, see reasons in 
Thanks for the PR!
Uh... weird.  The spreadsheet is at ... not sure why the link ?changed? or what happened.  Does that look worth linking to? On Sun, Apr 23, 2017 at 12:14 PM, Eric Edens <wrote: --  Kevin Bourrillion | Java Librarian | Google, Inc. | 
Hmm, ok that is unfortunate. I have split  support into a separate pull request (#2071). If you want you can close this pull request here then, if you don't think there is any chance this will be integrated.
Not a problem at all - you were not a hindrance. Git is very powerful but it could take some time to get used to. Hopefully you learned something new and the next time will be easier :) Thanks again for your contribution! This is now in master.
It is generated from the code, the current description is "Initialize the datasource with available DDL and DML scripts." I agree that this can be improved and we can do that as part of a separate issue. Type of datasource can be misleading IMO.
Man.  What the hell is going on on Travis?  I've re-started the job a couple of times.  Do you want to maybe rebase -i and force a new commit ref no, and push -f to force travis to try again?  I don't know if it's this branch or environmental...
LGTM, though I'm quite surprised that you're adding such a bogus type. Also, please squash.
We may need to do this internally, as we're not turning on deprecation on dagger1 internally, since it slows down the builds of really large projects (seriously - the extra i/o is a problem). So we have to do some fancy magic with MOE to do things differently between the two repos.  Let me consult a bit though.  We might yet use this pull. 
Thanks, ! This has been merged into  in a5351f3d890b888857bb60171a9846c331a6aabe. I standardized the commit format and then also merge it into .
For tracking purposes the link to the JIRA is 
This is the branch to reproduce #8674, not an pull request intended for merging. As such closing it to avoid confusion. I believe the branch can still be checkout if the pull request is closed.
Kinda forgot about this. I'll try making the requested fixes asap and resubmit for review.
I've updated this PR. Please take a look :) Thanks in advance.
 fix is PR 1508. I looked at it again after I wrote that and saw it wasn't a problem then started reading more and got a headache. Then I decided I didn't hate myself enough so I looked into TrueHD passthrough again and got annoyed again. ;) 
Yup, sorry. We're having issues with it at the moment.
I'll have a look tomorrow if I can make this nasty time shifting work reliable. Speaking of timezones .. it is already tomorrow over here ...
Thanks again Christoph!
Thanks for the PR !
Thanks
-nflx or  : Can you please merge this PR?
I have just delivered the requested changes, sorry for the delay. Does it look ok now?
Thanks for you answer, but in my mind  method just remove client information, but not update those two numbers Immediately. Update is on the background task. Why not update immediately when  method remove client information.
as I said - it uses deprecated method which will be removed in the coming major release of SnakeYAML. This project stops to compile. This will simplify the migration
I'm very sorry I missed that. :(
Thanks again !
-issuemaster This is an obvious fix.
idk if anyone would be interested, but I spent a few hours: * updating  from c516740 to 6aa35aa (tag )   - determining which handful of files to not update     * ie: which handful of methods to not remove * updating , ,  to accommodate for changes in    - note:  should be (but wasn't) fully updated from c516740 to 6aa35aa * updating my app to accommodate for the changes I made to the  API   - ie: pass instance of  to factory links: * release notes * commits in branch    - all updates after  ..,completing at  * my notes on the update process * patch file that shows all changes to  to go from 6aa35aa to its state after my updates comments: * this was a relatively quick and dirty endeavor   - with a little more work.. the differences in  between  and  could be farther reduced
going to merge this and address the comments in a separate PR.
In a nutshell, CLI uses annotations, fields etc to derive starters. Start.spring.io needs to take a list of starters and look up annotations etc. Having that info in one place sounds useful, consistent, and accurate. 
Are we opensearch users expected to keep using opensearch.RestHighLevelClient after 2.7.0?
FWIW, I don't see a specific problem with . It's only called from the constructor so from the caller's perspective the value of  can't change.
thank you for making your first contribution to Spring Boot. Agreed on that ssl flag, I've tried a few options and this one is the least bad option. I've moved its processing in a different place though, making  a .
Thanks for the feedback, ! The goal was to make a simpler API for customizing the request handling. The alternative we discussed would be to add a post-processor inside the . After experimenting with this a bit, I felt that I could simplify the API and wanted to give it a try and get some feedback. With the change in this PR, support for breach fits back into the paradigm of a separate implementation of . It is given the , which it can modify, and then pass to the delegate (or super) implementation from this PR. If we go this route, I won't need to make very many changes to the branch from the draft PR.
Assuming this was opened by error.
I was thinking of fetching the data by chunks instead of having one large buffer. But the parameter is a good idea. I'll do that instead.
I prefer the logging I think.
it looks like you've done a weird rebase of your branch. Can you squash your commits in a single one and push force in your branch? There are a lot of unrelated changes in your branch now. Thanks.
Just a friendly bump because I want to know if anyone has seen this PR.
Thanks for catching this, . And for such a thorough PR. The proposed changes look good to me.  can you cast an eye over them before we merge please?
Thanks for this one, it must have taken a while! I've merged to master but rolled back a couple where I though that the for loops were easier to read.
Thanks for explaining. While a seekbar + current position and duration, like commonly used for VOD, is like you say not suited for live streams, a different style of seekbar can be a good solution for live streams. One use case is live TV, for channels with programs starting at specific times.  There are, I believe, two main ways of doing a live seekbar. In both cases the duration is not displayed, only the position. The position label can either be the offset from the live edge position, for example "-31:05", or (preferably) it can be the wall clock time associated with that position in the stream, for example "11:37:45". The wall clock time value can be calculated from the HLS' tag PROGRAM-DATE-TIME. If that tag is missing, an approximation can be made based on the time on the device when the live playlist was downloaded. This way, the seekbar can be used to, for example, find position "11:30", when a certain TV program starts.  I suggest this behavior for ExoPlayer HLS-live: to include a working seekbar, and to display "Live" in the duration label and the wall clock time, like described above, in the position label. The wall clock time associated with the current position can be calculated by determining the wall clock time when the stream starts (start of first chunk), and adding the elapsed time since the start. 
Thanks for the contribution. I'm merging, but feel free to get rid of ack altogether in any of the future changes, if possible. It is not a deal breaker for now.
Thanks for the PR! To be honest I am not sure I like that change. That would make the code quite complicated for one environment that does not support something who's a commodity in other environments. I've flagged it so that we discuss it at our next team meeting. 
Thanks Tavian!
This is a very, very old merge request. I don't see any chance this will be merged anytime, to be honest :-(
Have you signed the CLA?
Thanks for reporting this -lee. Can you please write a test and than I'll merge this.
No need to worry about the branch. We can cherry-pick the change back if needed and then merge it forwards.
I've rebased against master, merged Dave's latest batch of edits, resolved the conflicts, and fixed one lingering test case.
Merged into master. Thanks for the PR, 
, : any feedback on this?
Thanks, have you signed the contributors agreement?
This looks like a really nice addition to the existing test slice support and would be great to add it in 2.2.x. The one things we're not totally sure about is the  class. I think we'd rather not introduce that in Boot and instead just support a single  (similar to the way we support ). Can probably help answer that. I'd certainly like to keep a clean separation and have the general use Mock code in spring-ws and keep the Boot code specific to our slice concepts.
thank you for making your first contribution to Spring Boot.
It's been a while, so let's see how much I can recall. :) Really, from what I do remember, there were two big issues:   Spring Boot wants to prevent all logging until it has initialized the system. In order to do that, it installed a filter right away to drop all messages until it reconfigures the system. Using the public API via LogManager, as far as I could tell, you couldn't force a reconfigure event that way, so I bypassed the filter and initialized the system first instead. That made some of the unit tests irrelevant, could be related to what you're describing.   There is currently no public API in log4j-api that can be used to force a reconfigure event for a LoggerContext that was already started. This would normally not be an issue because you can use the monitorInterval setting in your config to make it updatable, but that's not programmatically controllable without digging into log4j-core internals.   I think we should work together to define a public API in log4j-api that can be used for programmatic reconfiguration and disabling logging for 2.9.
Yes! Thank you again. 
Hi -nflx    Request your help in reviewing the PR.
Sorry, we've been heads down fixing problems with 1.2.0 so we've not really had a chance to look yet. Will take a look when we flip the master branch to 1.3.0 (it's still on 1.2.x at the moment).  It looks interesting and I'm keen to look at what we can do with Docker in 1.3.0.
Merged, thanks.
I don't understand why you refer to it. Metrics support for  was added in #12228.
I don't like the idea of the actuator's output format changing depending on what's on the classpath. If we need the  to always be available to produce predictable output then I think we should make it a runtime dependency of the module. The format for a duration in  is, from a user's perspective, intended only to be human readable and writable. The format in the Actuator's response is intended to both human and machine readable. As such, I think we should use a standard format for the duration, rather than our own. Assuming I've read the code correctly, this proposal will result in an ISO-8601 seconds based representation which sounds good to me.
Thanks for your contribution! A few remarks.  This project is in maintenance mode, and we're generally going to be reluctant to accept PRs that are essentially cosmetic, especially if it is not trivially obvious that they don't change anything. Anyway, I'm not really convinced that the change would be an improvement. The new helper methods seem more complicated than I would expect. I don't see why they catch and rethrow exceptions, for example. They also have type parameters that don't seem useful. As a more general remark, refactoring test methods to remove duplication isn't as obviously beneficial as with production code. It's an advantage to be able to understand a test method in isolation, without having to look elsewhere in the test class.  So I think we're not going to accept this one. Thanks for thinking of us, though, and best wishes for your research!
sorry. was out of town. will rebase tomorrow morning!
We aren't using transactions so yes, in our case this doesn't really make sense. I think it would be better to have more defensive defaults for the autoconfigured endpoint.
 Is there any way I could access the patch implemented locally? Would be of great help. 
That‚Äôs validating...  can add the link to that in a comment so we can remove the workaround when the older versions of Android finally age our On Fri, Nov 8, 2019 at 5:45 AM Kevin Rocard <wrote:
Yes I am feeling better now, thanks.  I did the suggested changes, please let me know if there are other changes. 
Thanks  
I apologise for the delay. Will look into this next week. If you want to speed up the process, please consider raising the same PR in .  Please raise any future PRs in the media repository as well. Thanks.
Thanks. Things are definitely better now, but  is still a bit too broad to be merged as-is. For example, the change to how the plugin classpath looks like a good thing to do, but it's unrelated to applying Kotlin examples in the documentation. It's also confusing to me in its current form as sometimes the classpath is configured in the test, and sometimes the classpath is configured in the build script. I'd prefer that the classpath is configured consistently across the whole module. Do you have time to break things up further? I'd really like to keep the changes in this PR focussed solely on adding Kotlin examples. Also, I wonder if a Suite-based approach could be taken for testing the Groovy and Kotlin examples that are included in the documentation. This would align them with the approach that's been taken in the integration tests where  is used to run against different versions of Gradle. The suite would run the tests using both a  file and a  file and would avoid the need for creating a separate test class for testing the two languages for each example.
+1 for JsonJqTransform
Thanks for the PR ! This is now merged into master.
Error in CLA occurred because of my global Git configuration on computer I worked, what should I do in this case ? My GitHub account match in CLA but commits are using different email address
... sounds good. thank you. 
Good catch, merged. Thanks!
Thanks, ! Would you please squash your commits and format it to look something like: For extra context, please see the contribution guidelines for squashing and formatting commits.
Thanks .  Just modified the state in  to be volatile whenever possible
Ha you beat me to it. Was about to commit almost an identical change to the tests. Apologies for not adding them to the original pr, but I could not clone the source at work.
good point, I thought of that as well and decided to go the oversight route and nuke it. Fair enough, I'll restore it in . The second copy is package private so I won't restore it.
I'm planning to pull this as-is and clean it up a bit after the merge. Unless you're actively working on it still.
Thanks again, . This is now merged into  via 3820f0f3a39e2539ccdf265e68d59d204725e219. I also committed a polish via e91cacfdafc9d23667a9e889826750bb3518631f
There was something wrong with the original pull request but I've since fixed it.  Yet the test still fails.  From looking at the code this seems to be a problem that always existed with the MockRemoteEurekaServer so I'm not sure how this ever passed.  Although the fact that it ran before means that I probably missed something. On Tue, Apr 1, 2014 at 11:26 AM, Nitesh Kant :
Thanks for investigating! In the meantime I started to set my server up freshly. Out of whatever reasons, the class loading error does not show up any more when using the originally released hystrix-core 1.5.6 artifact. So the whole thing turned out to be due to some misconfiguration of my environment.  Sorry for the inconvenience. Alexander
Merged with edits (commit f6c12e0), thanks
Thanks Johnny. This was backported to 2.1.x so maybe the error occurred when rebasing or something. If nobody beats me to it, I‚Äôll double check those branches too. 
Thanks for the ping. I'd say we should just expose the handler via a Bean lookup similar to how httpFirewall is looked up in . I'm not sure what is happening with the JDK. Our travis build is passing with JDK 8. How did you reproduce this?
Thanks for the PR. The current behaviour is intentional and is described on the constructors that take additional converters where it says the following: I'm going to close this PR as we can't just change the behaviour. If the behaviour is causing you a problem, please open an issue describing that problem in as much detail as possible and we'll see what can be done.
+1 interest Otherwise i followed this approch to redirect after authentication on specific page : 
Thanks Christoph. I've backported the cassandra fix as I wanted it to be fixed in  as well.
Those names sound sensible to me. We can always refine them if we think of something better when we merge.
Thank you for your patient.I think I understand what you mean.üòÉüòÉüòÉ
Thats weird - I don't see any unresolved comments on . It shows just myself and  as the only participants on my screen.
Thanks again, !
Thanks for the comments , I've added the changes
Please take the time to compile and test your changes before submitting a pull request. As shown by the fact that this change breaks the build, we still auto-configure the layout dialect when it's on the classpath.
I'm afraid the change that you're suggesting cannot be made because it would break existing code.  Have you considered injecting the properties directly instead? Something like:
sorry for disturbing but I found that you mentioned at comment  that CI failures are general problem. Mine PR fails at  as mentioned above... is it same problem and will be fixed?
I have been working off of and only really looking at the  branch.  There are significant changes to how modules/configuration/bootstrapping works in 2.0, so you might want to take a look at that.  If you need to test something you are welcome to pull the branch from this pr gorzell:gorzell/upstream/mysql-config.  Keep in mind that it is based on the 2.0 branch though, so it will probably look quite a bit different than /. If you have need for those additional configuration values I am happy to expose them.  But note that the names will likely change to enable better name spacing and ensure that they are consistent with the other values.
thanks a lot for your first contribution to Spring Boot. This is now merged in  and .
Thanks for your reply . This PR was submitted based on Andy's comment. It's essentially a variant of  , simplifying some logic and accounting for attribute overriding. I didn't modify the code in  and this unit test passed.
we are still looking into the idea of mapping this to config properties. While this does appear to be a common way to handle multi-tenancy in resource servers, it's not clear whether or not Resource Server Multi-Tenancy itself is so common as to want to add Spring Boot support. That said, this class leaves open this possibility.
Do you understand exactly what the specification means by "successive frames"? Video frames are quite often re-ordered during decode, and it's unclear whether successive is defined before or after this re-ordering occurs.
There are other places in the configuration where you have to wrap thing in yaml for this to work;  will work. Having said that, it isn't such a big deal to upgrade the converter to support that use case as well.
Thanks for the Pull Request! This is now merged into master :smile:
I don't really understand what this is for. That said, I don't think it's the right way of doing whatever it is that you're trying to do. Since the event is being posted from playback thread to main thread, you don't really have any strong guarantees about when that event will end up being handled on the main thread. So if you're relying on the event to do something that's needed when switching DRM scheme, I don't think there's any strong guarantee that you'd do it in time. Please clarify.
Sorry for the late reply.. Thanks, Elan On Wed, Feb 3, 2016 at 3:41 AM, P M VADIVEL  wrote:
Thanks a lot ! I am not sure we'll have time to review this one for 2.0 still. I am flagging it now to get more feedback.
Can you confirm that this issue was fixed in gh-7687 and if so please close this PR?
links to  which is 404.
Please submit another PR for 1.4.x.
-suhorukov thanks, I've merged your contribution with a polish commit. If you run the maven build, those formatting failures will show up with an instruction on how to fix them.
Please note that both  and  have been closed.
this is great, can you rebase so we can pull this in?
I just tested out the "user passes in their own " approach, and it solves the problem (when combined with your PR). , do you want to take a stab at incorporating this properly?  I'd imagine an optional  method on FactoryModuleBuilder that passes the lookups to FactoryProvider2, down through the new  methods.   would fallback to a Guice-constructed lookups if the user didn't supply one, and warn the user that they need to start supplying one if the factory type is non-public. We'd also want to do something about the thread-safety issue (if indeed there is one) with the mutable static state.
Not a problem I have amended the commit as requested
I signed it!
 I can take a look at this if you like. 
Fair enough. We didn't upgrade yet. The change is simple enough, but I guess it is matter of taste. Cons are - we expose something that is not needed outside of the class Pros - no extra classes generated. Will close this PR as eventually it wouldn't matter anyway. Thank you for looking!
Thanks for the PR, but things right now are working as expected. The idea of  is that it can do so early in a separate thread so that this costly call is applied (and cached) before  calls it in the main thread that starts the context.
Isn't that code just mapping "jvmArgs" to something more obscure that is needed by the gradle code that we wrap? I assume "jvmArgs" or "allJvmArgs" or "systemProperties" would work just as well (see ). And there was never any indication that this issue was resolved. It may be resolved at some point and marked as "Won'tFix" because it seems to be a general problem with gradle, not specifically anything to do with Boot. Or maybe not.Tomas's point that the Grails plugin has taken the lead and exposed properties in a more friendly way is well made: we could have a stronger position here, but  the pull request as it stands is not going to work, so it's waiting for someone to fix it.
Thanks, . The indention looks ok in the rendered docs, but we should swap out the spaces for tabs regardless.
while you can use  or similar on the command-line, I couldn't find a way to do this in github. So instead I separated this into two commits: the first just copies  /  to  / , while the second makes the actual changes to make them extensible. Hopefully that's easier to review.
ü§¶‚Äç‚ôÇÔ∏è Thank you, !
thanks for the PR. We can polish the formatting as part of reviewing this PR. Going forward, please build the project locally before submitting the PR.
thank you for trying, we'll give it another go.
I'm not sure what this means; I think there might be some words missing from your sentence :)? Not unless they're positioned differently. If it's just a line break then it should be a single cue that contains a line break.
finally all tests pass. :)
Can we have faster work on this. Spring Security currently no way to login without password. Login with OTP, Finger Print, Retina Scan, Face Recognization, QR are all used in Modern Web Apps and we neeed to move with time. If time is issue please point here, so community can come in and take part in development to move it fast.
Thanks! I'll work on getting this merged.
, I forgot to remove the colored boxes around the page regions and the region objects but they only should appear in the debug builds...
Any luck?
Sorry for my delay, I was on Holidays :-) Your question is very interesting; I discussed this issue with . We think there is a performance problem even in the original CAS client; the behavior is exactly the same. We should probably change the gatewayResolver to try a gateway authentication every xx minutes. I will discuss the question on the CAS mailing list and come back with answers. Any suggestions from you are welcome.
Yep. My search foo wasn‚Äôt good. 
General purpose playlists would be nice indeed. I think there are two kinds of multi-source playback:  - those where you are interested in playing full clips - one after the other - where progress bars and UI change upon the next clip (for example album cover when playing music, current time, time remaining), having possibly very different formats (video/audio mixed) - and secondly playback where the source is subdivided (like HLS) but where chunks have some meaning (are clips) and possibly have a slightly different MediaFormat (max buffer size or codec initialisation data). In the first case 'some' delay would be acceptable and a simple  would suffice. It's the latter case I'm interested in, but I'm not sure if that requires changing TrackRenderers. It would of course be nice if ExoPlayer would support a dynamic playlist where you can start multiple audio sources with different offsets / independently from the video... that way it would be more efficient to make TrackRenderers dynamically bound. In our case we have a single timeline, showing all chunks/clips and you can seek through the whole thing. This is the latter case, since although we need to know which clip is playing (to apply selected GPU Fx for example) we do not swap UI's and would like to prevent any delay incurred by flushing the codec, sample sources and/or renderers. Currently our UI needs to know the complete duration to show progress. We retrieve the durations from the sample sources. That's why we are preparing all sources right now. This would be solvable if we had a database of this information on before hand. That would be fine too. If I think about it more, the clips currently are represented as fixed width (horizontal-)list items, so if the player would know which clip is playing we would only need to know the duration of the current clip. For example  could simply return a tuple of the clip index and the position (s/ms/us) in that clip. This would be a breaking change though. Better to handle that outside ExoPlayer using that database of durations... Buffering should indeed we handled the way you propose. Our situation only deals with clips of approximately 10 seconds and a total duration of like a minute, but for a general solution this should be looked into. I'm looking forward to the outcome of you guys looking into this! Some extra food for thought: say we want to create transitions between video's. Thats a thing that would need to be handled a layer above the codec, at SurfaceTexture level. Would it be possible to have multiple (2) textures (GL_TEXTURE_EXTERNAL_OES if I'm correct), render those simultaneously and blend them in the GPU? Or can't those textures co-exist?
Yes, using HTTP introduces the risk of a man-in-the-middle attack. We moved to HTTPS (and enforce it via NoHttp) to avoid the problem described in this blog post. I think the problem with HTTPS must be specific to your environment. It works fine on CI and on the local machines of everyone else that I'm aware of. Thanks for you efforts here, but we won't be able to make a switch from  to  so I'm going to close this pull request.
Both Quasar and Akka rely on plain old threads eventually, so the concurrency models may be different but they base on the same building blocks. In  is says:  "Using ThreadLocals in a fiber works as you‚Äôd expect ‚Äì the values are local to the fiber." Because a fiber is nothing but a wrapped Thread at the end of the day. Every concurrency library out there is based on plain old threads and ThreadLocal cannot be "tricked" out of working, so there is nothing to worry about. As long as every code execution in java happens in the context of a java thread, ThreadLocals will work and this patch will work. 
Thanks for the PR. We discussed this again today and have decided that we'd prefer to tackle this by enhancing the existing code that looks at settings.xml to also honour the repositories that are configured there. Would you like to take a look at that in another PR?
thank you for making your first contribution to Spring Boot. I've polished it in aa4dad1 
Hi  -- extremely sorry for the delay in replying.  Life (and my actual job) got in the way. I still had some reservations about if this worked if the params or return types were package private, so I tested it out to see if my concerns had merit, and it turns out they do.  This gist illustrates the problem.  I basically just copied FactoryProvider2Test.testGeneratedDefaultMethodsForwardCorrectly (and its associated classes) to a subpackage "subpkg", and commented out the fallback to the java 8 (PRIVATE) behavior.  Note that if we don't move the test to another package, then nothing fails because the test is in the same package as the code trying to do the lookup, so everything is otherwise copacetic. The test fails with the error message: The problem AFAICT is that neither UNREFLECT_SPECIAL nor FIND_SPECIAL will work when any of the params (or return type) isn't public, regardless of the method signature of the method itself (which as you say will always be public). As-is the PR doesn't fail because it falls back to PRIVATE_LOOKUP using the reflection... but the fallback is global for the whole injector... so if some factory doesn't need it (b/c it only has public types) but a prior one did need it, then it will still use PRIVATE_LOOKUP. As a whole, I don't really see the benefit in the complexity of the PR, since we're going to need PRIVATE_LOOKUP no matter what (since we need to support non-public types).  And worse: the PR adds some non-determinism in that the order of your factory installations will impact what kind of lookup it uses (b/c a prior one impacts a later one). If there were a way to do this w/o the private lookup while also supporting non-public types, I'll happily merge it.  But as-is, it doesn't look like this does much to help?
Any application that calls these methods and that has been compiled against a version of Gson before this change would fail when run with a version of Gson after the change. The reason is that the return type of a method is part of its signature at the JVM level, even though that is not true for the Java language.
That's good to hear. Please review #2633 and let me know if you have more ideas and then when we can start working on the actual features in a branch. I'll merge your PR there once I have a basic infra in place.
Please create a new module akin to the elasticsearch modules, so that users can choose to install this module if required.
Sorry, when I submitted this time, I used the company's computer and the mailbox was the company's email. This email could not receive the verification email from Google, so I was unable to signed the CLA. I changed the git email and resubmitted.
Ah, sorry. I didn't know that  is checked before  or . Feel free to close this if that's the case.
I've found an issue when the datasource that's auto closed being exposed as a bean means it's picked up by the datasource health auto indicator, which doesn't really like finding the pool closed. Not sure if the good move is to filter it out once it closes or to on the contrary support a closed datasource pool as "healthy" in that case. The second sounds really contrived to me so I would think of the first as better ; opinions?
No problem. I've tried to take a generic approach, so it can be easily extended (hence the regex).
Btw. I'm having trouble to see the concourse builds at the moment (it redirects me to a blank page). Might be related to the build-pipeline rename, but I thought I mention it at least ;-)
Sorry, this isn't something I see us wanting to add to Guava.
We've discussed a few things and we'd like a different output format. We'd like to list the caches with a name, potentially adding a reference to the cache manager when they are two caches with the same name. I don't like the idea of adding the penalty of the  reference where the vast majority of apps only have one and I don't like the idea of using a bean name there either. We've also discussed that the  operation should just drop the cache with given names, with the ability to further qualify in case of conflicts (but, IMO, that's a corner case that shouldn't happen). I am not sure yet how to structure the read operation so we need to give it a bit more thought. We will use this PR as the base for this work.
where is the XSD? This is so disappointing.
I resubmitted this.
yes, it will be nice if springboot supports messagepack soon
Just did the process again. It didn't look like it actually was signed (Why would it give that message?)
hi friends i bought a new ip camera    tp link nc220   it is h.264  but exo-player can't play stream  this is log cat : 2019-05-21 16:33:55.883 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@d9f77c8[SampleChooserActivity]: ViewPostIme pointer 0 2019-05-21 16:33:55.923 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@d9f77c8[SampleChooserActivity]: ViewPostIme pointer 1 2019-05-21 16:33:55.926 13764-13764/com.google.android.exoplayer2.demo D/AbsListView: onTouchUp() mTouchMode : 0 2019-05-21 16:33:56.075 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@d9f77c8[SampleChooserActivity]: MSG_WINDOW_FOCUS_CHANGED 0 2019-05-21 16:33:56.606 13764-13783/com.google.android.exoplayer2.demo I/zygote: Do partial code cache collection, code=126KB, data=91KB 2019-05-21 16:33:56.606 13764-13783/com.google.android.exoplayer2.demo I/zygote: After code cache collection, code=126KB, data=91KB 2019-05-21 16:33:56.606 13764-13783/com.google.android.exoplayer2.demo I/zygote: Increasing code cache capacity to 512KB 2019-05-21 16:33:56.805 13764-13764/com.google.android.exoplayer2.demo I/ExoPlayerImpl: Init 12872e9 [ExoPlayerLib/2.9.0] [j7xelte, SM-J710F, samsung, 27] 2019-05-21 16:33:56.918 13764-13764/com.google.android.exoplayer2.demo D/EventLogger: state [0.04, 0.00, window=0, true, BUFFERING] 2019-05-21 16:33:56.934 13764-14031/com.google.android.exoplayer2.demo V/Client: opening: elapsedRealtime=[69489246] 2019-05-21 16:33:56.943 13764-13764/com.google.android.exoplayer2.demo D/InputTransport: Input channel constructed: fd=98 2019-05-21 16:33:56.944 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@8c5829c[PlayerActivity]: setView = DecorView@a8c54a5[PlayerActivity] TM=true MM=false 2019-05-21 16:33:56.947 13764-13764/com.google.android.exoplayer2.demo I/Choreographer: Skipped 51 frames!  The application may be doing too much work on its main thread. 2019-05-21 16:33:56.964 13764-13764/com.google.android.exoplayer2.demo D/SurfaceView: onWindowVisibilityChanged(0) true c28807a of ViewRootImpl@8c5829c[PlayerActivity] 2019-05-21 16:33:56.981 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@8c5829c[PlayerActivity]: dispatchAttachedToWindow 2019-05-21 16:33:57.017 13764-13764/com.google.android.exoplayer2.demo V/Surface: sf_framedrop debug : 0x4f4c, game : false, logging : 0 2019-05-21 16:33:57.020 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@8c5829c[PlayerActivity]: Relayout returned: old=[0,0][0,0] new=[0,0][720,1280] result=0x7 surface={valid=true 3485743104} changed=true 2019-05-21 16:33:57.024 13764-13869/com.google.android.exoplayer2.demo D/mali_winsys: EGLint new_window_surface(egl_winsys_display , void , EGLSurface, EGLConfig, egl_winsys_surface *, egl_color_buffer_format , EGLBoolean) returns 0x3000,  [720x1280]-format:1 2019-05-21 16:33:57.024 13764-13869/com.google.android.exoplayer2.demo D/OpenGLRenderer: eglCreateWindowSurface = 0xd1073fa8, 0xcfc43808 2019-05-21 16:33:57.046 13764-13764/com.google.android.exoplayer2.demo D/SurfaceView: BG show() Surface(name=Background for - SurfaceView - com.google.android.exoplayer2.demo/com.google.android.exoplayer2.demo.PlayerActivity@c28807a@0) android.view.SurfaceView{c28807a V.E...... ......ID 0,0-720,1232} 2019-05-21 16:33:57.056 13764-13764/com.google.android.exoplayer2.demo V/Surface: sf_framedrop debug : 0x4f4c, game : false, logging : 0 2019-05-21 16:33:57.057 13764-13764/com.google.android.exoplayer2.demo D/SurfaceView: surfaceCreated 1 #8 android.view.SurfaceView{c28807a V.E...... ......ID 0,0-720,1232} 2019-05-21 16:33:57.058 13764-13764/com.google.android.exoplayer2.demo D/SurfaceView: surfaceChanged (720,1232) 1 #8 android.view.SurfaceView{c28807a V.E...... ......ID 0,0-720,1232} 2019-05-21 16:33:57.059 13764-13764/com.google.android.exoplayer2.demo D/EventLogger: surfaceSizeChanged [0.18, 0.00, window=0, 720, 1232] 2019-05-21 16:33:57.073 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@8c5829c[PlayerActivity]: Relayout returned: old=[0,0][720,1280] new=[0,0][720,1280] result=0x3 surface={valid=true 3485743104} changed=false 2019-05-21 16:33:57.155 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@8c5829c[PlayerActivity]: MSG_RESIZED_REPORT: frame=Rect(0, 0 - 720, 1280) ci=Rect(0, 48 - 0, 0) vi=Rect(0, 48 - 0, 0) or=1 2019-05-21 16:33:57.156 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@8c5829c[PlayerActivity]: MSG_WINDOW_FOCUS_CHANGED 1 2019-05-21 16:33:57.171 13764-13764/com.google.android.exoplayer2.demo V/InputMethodManager: Starting input: tba=android.view.inputmethod.EditorInfo@cc0102b nm : com.google.android.exoplayer2.demo ic=null 2019-05-21 16:33:57.171 13764-13764/com.google.android.exoplayer2.demo D/InputMethodManager: startInputInner - Id : 0 2019-05-21 16:33:57.171 13764-13764/com.google.android.exoplayer2.demo I/InputMethodManager: startInputInner - mService.startInputOrWindowGainedFocus 2019-05-21 16:33:57.176 13764-13764/com.google.android.exoplayer2.demo D/InputTransport: Input channel constructed: fd=100 2019-05-21 16:33:57.176 13764-13764/com.google.android.exoplayer2.demo D/InputTransport: Input channel destroyed: fd=85 2019-05-21 16:33:57.217 13764-13869/com.google.android.exoplayer2.demo D/OpenGLRenderer: eglDestroySurface = 0xd1072018, 0xd1cff800 2019-05-21 16:33:57.230 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@d9f77c8[SampleChooserActivity]: Relayout returned: old=[0,0][720,1280] new=[0,0][720,1280] result=0x5 surface={valid=false 0} changed=true 2019-05-21 16:33:57.605 13764-13764/com.google.android.exoplayer2.demo D/ViewRootImpl@d9f77c8[SampleChooserActivity]: Relayout returned: old=[0,0][720,1280] new=[0,0][720,1280] result=0x1 surface={valid=false 0} changed=false 2019-05-21 16:33:57.709 13764-13783/com.google.android.exoplayer2.demo I/zygote: Compiler allocated 4MB to compile void android.view.ViewRootImpl.performTraversals() 2019-05-21 16:33:58.111 13764-14036/com.google.android.exoplayer2.demo V/Sender: OPTIONS rtsp://admin::554/h264_vga.sdp RTSP/1.0     CSeq: 1     User-Agent: ExoPlayerLib/2.9.0 (Media Player for Android) 2019-05-21 16:33:58.122 13764-14035/com.google.android.exoplayer2.demo V/Receiver: RTSP/1.0 200 OK     CSeq: 1     Public: DESCRIBE OPTIONS SETUP PLAY PAUSE TEARDOWN GET_PARAMETER SET_PARAMETER 2019-05-21 16:33:58.127 13764-14036/com.google.android.exoplayer2.demo V/Sender: DESCRIBE rtsp://admin::554/h264_vga.sdp RTSP/1.0     CSeq: 2     User-Agent: ExoPlayerLib/2.9.0 (Media Player for Android)     Accept: application/sdp 2019-05-21 16:33:58.145 13764-14035/com.google.android.exoplayer2.demo V/Receiver: RTSP/1.0 401 Unauthorized     CSeq: 2     Server: Streaming Server     WWW-Authenticate: Digest realm="TP-Link IP-Camera", nonce="d248c8735a0323d7027027a84e09f25c00000938076d2d5d" 2019-05-21 16:33:58.174 13764-14036/com.google.android.exoplayer2.demo V/Sender: DESCRIBE rtsp://admin::554/h264_vga.sdp RTSP/1.0     CSeq: 3     User-Agent: ExoPlayerLib/2.9.0 (Media Player for Android)     Accept: application/sdp     Authorization: Digest username="admin", realm="TP-Link IP-Camera", nonce="d248c8735a0323d7027027a84e09f25c00000938076d2d5d", uri="rtsp://admin::554/h264_vga.sdp", response="e99c5bad8af73c23e9ff1df41649f8de" 2019-05-21 16:33:58.222 13764-14035/com.google.android.exoplayer2.demo V/Receiver: RTSP/1.0 200 OK     CSeq: 3     Server: NC220 1.0/1.0     Date: Fri, 08 Aug 2014 00:39:15 GMT     Content-Base: rtsp://192.168.1.103:554/h264_vga.sdp     Content-Type: application/sdp     Content-Length: 628 v=0 o=- pmtm70rhg1fowxz 354fkzxi3yliwgm IN IP4 192.168.1.103:554/h264_vga.sdp s=RTSP/RTP stream from NC220 1.0 i=NC220 1.0 1.0 Streaming Server t=0 0 a=type:unicast a=control:* a=range:npt=0- a=x-qt-text-nam:RTSP/RTP stream from NC220 1.0 a=x-qt-text-inf:h264_vga.sdp m=video 0 RTP/AVP 96 c=IN IP4 0.0.0.0/0 a=rtpmap:96 h264/90000 a=control:rtsp://192.168.1.103:554/h264_vga.sdp/getvideo a=fmtp:96 packetization-mode=1;profile-level-id=4d401f;sprop-parameter-sets=Z01AH5ZUBQHsgA==,aO44gA==; m=audio 0 RTP/AVP 0 c=IN IP4 0.0.0.0/0 a=rtpmap:0 PCMU/16000 a=control:rtsp://192.168.1.103:554/h264_vga.sdp/getaudio 
Hello we are using .. version 1.3.9 we are seeing similar error: it hides the true exception: Caused by: java.lang.Throwable: Calling Thread included as the last 'caused by' on the chain. at sun.misc.Unsafe.park(Native Method) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226) at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1033) at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1326) at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:282) at rx.operators.OperationToFuture$2.get(OperationToFuture.java:113) at com.netflix.hystrix.HystrixCommand$1.performBlockingGetWithTimeout(HystrixCommand.java:617) at com.netflix.hystrix.HystrixCommand$1.get(HystrixCommand.java:516) at com.netflix.hystrix.HystrixCommand.execute(HystrixCommand.java:425) at com.expedia.abacus.bucketing.client.rest.BucketingClient.callBucketingService(BucketingClient.java:40)
IMHO the problem is not the corrupt input file but the input validation. In any case I would never expect an application to throw a . I would consider that as a bug (or as bad practice). The pull request gracefully goes over a non-readable user detail. But of course a warning could be added in addition, there.
Thanks. Can you please squash and then please update the commit message to align with the Spring Security conventions? It should end with 
Sorry, have not investigated further yet.
I think there ia nothing you can change on your side. The spring boot defaults are ok. This happens when one actively uses failover transport without setting anything (just addresses). I can submit an issue for them. However, other vendors might be doing something like that as well. Also keep in mind that if one does such configuration mistake the entire health endpoint is blocked. At first I didn't know why the endpoint was not working. I noticed that it blocks only because I was trying something with spring boot admin and they have a timeout on the request, which means that they report that the service is offline. I am open to other ideas about improving this as well.  In the end it is completely up to you whether you want to have something like this. The elasticsearch endpoint has something similar, although they support it in their API.
You have to rebase against   has fixed this in #17092
Thanks, . Unfortunately, it is necessary.  embeds an old version of  which is incompatible with the version that Gradle's generated API embeds. It isn't a problem in a TestKit-powered integration test where, I think, Gradle's class loader isolation keeps the two separate but is a problem in tests that use  when  appears on the classpath before Gradle's generated API jar.
(I think I have it working.)
When you tell Gson to deserialize a Java  / Kotlin  and it finds a JSON number it deserializes it by default as  regardless of the format of the number. I assume for historical reasons that could not be changed which is why this PR here was proposed to allow customizing the behavior. The  allows you to implement the functionality you want. A very simple implementation which just checks if the number contains a  could look like this: You could also have a look at the implementation of Gson's  which implements the same concept except for  and , and also rejects non-finite values and produces more helpful exception messages when parsing the number fails.
that change works fine for me in Postgres.
Thanks! I found a few more so I tweaked the fix a little.
Thanks, ! This is now merged into .
sorry, wrong merge direction
thank you for making your first contribution to Spring Boot. I've polished your contribution to address code formatting and checkstyle violations for the most part. Please consider running the build locally next time as it would exhibit those issues and offer a way to reformat the code.
Thank you for your work on this pull request. We are looking into how we can starting merging pieces of this into ExoPlayer, but some CLA issues need to be fixed first:  , , please could you give author consent for us to use the contribution by replying  here? , please could you sign the CLA? (Or alternatively df3122c89aaa5b4353730576d5df3f0b7ad7e316 would need to be to be removed from the pull request.)  Is it the case that  is the same as this pull request but implemented against the release branch rather than ? If you have any changes we should include that are on the fork but not present in this pull request, please could you add them to this pull request? Thanks! [Internal note: the CLA status can be checked at go/prinfo]
I have been using jar files as an executable file. So this is not good practice in spring boot world, right? 
Thanks very much for making your first contribution to Spring Boot, .
Merged. Thanks!
Thanks again  !
Reverted the change
Yeah - that was my idea as well because it's only temporary anyhow (until Gradle 7 is out). Already working on a follow-up PR. Unfortunately, I had stuff in my local Gradle caches still and hence they ran locally. Sorry for that.
I signed it!
this is an update to your PR #821
I've merged this and also polished up  a little. Let me know if think I've broken anything.
Thanks for the PR . We've discussed this request and implementing it has its quirks and compromises. We've investigated several options and none of them (including this one) are satisfactory. Taking a step back, we'd like to revisit  entirely, I'll comment in that issue shortly. Thanks again. 
The build after merge failed  because QueueDAO interface has a new method setOffsetTime(), you will have to implement that in your MySQLQueueDAO class.
Oops, sorry. I didn't mean to push that. Thanks for noticing my mistake. I was experimenting to see if I could learn if it was possible to get doclint to fail the build when javadoc references a deprecated method. I've reinstated the changes.
Thanks for your time, I've worked on your suggestion .
google3 is marginally easier for us, but I'm fine with whatever you prefer.
I'm aware of the check in the constructor, but since the lack of using a null safe equals causes problems with a code quality checking tool (which is arguably a bug in the tool, which was also reported) and changing the code doesn't hurt anything... anyways not surprised.
Oops. Where do the other commits come from? My intention was a pull request for this commit only fe33669. Any ideas on how to solve this?
Please can you revert the indentation changes before we look at this? Specifically (but not limited to) C.java and TsExtractor.java. If you look at the diff (by clicking "Files changed"), it appears as though you've deleted and re-added huge parts of these files because you've changed them to have 4 character indentation rather than 2 character indentation. This makes it very hard to review what you've actually changed. ExoPlayer source code uses 2 character indentation (and 4 character indentation for line continuations only). Thanks!
thanks,  does it mean my commit will be merged with your changes?
I don't know any other library that supports delayed operations, where you have to wait some time to perform assertion. Awaitility is standard in that area and allows you to spent min time in waiting. await().atMost(2, TimeUnit.SECONDS) causes that code is waiting at most 2 seconds, but checks condition every 100ms. So if it'll be true after 100ms tests is finished - you don't have to wait for example 600ms, as in case from this commit. It allows us to use higher timeouts which ensures that there will be no flickering tests in CI environment.
This has been merged but copybara didn't integrate properly with github again :(
This is my first time squashing commits of a branch, so I might have messed up somewhere along the way. Can you please help me make sure everything is correct?
latest commit has proper formatting of PluginXmlParser.java classs.
The issue is quite simple:  The problem I face is that our proxies do virus checks and silently interrupt the download of an archive. Cargo before 1.4.16 does not recognize this and thinks everything is fine until it tries to extract an incomplete archive. This manifests in the exception above. My wildfly zip is only 11MB in size, but should be much larger...
Unfortunately, I don't think this is compatible with what callers currently expect.
The best way that a found was: just specificy what profile do you want and be happy. I believe thats its best way to do that. I hope that it works to another person. Cheers!
An example is Lightbend's Lagom Framework: it is based on Play! Framework, which uses Guice. It is stuck on Java 8 until these problems are sorted out. They have recently decided to jump directly to 11 (citing Cassandra's team same decision). Work on Guice for JDK 10/11 seems ongoing here: Relevant discussions: Thanks to all the contributors for their work!
Thanks for this! I think it would make more sense just to keep the aarch64 exclusion in the  tree and remove it in the  tree. This is easier for people on the Guava team to do, so I'll look into it.
Speaking as a Governator owner,  is correct in that this implementation does raise some larger questions. The behavior of this in combination with Modules.override for example is poorly defined. I'd definitely +1 for a solution to this issue, but this implementation by itself feels incomplete. 
When you have completed your changes, can you also squash your commits please?
Thanks for the PR ! This is now merged into master.
I am actually busy doing that myself. It should be available in a few days.
Thanks once again, .
Hey  & , thanks for picking up this long awaited feature. While documentation definitely helps, we could still run into a situation where setVariables is called enough number of times, knowingly or accidentally to become a large payload blob. This could in turn cause unforeseen issues in Persistence layer, for eg., wide rows in Cassandra, which we'll have limited control over. How about checking the variables hashmap size in SetVariable's  method, everytime this task is executed? I.e We shall limit max size to a configurable value defaulting to 256KB, and reject any updates to this hashmap over this limit by failing the task.
I missed an integration test. I'll look into that.
MediaInfo will be adding support for recognizing Dolby Vision inside MKV files in their next release:  Very excited for this PR as it's the missing piece of the Dolby Vision playback puzzle! Thanks so much !
Oops. Didn't merge yesterday's PR. Let me do that and try again.
Error from my side sorry.
Merged via 057587e
Belated thanks for the review! I'm working on this now. Do you like updates squashed?
There is an experimental module in JUnit5 that we haven't added at all in our dependency management so if we want to be consistent we should either reject this or add the one of Junit5
-sf There is something strange happening. It doesn't let you sign the CLA twice, so that is an indicator that the signature hasn't been registered. I looked and I do not see a corporate signature from you nor do I see an individual signature. Were there any messages when you got to this point? Note that I'd expect you to try and sign the individual CLA unless you are "representing a company wanting its employees to contribute".
Hi. I merged this with the bitrate adjustments and a few other tweaks. You can view and check the final version here. Please let us know if there are any issues, and thanks for your contribution!
Thanks! I think Caliper support is pretty much best-effort at this stage but it's definitely better to have a more recent version.
could you send the complete log with details of the RTSP messages? It seems that the url is not well formed. An rtsp:// schema is required and apparently it is not included in the url.
Checked this change on Eclipse 4.4 - have not observed any differences in how formatter works.
This looks like a sensible approach to me. (I think  is doing the actual review.) Aside: It's a shame we can't use ImmutableMap here, of course, but c.g.common.math can't depend on c.g.common.collect without creating a circular dependency :-(.
I'm with Andy on this one I'm afraid. We have a checkstyle rule to enforce the  prefix so I think there's limited value in enforcing different local variable names. In fact, I often prefer the simpler names you get when you aren't forced to choose something different.
I indeed found a way to avoid the duplicated test execution. Hope that changes your mind about the PR :)
Here we go : I committed all changes and sent pull request #14. I messed up again with git in squashing properly commits that's why pull request #12 was closed. I'm pretty happy with the results : it looks well designed and well integrated in Spring Security. I followed at best what we agreed upon and what I proposed. I did realize my first proposal has a bug as the isRememberMe() method was acting like the isAuthenticated() method. I added several unit tests and two integration tests you can call with : gradlew spring-security-samples-cassample:integrationTest. I'm looking forward to your feedback.
Thank you for making your first contribution to Spring Boot. This is now merged in  and .
You're correct. Parts of the library that are important to library developers may not match the interest level of application developers using the library. This seems to touch on a broader issue of log "composition," i.e., the log intentions of application developers may not coincide with the application's dependencies in general. 
Sorry for the trouble, , and thanks for taking the time to make us aware of the problem caused. I've added an entry to the release notes for 2.1 so that others hopefully have an easier time of it.
Check out , that's the reworked version of this one.
It appears this was opened in error. 
I think you might need to rebase onto master and repush (--force) because there are conflicts with the message codes stuff now. Sorry.
Merged to  and 
 You can/should implement this in your own codebase. The code snippet  provided above should help. We don't plan to merge this pull request for the reasons mentioned further up this thread. 
thank you for making your first contribution to Spring Boot.
Awesome, it looks good. However, I just noticed you were trying to merge this into 1.12; We're actively working on 2.0 right now, and this should go to  branch. Would you mind changing it to  branch please. Let me know if you need any help in doing that.
Released. Closing this pull request.
is this something you are still interesting in contributing?
OK, let me check more devices and let you know. BTW about the consensus, I think I can say that this might be a platform bug as you said, but it might also be an ExoPlayer's bug. It's the problem that there is no standard for vertical video. As you know, we say 720P as when width is 720 px, not height commonly. But it's not always correct when we say vertical video. I mean that we need more robust rules can be applied to vertical video if we say whether this is a platform's or exo's issue. Converting width & height is also a kind of this problem. I'm thinking It's... it's a little complicated... :( Please let me know if you all arrive at a conclusion about this issue. Thanks.
Thank you for such an in-depth explanation of your reasoning. While I still would have been confused and would likely have chosen the wrong version at first, you are right in your estimation that it would have been more logical to use  than . I therefore withdraw my initial rejection of this change.
I think we're currently stuck with it not really being possible to robustly track battery state at the application layer. I have an internal bug open about that, but no progress so far [Internal ref: b/156962128].
Yes I updated the commit and did a force-push.   Sure, in the future I'll make new commits each time for reviews you are on.   Some people don't like lots of commits on a pull request branch, but I can see addressing review comments it is nice to see the diffs. I do like when people interactive rebase to a single change before the final merge, that makes a cleaner history.  But next time, I'll have you let me know when you are ready to merge then I can do that before the final merge. Thanks for the review...  BTW, the change does speed up paused seeks on i-Frame only playlist a bit.  I've got some other things I'm working on for #8592 as well. Once it is all a bit more baked I can add a track selector setting for iFrame only mode and add the scrub seek to the demo app.
Will do.
thank you for the PR! Much appreciated. I'll take a look at this as soon as I can.
Thanks for the PR  ! I went ahead and added a polish commit to get this merged. This is now in master.
Thank you, -ivanov.
this is waiting for three months now without feedback... :-(
I will work to get a small sample to you. 
Thanks . Apologies, I haven't been able to review it thoroughly yet, as I'm still heads down. However, glancing at it, I wanted to mention one thing to think about. You may want to consider the  interface from spring-core. It's used fairly extensively throughout the framework already, and we'd probably want to prefer that over introducing new interfaces. Switching that over will get you a bit ahead on review feedback. I'll let you know when I have a bit more time to review.
Closing as alternate PR as been merged.
Since Arjen and I are writing a spring WS guide I'll definitely be able to offer feedback through a PR later on (probably no sooner than after this GA on the next version).  Sent from my iPhone
Merged (and rebased) thanks.
OK, then I'll look at the CI problem
Thank you!
Thanks for the PR  Now that we support discovery from the issuer uri, it is the preferred mechanism for registering providers instead of adding lots of well known endpoints.
Hi wilkinsona, sorry, that was my fault! I tried to add a folder that did not exist. As the error said, that the given folder was not a directory, I misunderstood the assert. I would like to suggest to add an additional assert before the check: Maybe this additional check helps if someone mistyped the directory name, like me :) Sorry for the inconvenience! Should I add an other pull request with this   assert?
As I wrote earlier, I've tested this implementation with a real live tv channel, and as it turned out, they're sending the images in "full screen" (with transparent area), This leads to a problem, because based on the logic that we discussed yesterday this "full screen" image will be pushed into a smaller box (50% width, 10% height) and the cues will be extremely small, impossible to read. If I manually set the cueSize and cueBitmapHeight to 1.0f for this particular TTML, then it is rendered "correctly", same way as on other players. Do you think we can add support for regions that are defined by pixels? Or can you think of any shortcut that could solve this edge case? One idea would be to parse the pixels also, and check the region size against common video resolutions (1920x1080, 1280x720, 720x576 etc), and assume fullscreen if so. Of course this would be checked only in case of image based cues.
Thanks for the PR but we have a semi-automated process to upgrade dependencies so we don't accept such PRs for that reason.
Thanks for the PR, it was very helpful (especially the Tomcat stuff). In the end I've fixed this is a slightly different way (see b5679594826e7b609524bea1c4ac7806af62bd5a). Cheers!
It should have said  but GitHub mangled it.
Please, see an update in the PR about an . I'm not fully sure that I understood an  contract correctly. Plus it is not clear how to test with  in the . Thanks
As you've probably seen already, I've now split up the PR. This PR is now dependant on #9421. I did some tests before working on this PR and  does currently not suffice to make ExoPlayer notice the aspect ratio change. For Apple AVKit and VLC, a discontinuity is sufficient, but required to make the aspect ratio change get noticed. And FFmpeg/FFplay notices the aspect ratio changes even without discontinuities. RFC8216 says about this:    any of the following characteristics: So at least to my understanding, a discontinuity is not strictly required in this case. And my opinion is that, if it doesn't cause any issues on the player side, why not make PAR changes just work out of the box, even without discontinuities? This would at least make the stream creation easier. e.g. in my case, I had to write a patch () for shaka-packager to make it insert these discontinuities because Apples player requires them. But even then the switches are still not as smooth as with FFmpeg/FFplay (and thanks to this PR with ExoPlayer, too) because the segment cuts might not happen exactly where the aspect ratio change occurs. And fixing this will require even more effort and complexity on the stream-creation side. So as you can see, I highly prefer how FFmpeg does it because it's way less of a burden to get it to work and I don't see a reason not to support this.
I do :)
Thanks Sebastian, this should have been on the list  for quite a while already!
I saw that gwtproject/gwt#9206 seems to be resolved. Could someone restart following builds, please?    I'd like to avoid pushing commits just to trigger rebuild.
I see this was also proposed as #25080.  sorry that we couldn't merge your changes. Please don't spam the repository with duplicate pull requests.
Thanks very much, .
ok then i would apply the fix directly in the DataSize class at first and create a separate PR in the spring framework and leave the Converters untouched at the moment. So from my perspective this PR could be closed then.
I will try to setup a scenario with wireshark next week to do a capture. El vie., 3 may. 2019 17:28, Pablo Ortiz <
thank you for making your first contribution to Spring Boot. I've merged your contribution with a polish commit. I've also updated  as discussed in this issue in a separate commit.
I don't yet understand why these unit tests failed on the build server. 
I am aware of that. I didn't understand what you mean by "we will select correct path". Thank you for reviewing. Let's move this conversation on #25891. I know that token is preferred with v2 but that would introduce a v2 specific property and I am not sure yet we want to do that. I've flagged the issue for team meeting so that we can discuss our options.
Adding a line to the settings.gradle will get it compile into the build, but we still need to program the app to use okhttp instead default one. There is no magic (like reflection) to pick up the okhttp.
I figured it out - it was our old friend slf4j; excluding that from the test dependency solved it. Produced some weird failures, though; which is what threw me and made me think it was something worse...
lgtm 
Hi,  thanks for sharing the view and proposing to implement a codec/renderer specific messaging and a setCodecParameters() as opposed to reusing the exisiting setPlaybackParameters(). How different would the suggested setCodecParametes() be from the existing sendRendererMessage(): I understand that the MSG_SET_CODEC_PARAMETERS  would have to bundle multiple controls , say multiple TLV fields , one of them being the AC4_DIALOG_ENHANCEMENT, others the AAC_DRC parameters and so on and that the message parser would have to dispatch the TLVs to the actual codec.setParameter function as in the ConfigureAC4() from my commit :  Is my understanding correct ? or did you target a larger refactoring that would replace AAC_DRC_PARAMETERs with codec agnostic DRC parameters and my AC4_DIALOG_ENHANCEMENT gain with a codec agnostic dialog enhancement gain without knowing whether the underlying codec will actually apply it or ignore it ? 
Thanks , this is now merged with a polish commit
I just copied from start.spring.io. If you want to change it there as well, fine by me. I don't think you are missing anything.
Unfortunately, I think it is. Trivial changes are really just one-liners, typo corrections, etc
Thanks, updated the commit message and posted a response to the Issue :)
Hey , are you still planning to work on this feature? We still feel this would be an important addition to ES modules.
Rebased to  and adopted this PR to the changes from #6142.
Thanks for the speedy update ! This is now merged into master.
Good points. It's quite common in Spring Security to test that setters have non-null guards. For example, you can see this in . I believe this PR should at least test that the setters check for . Additionally, I was thinking that tests would confirm that the  used by the class is the one that the setter provided. But, after trying it out myself on , it seems to create a test that heavily overlaps other tests. Also, this kind of test isn't done anywhere else in the repo, so maybe we can leave those out. Can you add tests that confirm that the setters check for null?
I made a mistake and the PR was closed. So I reopened at #12503 
yeah : it's the wrong place, sorry !
I've edited the contact info.
Me too :(
LGTM
Could you please take a look at the test cases added by me, and help me understand what I am doing wrong in that. Thanks
squash and merge
Guava is a mature, low-level, general-purpose library. Because of its maturity, much of it is quite stable. It looks like your prototype took that to mean that all logging statements should be at , but I'm not sure how well your interesting theory tying logging levels to code stability applies. I wonder whether your research is intended to apply more to application/service code than to general-purpose library code.
Hey , could you please take a look at this when you get a chance?
Disclaimer: The following is not an official statement; I am not a member of this project.  This only affects Java Serialization, if neither your code nor your dependencies are not using it, then you are not affected by this. I was not the one who filed / requested the CVE or the Snyk vulnerability entry and was not even aware of its existence until I saw your comment. I created this pull request as preventive action, but not because I was aware of any specific existing exploit, nor have I investigated whether a denial of service attack is really possible. The description of this pull request was meant as hypothetical worst case consequence of the current code. (Though arguably I did not make that clear enough.) However, to put this into perspective: Java Serialization is in general dangerous and should be avoided by applications. It is rather likely that other libraries have not paid close attention to sanitization during deserialization, and that even the JDK classes might be vulnerable by chaining multiple objects with recursive references together, allowing to cause a denial of service in some situations. But unless you (or your dependencies) use Java Serialization such serializable classes without proper prevention of denial of service attacks is not a big issue (remote code execution vulnerabilities caused by serializable classes is of course a different topic). Therefore, in my personal opinion the current CVSS score of 7.3 with claimed high impact on availability and integrity is exaggerated. Similarly the "Details" section of the Snyk vulnerability entry seems to contain a generic Java Serialization vulnerabilities text, without being specific to the situation of Gson. To my knowledge the old Gson code could for example not directly have been exploited for a remote code execution attack. (It could however be the case that Snyk has private knowledge about a possible exploit.)  , would be good if you could comment on this, and maybe provide an official statement here. Might also be worth to contact Snyk to clarify the situation and to find out how they determined the CVSS score.
Thanks . I've squashed your commits into one commit.
good catch and thank you for making your first contribution to Spring Boot.
Right, got it. Thanks!
Thanks  
Thanks, merged. If we want to align what we do in the annotation processor, looking for the  and  type is what we should do. Those methods are a bit too permissive with regards to what we actually bind. I've polished that and changed the name of the test to make the intent clearer.
Done :)
I'm looking at this pr. I'll have some comments tomorrow. Sorry about the delay!
Thanks very much for the PR . One of the reasons we've got away with this for so long is that  just happens to be alphabetically before the configurations that use it. Unfortunately, despite my best efforts, I couldn't find an easy way to test the fix. Each test I tried ended up causing a order cycle. I'm pretty confident with the fix, so we'll have to just run with it.
Fair enough. Thanks for coming back to me,  
Hm, I think there are slightly bigger problems here, because "line" and "position" can both have an optional alignment suffix.
hehe, interesting. Thanks!
This was merged in  but our tooling didn't correctly link it back to this PR, so I'm closing it manually.
:) Thanks for the PR. If you want to fix the typo in the commit message, you can amend the commit and then force push to your  branch.
Needs more work.
I do not understand what this is for. The refresh rate is of the display, not of the content.
Yeah, but the  to the  happens no matter what the  does. That's the reason we do this so that if there is an existing PR, the branch remains unchanged.
I've updated the PR,  part is useless after equality check.
Thank you, .
, you don't have to open a new pull request when you notice an issue with your existing one, you can just update the existing one. For example the CLA check will notice automatically when you sign the CLA. Also, regarding the "Fixes ..." text, I meant the pull request description, not the title. You can edit the description by clicking the  icon at the top right corner of your pull request.
Need  and 
Merged via ac93f10
Thanks , I understand your use-case but I think a little bit of pain here is probably better for most Spring Boot applications. Since you have the  option I'll close this one. Thanks anyway for the PR!
Thanks. I've manually picked most of these in 9159c87bf9f073810ac3da9a85292a9253d09985.
Closing and re-opening to trigger a new build.
, thanks for this OkHttp version.  can you share how you set this up to get caching working with mp4s? Are you working with partial responses at all?
You can test out these changes using  or  (until a release is made).
You are absolutely right, there's a mistake in the relocation POM name. We are fixing it as soon as possible. Mind that we'll be publishing relocation POMs for a limited number of releases and you should move on to using the new maven coordinates as soon as possible. Thank you for making us aware of the issue. 
Ok, after reviewing the mentioned ticket I think I understand my misunderstanding. I am working with 2.4.1 where that feature is working, it was on 2.4.2 when this stopped working, that's why I did not understand the example. That said, this paragraph was there in the docs before 2.4, so it was not added with 2.4.2 regression, I don't know what was the behavior in older versions but I agree with you that if what you describe was the original intent of the documentation is better to just remove it. I will modify it and remove the paragraph.
Hi  we are probably going to look at some of the other outstanding PRs before a new release. This PR only adds a guard against misconfiguration (i.e. when the config value is specified incorrectly as > 1), and can be addressed for now by appropriately setting the config. Is there an urgent need for a release? Thanks.
Since, the same test failed twice, which does not happen in other pull requests. I suspect that there is a change in this PR that is causing the failure.  can you verify?
Would you please check if this looks good whenever you have some time for this?
Cool, have you signed the CLA? 
Thanks for the explanation! Somehow I had a faulty assumption that  will always be present based on the  for .
Greg, looking at the report I'm not sure I see duplicates. Could you please verify that you pasted the correct logging snippet.  Thanks.
-fu Are you available to continue working on this PR? Thanks
I think that another valid argument is that  just must create different  and delegate the configuration on each of used tools (e.g.  or  ).
Thanks  - no disagreements. you are more than welcome to implement all the changes or let me know to perform them. While I may not agree on limiting extensibility by making protected methods final, or testability removing getters, it does not limit the PR or the benefit we get from our use of Spring Security LDAP. As for the formatting changes, not sure the formatter I have configured is aligned with the rest of Spring Security LDAP. are you just looking for an extra space on each side of an operator?
In my opinion, there isn't a strong argument for us to start using Kotlin in the core library at this point in time. We (the whole team) spent some time using Kotlin toward the end of last year, and I agree there's a lot to like. However, forcing app developers who aren't already bundling the Kotlin runtime to do so is very painful. I would argue that it's probably significantly worse for us to do this than for a network stack library, because there are fewer good alternatives (that a developer could switch to) and because streaming media is an area that's evolving very rapidly (which makes it less viable for a developer to freeze on the current version for an extended period of time). It's interesting that OkHttp have migrated. That will provide us with a data point to keep an eye on. It should be noted that not all of the feedback has been positive (e.g. some of the responses in ). We're already using Checker framework to achieve this with the current Java implementation. The vast majority of the library is already checked, and we hope to complete removal of the remaining exemptions relatively soon.
-YuYan thanks for asking, I believe your working copy of  was outdated. Next time, please make sure you're up-to-date with  before creating a branch for a PR. I am reviewing the PR, no action required on your end at this point.
Unfortunately the issue we generally find with  isn't that it fails, but rather it thinks it has succeeded but in reality the port is not available. Adding a retry is unlikely so solve that issue I'm afraid. The way that  works is that it first finds a free port and then it releases it so that it can be used by the real server. After the release happens the OS assumes it's free to dish it out again, so it can be used before the real server actually gets a chance to start. The only way I can think of to support this would be to dig into the internals of Tomcat/Undertow/Jetty to see if it's possible to obtain and keep the server port directly.
I suspect that we want: ( cd android && ... )  Instead of: cd android && ...  So that we restore the original directory for the later commands. Currently, I think that we're changing directory for  and then ending up in the wrong place for .
Yes, there are more flaky tests unfortunately. I'll have a look ‚Äì the master build failed as well after my PR was merged.
I download the  and run it. But I got some thing wrong,  And I think a more clear and easier guide is better for the newbies. No matter what's the next step, I will still contribute. Be in this Spring family.
what does waiting-for-triage tag mean? sorry if its a silly question
PR: Fix #3720 Update: indexOf(byte[] array, byte target, int fromIndex)  [Byte.java] indexOf(byte[] array, byte[] target, int fromIndex)  [Byte.java] lastIndexOf(byte[] array, byte target, int fromIndex)  [Byte.java] lastIndexOf(byte[] array, byte[] target, int fromIndex)  [Byte.java] These 4 methods are written strictly according to the requirements of the issue #3720. Unit Tests written: testIndexOf_arrayTarget_fromIndex()  [ByteTest.java] testIndexOf_fromIndex()  [ByteTest.java] testLastIndexOf_fromIndex()  [ByteTest.java] These tests try to cover a case coverage as comprehensively as possible. I think the requirements of this issue have been met. If there are extra requirements or bugs exists, please just comment here. Thanks for reviewing it!
thanks again.
I went ahead and fixed this in  8f53c2e - Thanks for the report
I am sorry.I am just confused by this: Thank you for your reply. .Thank you for your reply.
Please let me know if  is supposed to be an optional field. I can do that as well. I wasn't able to figure it out from the docs. The schema on API docs page doesn't mention logs.
Changed git commit message to comply to the standard.
It does but better be safe than sorry. We know about the travis situation. We'll fix that today. Thanks. 
No need to apologize, we prefer merging lots of smaller PRs to splitting up large ones :) Thanks once again!
Thanks! I think you now just need to do what the robot says in  and reply with a message that only contains .
I am not sure about that //  replacements as the error message is simply AssertionError in that case. 
Working on it :)
Thanks again for the PR . That's not exactly what I had in mind for the test, I've updated your proposal with what I had in mind.
Sorry ;) i saw Josh already in LA again. But he's no measure
Hi , thanks for the efforts here, unfortunately this isn't what we're ultimately looking to do. We want to remove our dependency, not exclude the one from Hibernate. Thanks anyway!
Oh, the contribution is the least you can make :) , you know my github page.
They have class retention, though, so they'll be in the output. Maybe they shouldn't be, but arbitrary tools don't know that :( Maybe file a bug against Animal Sniffer?
thanks for the very kind words and the tips üòÉ I appreciate that a lot, it's good to know that it's not an ununsual case. also thanks for taking it serious and trying to get pull requests integrated into your triage process üëç  
Yes, I have signed the CLA.
Is there any feedback on this?
We don't want to break backward compatible for this one. This should be possible by keeping the existing health indicator, adding this one and updating the auto-configuration to try this one and then the existing one if none apply. Unfortunately, the existing health indicator is in the  package so we can't really have an additional one without having to use a name we wouldn't like. We've discovered brainstorming on this one that #11574 could be extended to package space as well as the actuator has no notion of data vs. raw driver. It is unfortunately too late to make a breaking change in  so I've scheduled this for the next feature release.
Thanks for the PR. I've merged it into 1.3.x and forward into master.
Hi  , I have run it on my local machine twice before pushing it. I didn't have any issues. Let me check the error and I will work on them. Sorry about thta
Thanks for the analysis, that's very helpful! Because of the   argument in the link you gave. I totally forgot I had fix that in the  line. We introduced a different opinion for transactions (which is unfortunate considering the default for AOP and we've fixed that in 2.x). Your PR is spot on (in , thank you very much for the feedback).
My fault.) Done.
I believe the build failure is unrelated to the PR. Looks like the build is also failing on master.
This change would not be enough to make  thread-safe: While it makes calls to  thread-safe (assuming that the backing map and supplier are thread-safe), it does not make other operations like  thread-safe. Still, the simplification to the code is nice. Unfortunately, we currently still maintain compatibility with older versions of Java for our Android and JRE7 users, so we can't use  in code that works there. We can use  in environments in which it's available while avoiding it when it's not, but this typically makes our code more complex. So we almost always avoid that approach. Once we start requiring all our users to target environments that contain , we could make changes like this. But I expect that not to happen for years.
I don't think this should've been merged. First of all,  extracts the value of  header, which is really different thing from  which was used as argument for this change. The RFC 6750 is quite explicit about the syntax of  header in section 2.1: It also states that Unless otherwise noted, all the protocol parameter names and values are case sensitive in section 1.1. Regarding  itself, section 3 quite explicitly says that All challenges defined by this specification MUST use the auth-scheme value "Bearer". To my understanding, the RFC 2617 uses case-insensitivity in terms of identifying auth scheme on the client, which isn't really a subject of Resource Server support.
Sorry that I was not clear. I was speaking in reference to adding documentation at 
Looks good, thanks  .
Thanks  .  I'll also backport this to 1.4.x so the fix is available there
Thanks very much for making your first contribution to Spring Boot.
If everyone here agrees, I'd open a PR focused purely on addressing #5668 off this branch in my fork. That still leaves room for  to re-submit the PR with some of the nice optimizations outlined here, like moving exceptions to constants and validating the token chars.
When it comes to security, disruption should be least of concerns.  See SolarWinds hack 2020...
Can I get an update on any thinking on this? I'm happy to look for another approach if this isn't going to be taken, but we don't want to need to maintain our own fork long-term just for this one change.
sorry, I apparently did a mistake. Do you have any clue how to change this in this pull request ?
Hi , thanks for the contribution. You can go ahead and close that ticket in Spring Framework. About the PR, I don't think we want to solve it this way. Instead, a delegate that delays the initialization of the bean would probably work in this case. I created  for that
Thanks for the PR ! This is now in 4.2.x
Please resolve the merge conflicts. Thanks for your contribution.
There was never any followup from the platform team about this issue, so I think it remains the case that it's not possible to robustly track battery state at the application layer, unfortunately.
I'm not on the Guava team myself, so I can't truly speak on their behalf, but as someone who's contributed to the project for a couple of years now, I think it's worth letting you know that they can be very slow addressing new issues and PRs, which I think happens because they're busy as a whole dealing with Google-internal priorities. So if they take forever to respond (which seems likely at this stage, sadly), it absolutely won't be because you did something wrong; they're just apparently very, very busy with their day-to-day jobs, and someone from the team will eventually respond to this PR. If you don't get a response as quickly as you'd like, writing a reminder message like the one you wrote here every now and then should encourage a more timely response, even if they're a bit too busy to review the PR properly. I hope this helps! :)
I think this is worth documenting as proposed and/or by mentioning  in the documentation for .
Could you sign the CLA and ensure the PR is merging into the "dev-v2" branch? Otherwise we can't accept the contribution.
Thanks, have you signed the CLA?
thank you for making your first contribution to Spring Boot.
Okay, here I may have misunderstood the usage of the  for . Some of them are setting it , some are , some are ... But most of all,  selecting for videos or audios, I can understand, but for subtitles.. I really think it's even hard to understand for service users too. (e.g. watching NETFLIX, and I click on changing subtitle button and it shows current option is on  "AUTO")...? And that's why I wanted to remove that option from the first place. Since not using this method doesn't affect anything else anyway, how about throwing  in  method when the user didn't set default value? And so there will be  and make constant value for  option = -1 (I really want to remove  option...) 2019ÎÖÑ 2Ïõî 19Ïùº (Ìôî) Ïò§ÌõÑ 10:53, Oliver Woodman <
What I'm saying is: - The work done in  is vital. If you remove final from that method, as proposed here, it would allow someone to make the mistake of overriding it and failing to call  from their override. This is why it's final. - You should just be able to implement  to do what you need. You shouldn't need to override .
Ok - this looks good.  I'll merge in. 
thanks for the PR, you logic seems sound and there does seem to be an error in the code. Before I merge in your fix however, I'd appreciate it if you added a unit test that assert and validate the expected behaviour? Thanks.
CEA608 is hardly ever used in on-demand content, but it is widely used for over-the-air television. The artificial alignment of the content providers often creates scenarios when consecutive lines aligned differently become very hard to read. The existing optimization of ExoPlayer does not consider multiple lines when decides about alignment of each line individually. This change fixes lots of issues when the data contains something like (note that the left sides of the lines were matched fore easy readability):  With the optimization before this change (aligning lines individually)  Possible side effect of the new change: both lines are accidentally matching the criteria for center alignment. That is not a real issue, as it is still easy to read:  worst case scenario (everything reverted back to the left alignment and gets displayed exactly as defined in the content, easy to read (this is the exact placement requested by the specification)
-procon  is not going to help, the timeout offered by the provider is related to message consumption (which is certainly not something you want to do as part  of a health check). As for what Phil said, it's related to backporting the change to , there is no lambda there.
Thanks  . I am just now getting back to this and will update w/ suggestions shortly. No worries. 
Hmm, that sounds like the same problem, only worse. Greg can say for sure what bit him, but I think it was SD Gemfire. I guess in that case he chose a version of SDG that happened to work with the latest SDC, but wasn't really supported in that combination. Or something.  We can certainly revert this change if it causes problems.
Hi -manes you can create a bean like this and the auto-configuration will take this.
I suspect this PR won't be merged anyway, so here's my two cents:  Do not check for equality using . Use  instead. It's possible to construct  equal to  but¬†not being the same instance as . One of many possibilities is to call . First divide, then multiply. It's more efficient. As rounding is indeed , don't use it at all (it is sufficient to use ). There's no need to call  more than once. 
I think Gson.lenient flag probably does more harm than good in the current state.  The comments on the GsonBuilder.setLenient() method say  The comments on Gson.setLenient() also references the JsonReader.setLenient(boolean) method which has a great explanation of what should and shouldn't be considered when using the lenient flag. The unfortunate fact here is that due to the Gson.fromJson(JsonReader, Type) method always setting the lenient flag to true when parsing, almost none of what is commented in GsonBuilder about the default behavior of Gson is true.  The only affect that setting the lenient flag on Gson will do is to allow comments to be at the end of your json buffer when calling Gson.fromJson(Reader, Type) since the assertFullConsumption(Object, JsonReader) method will be called from here and only checks for data at the end of the buffer having not been consumed (e.g. comments at the end). Consider, for example, the test in com.google.gson.functional.LeniencyTest If you were to remove the comment at the end of the String ("# Array!"), then it would not make any difference at all whether or not the lenient flag had been set.  The following would also pass: It seems counterintuitive that with the lenient flag unset, comments in the middle of the JSON data would be ignored but comments at the end would cause a failure when the Gson parser is supposed to be "strict". If it is considered undesirable to change the default behavior (to the behavior that is documented) by actually respecting a default lenient flag being set to false (i.e. default to strict), then perhaps the correct answer is to respect the lenient flag, default Gson to have the lenient flag set to true, and update the javadocs to reflect that Gson by default is lenient. Do you have any thoughts on this alternate approach?
The example is trying to show unexpected behavior when there is a nested document in a profile-specific file. It is saying that even if you have the  profile activated and the  file is loaded, the nested document under  will not be processed. This is due to the filtering of nested documents that occurs in profile-specific files. It is an example to show why you should not use  with profile-specific files. Hope this answers your question.
PR stands for pull-request but please don't spam our issue tracker with questions.
This is a great change.  (Sorry it took me so long to see it.)  One small style nit though.
Weird that things changed there. Thanks for getting to the bottom of that, I've get to upgrade to 4.5.
so cool.
thank you for making your first contribution to Spring Boot. I've polished your contribution to use  for consistency. There are include/exclude-related user properties in  but these apply to multiple plugins and this one does not.
The test is awesome. Thank you all reviewing and merging the pull request.
I signed it!
, oh, it's my mistake, I'm so sorry. We could delete this pull request if Brian has started working on this enhancement.
thank you for making your first contribution to Spring Boot. I've polished your contribution as the error message in the test you've added was misleading. This turned out to be a bigger change than I anticipated. Hopefully, the reason provided in the log is more accurate now.
Hi , assumed correctly! ;) I forgot to mention #164 in the request, apologies.
I'd quite like to go the other way and add some additional CSS styles. I think the HTML snippets are quite useful for people.
sorry, the pull request was #1546, not 1526.
This commit is already included in this PR:  But I can send a separate PR if needed.
Either way. Before we merge, you'll need to force push down to one commit. Some folks like to keep commits separate while the review is going on. For small PRs like this, it doesn't make a big difference.
FWIW, I have no objections to using a  type. I assume that  doesn't either given that this is now in the 1.5.0.M1 milestone. I'll mark if for discussion just in case. In addition to being protected by a condition at runtime, use of  should be done via reflection to ensure that the code will compile on a JDK without the  classes. See HeapdumpMvcEndpoint for an example of that.
I have updated description with my use-case.
It will break people who rely on the existing behavior, which is why Gson is effectively frozen in time. On Wed, Sep 9, 2020, at 8:36 PM, Phillip Hellewell wrote:
Thanks , yes I have signed the Contributors agreement. Yes, I totally understand not encouraging the use of jsp as a view technology - and absolutely fine if this pull request is not merged.  I wanted to contribute this as I personally use jsp for view and tiles for layout extensively in all my projects, and more recently have been using Spring boot but with jsp and tiles ( I have tried thymeleaf, but I am yet to take a shine to it :-) ).  
Lol, sorry.  Copy and paste did me in when I grabbed the existing buildAudioRenderers and made a minor change in my new class.  That function uses componentListener and not the passed in eventListener.
Hello, If you wanna add many byte values and you don't know how many. You can't this structure. Thanks your comment.
So should the documentation then be updated to state that a MalformedJsonException is thrown and JsonTreeReader be adjusted accordingly? Because the current behavior is inconsistent.
Sorry, I missed the Java 6 requirement. I believe that you can use the  instead. I chose to use  because I thought it would be beneficial to have a "fail fast" approach. For example, if the app does not have read privilege of the specified path, or the security manager has not been configured correct, I prefer to have the exception during startup as opposed to when the health check is called. But nothing prevents you from calling   in the constructor as well.
I didn't have my coffee yet - sorry for the polishing commits.
Thanks for PR! Can you please update your commit message to align for contributor guidelines  Something like this works:
thanks a lot for the PR.
I always forget the ,  order for . A lot of the other tests use  which I generally prefer for both the error messages that it produces and the readability of the code. For example: 
Hi Thank you for your reply, thank you very much. I will try to validate my logic by adding test code because the update is done in a thread and I currently have no idea how to test it(These days I have been looking for ways  but unfortunately did not find) .but do not worry I'm trying to figure out how to solve this problem
Well don't revert it, that would revert it in master too!  Just rebase this branch.
Thanks for doing this!
-simons been taking a look at your comment, and in regards of possible side effects, MongoProperties has a method to create a MongoClient, is there any risk of the MongoClient being created before the post processing happens? Probably its a silly question, as I'm not that familiar with BeanPostProcessors, my apologies if that is the case. As for alternatives, what about extending MongoProperties and overriding the getPort method to return a fixed 0 if super is null, and make sure that this new class is the one being used for the AutoConfiguration in the tests?  Also, in regards of  would you prefeer that i open a PR to your repository, or better that i wait for the PR to be closed and then i open a new one afterwards? 
It's my custom extractor code that's broken.
hi. I see many other opensource projects using Guice. They are moving on java 10, so they are forced to delete Guice as dependency unless Guice move to java 10 too
Hi , Were you able to take a look at my comment above? Thank you very much!
Merged, thanks (commit b8c4720).
Jetty relies on modifying the bootclasspath. I'm not sure whether to require Spring Boot users to do that when running their app is a viable option. Two solutions come to my mind:  Decide that HTTP/2 will only be supported for Java 9 and later. Provide our own nasty hack to support ALPN on Java 8  What do you think? Is there a general solution to problems like this one, where a feature is not equally supported by all three Servlet Containers?
Hmm,  is it possible that respecting settings.xml is only implemented for grab- and not for install-command?
Thanks!
Having discussed this, our current feeling is that we're happy with this as it is. However, we'd like to know if you encountered a problem that was caused by the code in its current form? That would probably change our opinion.
It is recommended to reconsider this action.
Given there are 800+ commits in this PR, I am guessing you made a mistake setting up this PR. I'm going to close this so you can create a new PR with a single commit for the changes you need. If you need help, please let me know on gh-7578 and I can try and guide you through the process.
for review
Got it. Too bad. In that case I recommend copying the code you need into your project. I don‚Äôt want to encourage anyone to pull code from Gson‚Äôs  package.
See #5208 
Resolved now, thanks.
Sorry I was trying something else before pushing my commit, all tests take 13mins in my machine. I ran them all three times üôÉ
Thanks for the suggestion, but we think it's probably more useful to have the complete set of results rather than failing fast.
Thank you for the PR -lee! This is now in master.
Funny enough, I had a similar version before (with  instead of  but hey) and I too find the double  sub-optimal. I decided to append it at the end to less likely break it for anyone parsing this log statement - (I've seen people do this for startup statistics). I'm totally fine with what you suggested. Let me know if I should change it.
Hello,  ! I don't know what was wrong (may be just my hands :smile: during release), but I asked  for the help about promoting from our . Maybe you have some advice how to be ? Thanks
it's been a while since this PR was opened and I'd like to understand how relevant it is. Can you please update us with the current sate of affair?
Signed on behalf of corporation, Vidku, Inc.
Both the  and  methods push the parent workflow id to the  and don't call  synchronously. This is the reason the tests need to call  for the parent workflow state to be updated. The subworkflow still accesses the parent workflow's task synchronously and updates it.
These days we're trying to only add media types as entries only if Spring projects have a specific support for that, or if this type is officially added by containers we're in sync with. In the interest of efficiency, we won't add that one right now. Thanks!
I have finished adding Unit tests and Javadoc. The only thing I noticed/changed is how the HystrixPlugin is loaded as a singleton eagerly. I prefer lazy loading so you don't accidentally kick off loading by just importing . There is a slight chance this could affect backward compatibility and or performance (but this is very dubious). This may have been even done on purpose. Perhaps  would know? Let me know if and when you want me to squash the commits.
And I forgot to update the doc as part of the polish.
I just realized you're the author of Traute. I sorry we couldn't use it ourselves, but I'm sure for many projects will find it a very nice way to reduce boilerplate. Good luck with project!
,  , I addressed your concerns and rebased to the . Will hope that I have guessed what you mean :smile:  Thank you for taking a look though :smile: 
Any recent movement on this issue? We recently hit this problem when upgrading Bouncy Castle from 1.65 to 1.66 in our applications. When running the Spring Boot Plugin created uber jar we started to see a 20 - 30 second hit to our startup time when initializing Bouncy Castle. If we do a "classic" -cp style execution of the same application then there is no startup performance problems. We also noticed this only occurs on Java 11 and the problem did not exist if we ran against Java 8 (we didn't try any non-LTS releases of Java). Nothing in the Bouncy Castle 1.66 release notes really jumped out at us as a potential cause and then we stumbled upon this PR. We did notice that the bcprov-jdk15on-1.65.jar was ~4.25MB in size vs the bcprov-jdk15on-1.66.jar which is ~5.61MB. Looking into a bit more and the META-INF for 1.66 is significantly larger than 1.65. So if this problem is anything like the bug referenced by  above then the steep increase in initialization time would make sense. For the time being we are going to downgrade to Bouncy Castle 1.65 but that is obviously not a long-term solution. We are willing to help test or validate any proposed solution here.
I've restructured the section and added more general instructions on how to use JAXB.
merging. Please review and send me feedback, and I will incorporate it in another PR
, thanks for your patience. I put together a pretty simple test to measure performance differences with this code change. I tested just the method  with 100,000,000 iterations, and ran the test a number of times before and after the code change. The request that was saved included 4 headers, 4 cookies, 4 preferred locales and 4 parameters, causing the constructor to do some work on each iteration. There were no discernible differences with the default configuration for . However, with : Before code change:  Average ~1,464 nanoseconds per   After code change:  Average ~114 nanoseconds per   So we save about 1.35 microseconds per request. This is pretty small, but proves that the performance impact is non-negligible. It's worth noting that most applications would use the  in the stateless scenario ( or even ), so I'm not sure many applications will benefit from this. Still, this is another way to configure the application to avoid session creation when desired and may improve performance in that case.
The same change needs to be applied to the reactive counterpart. I added #6195
Calling format multiple times on the  causes the video to freeze while testing. My test bitstream currently appends display orientation SEI every 150 frames for a 30 FPS video. Are there any limitations or rules to the  method I should be aware of?
thanks, the API is published with Hazelcast 4.0.2 and I am now working on this to finalize.  Yes, unfortunately we had to check for 3 classes within the new API to make it work together with Hazelcast 3.x and 4.x. The good news is I used s, which won't add any performance drawbacks.  As I mentioned, I am working to finalize and I will let you know about my updates.
Thanks. Would going all the way to 2.3.3 be worse for your dependency-agreement efforts?
Aaah, ok.
-wr thank you for making your first contribution to Spring Boot.
Thanks again. Having recalled that  is a  and looked a bit more closely at Jetty's documentation, I don't think this PR is taking the right approach to configuring statistics. It's not completely clear from the XML, but I believe you need to create a  and use it to wrap the server's existing . You can see an example of this wrapping here: .
Thanks a lot!
Begging your pardon, but how do I wire up a minimal embedded setup using that for test purposes? So far, I have the following code, but I don't know how to bridge that to either  or . What's missing so I can test my changes?
Yeah looking back on my arguments against doing this, they're not very convincing :).  This way is certainly way simpler than trying to cache failures just during injector creation.  So +1 for this approach from me, except for the change to .
Thanks for the suggestion, . I'd prefer to keep the message enabled for local builds. I think it provides useful information for contributors who aren't familiar with the version of Gradle that we're using.
If you would like us to look at this issue, please provide the information requested in #8866. If the information is not provided within the next 7 days this issue will be closed.
Since RC1 is around the corner, heads-up that reactive bits of #5918 need to get reverted. Or maybe all of it, if this PR doesn't make the cut.
Closing this in favor of #858, with the assertions added  
Thanks for the PR. This auto-configuration doesn't feel like a natural fit for inclusion in Spring Boot. IMO, it would be better as a third-party starter. We could then add it to the list of such starters
Thanks for the PR. Sorry, I didn't see this until after a build had failed for me locally and I had pushed the fix.
M2 is approaching, any news about this one? Thanks!
Unfortunately, when the audio and/or video codec is not supported on the device there is no fix to it. I also have a Samsung S7 and I have the same issue. :(
I found 26 hits inside google using "Iterables.get(.*random", which is more than you, but still fairly low on the ubiquity scale. I'm also generally -1 on this proposal (all of the above comments are good), but I'm happy to leave this open in the "research" category in case other folks want to make a stronger case for it. In the case that you have a  (which I suspect is the majority case), we're not actually saving much: If you have an /, sure it's a little longer, but still not that much of a savings:
Thanks for approval and merge  ! May I ask, when should we expect next release to happen?
Thanks for doing this! Some remarks: 1. Can you avoid moving methods around? It makes reviewing harder. 2. Some of the formatting changes are a bit distracting. Fixing indentation to be consistent with Google style (+4 continuation lines) is good, but for example there's no need to split EnumWithObfuscatedTestsetUpprotectedpublicsetUp` because it's specified with the wrong modifier seems pretty hostile to me, but there it is.)
 Those s can't be added, as explained:  There's no reason to extract that , as the  method itself is only called once. 
Though sadly we can't really test it for real real until it's merged. :/
Yes, Motion JPEG and H265 video formats are not yet supported on Exoplayer RTSP.
I have added some tests, thanks to that I have discovered one problem so the tests have proven that they are useful :+1: I did not want to squash commits during code review, would you like me to do it and organize it like 1st commit for CompositeHandler and  2nd commit for WebSecurity setter?
Does this require an ownerEmail now on a task?
Thanks for the updated PR. Unfortunately we won't be able to upgrade until the passivity issues are fixed. The reason for this is that it will potentially break users that are using the non-passive APIs. Furthermore, if they are interested in upgrading the CAS client it is very simple for them to declare the updated version. Also note that running "./gradlew build" will fail with a NullPointerException in the CAS integration tests after making these changes due to 
rebased to latest dev-v2.  There is still some funkyness if you jump around in a true hd clip with the latest code.  It didn't happen before when I was buffering, but without the buffering it gets weird.  Going to look into this again soon (hopefully).
thank you for the PR but we don't need those as we have a semi-automated process to upgrade dependencies and we'll upgrade this one in due course. (There is a note about that in the template when you submit a PR).
Have decided against this design change. Yes it makes it more difficult to cause a memory leak, but it does it at the expense of a more awkward API that doesn't match the rest of the strategy pattern classes. The Javadocs are clear on the contract that initialize() is the only place where publishing should occur - I'll leave it at for now instead of a late change such as this.
Thanks , I've merged this to 2.3.x and master. 
Oops, good catch. We should add more tests because some should have covered us when we did the refactoring. I discussed with  about it unless you want to give that a try? 
I built what got merged (release-v2) and it's failing on most of my samples.  It appears most of the clock/AV sync code was removed.  This is what needs to get added back in (in order) to get a functional release:  The clock code.  Since AVI does not store PTS for each frame, it needs to be generated via some sort of clock generator. The XXX ChunkHandler, this code feeds the clock and keeps it in sync with the stream.  Usually you will need one of these per codec.  Probably the most import are MP4V and MpegAudio. The Audio Stream positioning in the SeekMap.  The audio stream is muxed in chunks (groups of frames), not frames.  The audio frame number is stored for each video frame that can be seeked to sync audio clock.  I'll admit that my impl. is hard to follow, but it's hard to store all that info efficiently.  Note:  Some streams (MJPEG) are 100% key frames, so just storing the key frames can be problematic.  It would be nice to have back the code that fixes up the aspect ratio based on the underlying codec data.  A lot of the AVI muxers don't pick up on the anamorphic flags in the video stream when muxing.  This results in the video being played back with the wrong aspect ratio.
I'm confused. I cannot reproduce the issue you're describing with Spring Boot 2.6.5. Could you provide a sample application that shows the problem? Also, checking for the presence of  classes on the classpath looks strange to me. The  condition already performs classpath checks on classes that are in spring-webmvc or spring-webflux JARs.
Yeah, it's a bit frustrating that there isn't a way to log debug info at a different level. I'll take another look to see if we can put it back.
The prebuild failed after almost an hour with the following message Clicking  then allowed the IDE to open in my browser but there's no Java extension installed. I can open the code, but it's treated as plain text. Unfortunately, it's getting increasingly difficult to justify spending more time on this. Flagging for discussion at a team meeting so that we can decide what we want to do.
Sorry. We would normally have taken a bit more time to give you a chance to make the suggested updates but we're trying to finish off 1.5.4 which is due on Thursday. Please don't misinterpret the PR not being merged as us not appreciating your efforts.
 I'm seeing the same behavior on a COMPLETED job. Just trying to run multiple times with a different parameter  value for .  Works fine for non-id parameter  
thank you for double check and your help!
After some consideration we've decided that we'd rather not add product specific log messages. Although it seems like a good idea, there are lots of other reasons why this exception could be thrown and adding a specific message could be confusing in those cases. We also don't really want to start adding specific code paths for issues that should ultimately be fixed upstream. Hopefully people searching for the problem will find this issue, or the stackoverflow answer until IDEA-107048 gets fixed.
See these comments here:  - Seems like we get an updated Guice very soon.
All,  If we went with allowing a ".conf" file to be included in the project, would we add "embeddedLaunchConfig" or "embeddedLaunchConf" at the same level as "embeddedLaunchScript"?  Or would you see it as another embeddedLaunchScriptProperties? Either way, procedurally how should we move forward?  A separate issue with a new pull request or edit this one?  I'm happy to do the development, but I'm not sure we would make the next 1.5.x release.
Thanks for the fast PR! I have added feedback to the code.
Thanks, Gary. This one feels a little bit different to me as there's a setter on container factory whereas other additions (such as ) have directly mapped one of our properties to a Kafka property. It doesn't sound like you have an objection so I think it makes sense to add this one, particularly given the setter in Spring Kafka. -ayotte Do you have time to update your proposal to add a  field to  and the corresponding getter and setter methods?
It is impossible. Upon using core reflection of a class, the JVM always eagerly asserts the consistency of a type. It does not matter if ,  or any other method is called. The JVM does not allow the use of reflection on an invalidly linked class. It does have a problem with it, therefore the  is emitted upon linking the Spring Boot class. The only reason that it works today is the fact that HotSpot links types lazily as suggested in JVMS ¬ß5.4: At the same time, the JVMS does not give any guarantees about lazy resolution. Spring Boot does therefore violate the specification and would not work on a spec-confirmant VM that applies eager linkage. Furthermore, with project Jigsaw in place, the module verification step would trigger a full linkage even without any third-party interaction. You are coding against the implementation, not the specification. This does not make this a legal pattern to be applied on the JVM, this goes for the current implementation as for the suggested  alternative. Strictly speaking, only reflective access of optional types is a legal pattern. This is also how Byte Buddy implements it itself to function on Android where linkage is applied eagerly. Neither the instrumentation or reflection APIs are explicitly bound to visibility scopes. A good example for this behavior is the usage of reflection by the Spring framework itself. Ironically, your own framework could not "work-arround" such a limitation if other people impelented a patter as the one that you suggest. As for reflection, only access of non-visible members is guarded and checked by a . And even if this was true, if you ever declared a public subclass or implemented a public interface of the class in question, calling  on this class would result in the same error. This is a bug in Spring Boot.
Yes, I have signed it.
Thank you! :smile: 
it is then.
I signed it
are you willing to rework this PR in that direction?
Thanks for the feedback. I've re-read the section and we're already mentioning quite advanced details about . That nullifies my previous argument.
Thank you, .
Thanks for the PR. I'm inclined to leave those lines because they do explain the difference between the methods and the equivalent non-"try" method on Integer itself. It's true that the method doesn't throw if parsing fails, but parsing failing and the input being null are different things. I do see how it could be confusing, so I'm inclined to add explicit  to the Javadoc instead (even though that's not a thing we normally do). We've already done that in a similar cases, as pointed out in #1259.
sorry that you were sick, I hope that you are feeling better now. Thank you for the updates. Let's please do two more changes:  First, will you please rebase your branch to resolve the conflict in the PR? Second, will you please deprecate the old  method? This is a suggestion that  made to me offline; my apologies that it wasn't in my initial review. To deprecate a method, please add both the  annotation to the method and the  JavaDoc tag that includes instructions to use the new  method you've created. 
Thanks. Have you signed the CLA?
I think your Amazon address is part of that group, but you're using a Lab126 address that isn't. You need to get the Lab126 address added to the group, or use your Amazon address on GitHub. The bot does verify corp CLA signers, so you should be able to reply  once this is resolved.
This one has been flagged for team attention so that we discuss it on one of our calls. I'm personally not too keen on the lazy bean idea, it's not that common for auto-configurations. In this instant, it would be nice if we could configure  so that the  must be provided. It feels like the confusion is caused by the fact that  creates the  for you. If it actually failed and made you configure something, at least you'd be making a conscious choice.
Maybe my PR is not accurate and need to be improved. I allow edits from maintainers.  I'm trying to improve docs for users without familiarity with Spring Security. Consider the next use case. "A very busy developer"‚Ñ¢ want to set up monitoring with Prometheus for a Spring Boot 2.1 app. They know:  Spring Boot app authorize with form-based auth (because it works in the browser) Prometheus cannot use form-based auth but can use HTTP Basic auth.  They search for more info in Spring Boot docs and finds: What this?!! What HTTP Content-Type header do they need to pass to enable Basic Auth. Current documentation is really confusing! In my case, I drilling into debug session, spend 1 hour and send this PR to help future users of Spring Boot 2.1  endpoint.
Ohhh ok, thank you üòÉ 
Thanks anyway!
Sure. No worries. Thank you for quick update. Congratulations to Moritz. üôÇ 
Also, if you add support for  (as you should) do you intend to keep the  test? IMO there's not much value in keeping it. And if there's a change in a point release that affects the test execution, you'd like to be aware of that ASAP, right? Both of these cases are handled automatically by using  tag.
It's unclear what this is trying to do. Note however we do not accept pull requests directly into the release branch.
reply
Thank you a lot for your time. 
-nflx I don't have any recent SQL Server experience so I wouldn't be a good resource to review this. As far as combining all sql-based database persistence modules, that is what we did before the Postgres module was introduced. We created a sql-persistence module. There were actually very few differences between MySQL and Postgres which we accommodated by having an interface for all query strings with default methods for the ones that were the same and the individual implementations would override what they needed to. This worked pretty well. The problem that we faced with doing it that way is that our knowledge of MySQL started to dwindle and whenever we would make a change for Postgres we would also have to be on the hook for making the MySQL changes. Since we no longer had a MySQL DBMS inhouse we couldn't test the changes for that db. When the Postgres persistence module was introduced we decided to bag our implementation in favor of that one because of the logistics of contributing back.
Sorry for the late response; could you please update the pull request to resolve the merge conflicts?
This is close to what I've been using. I'd suggest the following changes:  This shouldn't be called a . There are lots of ways of transforming JSON, this is very particular to jq. I would just use the whole inputData as the input. Additionally, I made an optional argument to instead use the entire task as the input to the transform, thus allowing access to things like the task ID. Cache the compiled queries (e.g. a Guava cache).  Looks like a NullPointerException:  A list of one is still a list. The conversion of the result makes the output challenging to consume if you don't know the exact size ahead of time. I'd suggest something like the following. 
This is really nice stuff, thanks! I need to make a few minor modification because the Flyway result wouldn't produce JSON and the ordering of auto-configurations needed to be tweaked. See 3995c16ba60bbeb1933c2233ffcab368655fb3c2 for the differences.
I think switching from  to  would be a cleaner approach. Cleaner in the sense that it will avoid passing around the  instance just to use its  method.
Agree with this and I understand your worries.  Another option can be adding a customizer.
This is merged into dev-v2, but the git history got a bit messed so I'm having to manually close it as github hasn't detected it as "merged".
So please update your PR!
I'm not able to share that information here, sorry. Although I'd suggest that results from a survey of developers who use Kotlin as one of their primary programming languages is probably not the most reliable of indicators for measuring Kotlin adoption. We will continue to look at the language mix being used by app developers who also depend on ExoPlayer, and this will continue to be an input into deciding when it makes sense for us to start using Kotlin within the library. Kotlin demo apps are great. We might convert some of ours as well. We're committed to making ExoPlayer easy to use from Kotlin (hence all of the nullness annotation work we've undertaken). It's unclear how this is directly related to what language we develop the core library in, however. Yes, that's the main pain point. And yes, it's correct that those using OkHttp 4 will already be pulling it in. That's why OkHttp 4 adoption is a good data point for us to keep an eye on. Regarding the ExoPlayer OkHttp extension specifically, I can say that adoption is tiny relative to adoption of the core library. There's no technical reason not to use Kotlin for tests, but I don't agree that it's beneficial to do so. It effectively requires developers to understand two languages before they can do anything, rather than one. I think there needs to be a bigger payoff than being able to use Kotlin syntax in test code for that to be worthwhile. This argument gets floated a lot for tooling that might make the development team's job a bit easier. You can make a similar argument for insert your favourite dependency injection framework here, AutoValue, other annotation processors and so on. If you're developing an app then this argument often makes sense, but the same is not so true when you're developing a widely used open source library that a large number of developers from different companies need to dip in and out of. The more tools we use, the harder it is for developers to do this. Some development inefficiency on our side is a price worth paying for keeping the code accessible to the widest group of external developers. This doesn't mean that we we'll never adopt additional tooling, but it does mean that the bar for adoption is significantly higher than it would be were we developing an app. The  class has grown into a bit of a mess, and adding a new field is indeed very painful at the moment. However it's a stretch to say that Kotlin features are important for fixing it. There are ways to rewrite  in Java that would also solve the problem. We also had an internal discussion where AutoValue was mooted as the solution. We've considered doing this, and I agree that it seems like a much better approach. We didn't see any compelling reasons or use cases to prioritize a more in depth investigation, however.
Would be nice to have a test for this class, but otherwise, LGTM. 
Thanks , please consider reviewing the polish commit when you get a chance.
yup and that's how I've found out about JOOq's error page :)  There isn't a valid link that matches the version AFAIK, e.g.  is there a way to make that happen?
A tricky thing here would be to detect, whether a user explicitly wants to have HTTP/2 enabled on Tomcat ‚Äì in that case you probably want to show the error from Tomcat that helps with properly configuring tomcat-native ‚Äì or whether HTTP/2 is enabled by default. In that case you want to avoid the error message and silently fall back to HTTP/1.1.
You'll likely want to take a look at the newly merged  as well.
Thanks again!
True, but I'm hoping that we (or I) can fix that. I'm hoping that having this version specified in the BOM will be a step towards resolving 
-nflx That's honestly a bit unfortunate, but that's a bit interesting as you can reproduce this issue under just one Conductor server instance. While locking does indeed help solve problems, it really shouldn't be a problem under a single instance.
I concur. Also, I don't like the idea of having a path as the key of a map. This feels a bit unnatural to me.
Thank you for this feedback! That is a really interesting insight. You may be right! We will certainly consider it.
Since, we are not using RabbitMQ, we haven't been able to test this feature out. However, we would appreciate help from the community with testing this.  Please feel free to review the PR and we will be merging this soon. Also, paging  based on the discussion earlier in the PR.
Awesome! Thanks for your help  and quick feedback!
we'll take a look. Thanks for the PR.
Re:  I've stubbed out the first part - adding the headers to  - but it feels very awkward to have to pass them around everywhere, especially when it's already possible to achieve this for playback by using a  that provides the headers. I went through the HLS playback flow, and was able to get it working, but wanted to stop and check in before I started in on the other types of media source. I
Good catch, I've fixed that in 5d3ac53
I don't think so I am afraid. Having a bean with an empty registry is more confusing than the error IMO.
sorry for the slow feedback, the PR should now be ready for review. I am wondering if some more test cases could be added, I will continue thinking about that. I see the build is failing but I guess not because of my changes. I will keep an eye on  to see if a rebase if needed.
Thanks again  
Oh, not really. I see your point and all that I can say is that maybe I was considering only my own use cases, where interruption is really a frequent thing, and I may have thought that this class was intended just for those situations. But thinking more carefully, it does not seem unlikely to use methods from this class, for example, just to avoid the verbosity of having to deal with InterruptedException in situations where the thread is actually never interrupted.
, it's a good question - addressing all permutations can get pretty hard to keep up with for really not that much benefit. I think the critical logic to verify is   Does the endpoint resolution logic work?, e.g. does it correctly fall back, and Does it correctly parse the response into a .  I think these can be tested independently for the most part - I wouldn't imagine there being 3x tests, it'd probably be one (or some) tests to verify the fallback logic and another set of tests confirming the parsing logic against the oauth2 endpoint.
This PR only touches files on the  module,  took 23s to build for me. 
Thanks for the review and consideration.  We can close this PR then.
Thanks for the PR. This has been applied in efb699de608fa53a41fdf98229348d9c6e3cea47
Sorry for the confusion. Somehow I missed that antora markup was being used in the code comment. I think this makes sense and have merged it.
Got it, thanks for the fix. Will merge for Boot 2.0.
Sure, we have video that contains information for mid rolls in TXXX frames  (don't ommit custom-mdt param) you should be able to see some extra TXXX at the beginning of this video Because college of mine is working on iOS application, I know that extra information in TXXX frames are available. Those extra TXXX frames should contain keys like "duration" or "trigger" and those TXXX frames are there and are parsed correctly by parser but value in ID3 frames Map is constantly overwritten by last TXXX value.
ah I see, too bad :broken_heart: I'll work toward a stable release of SDC... a new version (at least a milestone) is needed anyway since we must rely on a Couchbase SDK release that is available on Maven Central (as pointed out by the CI error)... thanks for the :gift: of PR :smiley:, looks like there's a tiny bit more work to do, I'll keep you updated
Could you please attach the stacktrace? Also do you have an example application? I've tried to make the Jetty sample fail in the same way but without any luck so far.
thank you for making your first contribution to Spring Boot. Please review my comment on the duplicate PR you've created.
CLA is on file as Square Inc.
Was this PR opened by mistake on the source instead of the fork?
I talked to the Android Gradle Plugin team team and we think the  solution I provided right now is not very good. They are already looking into this use cases - a library having a JVM and Android variant - and they will probably make use of another attribute for it. We are discussing what the best solution here is. I would suggest we hold off merging until that discussion resolved. I'll get back to you once this moved forward, in a few days.
sorry, I just dont know that...
Thanks, , for the PR! This is now merged into  via 51b9b2f693ec48127f2cc8554aa3edbc58fccc92. Note that I polished the commit message just a bit, though it will still show you as the contributor. I added a small polish via 653400edfabf52760bdda3c30c8b51283b256b15.
Wow! Great findings! I will change the PR and fix the problem. I am so happy we figured out a proper fix!
During the testing of the patch I saw weird things with the stream reproduction, it seems that there are sync problems between the Audio and Video tracks, in live channels the video seems to stutter a bit (and I¬¥m almost sure that the frameDurationUs is properly calculated) ~~but in carousel channels, where there are bigger clock differences between the tracks, when the stream starts, the video is frozen while the audio is playing until the video timestamp surpass the audio timestamp. I think that it is related to the current player architecture and that it would be more sensible to discard the audio frames with a timestamp lower than the timestamp of the first video frame.~~ UPDATE: after analyzing the stream PTSs thoroughly, the PTS differences between tracks can¬¥t account for the observed delay in the video start, I¬¥ll try to dig deeper in the problem and check if I can reproduce the problem filtering the audio tracks. UPDATE2: the stuttering observed in the video is due to the RK3288 decoder in other android boxes the video is fluid.
Thanks for the PR. Unfortunately, AnsiColors should have been removed as part of removing support for image-based banners. I have opened  to correct this oversight.
If you have time that would be fantastic. It looks like Jetty and Undertow should be fairly easy. Tomcat.... not so much :(
(re: googlebot, i just ended up signing the CLA as my .com too.. seemed easiest.  didn't want to mess with potentially getting the pattern-match wrong.)
Thank you anyway, , and thanks too for the feedback in #16756.
Perhaps because you're not part of any org? If we want to continue investigating, let's do that on a dedicated issue on the CLA issue tracker. 
I accidentally did this PR on a super old branch and all the tests failed so I closed it and opened the other one (on HEAD).  My bad.  Apologies.
Is there anything left to do for me or do you need any additional information?
Sorry if I my previous comment is not clear.  It'd help to have an integration test for the case you've sent as part of Terminate task, for this PR to be merged. We have ported integration tests for Terminate task here:  LMK if you have further questions or comments.
Good idea, I'll update that. 
I'm unable to reproduce the failure from CI. Any pointers or is that unrelated?
You can also send your test stream to . It's somewhat hard to tell whether the issue is with the media itself, or with ExoPlayer (and if so, where), without being able to take a look. I'm pretty sure we have some SCTE-35 test streams internally that work correctly with the current implementation.
: Sorry, I don't have too much justification for the errors changes, I adapted kvaster's patch from #676 and fixed the tests.  I'm not entirely sure what that fix does.
Oh, sorry for the confusion, I looked quickly at the pom and thought it would always flow in.  Guava version mgmt has caused me some pain so wanted to avoid any possible future headaches. On Oct 16, 2014, at 2:23 PM, Biju Kunjummen  wrote: Okay, this is not a required dependency though right Mark, it is only when a project using spring-boot requires it and they explicitly add the guava dependency in their pom(without version) does this flow in. Agreed in principle with what you said though, I will go ahead and close the pull request. ‚Äî Reply to this email directly or view it on GitHub .
I've always found it a little weird that we have this duplicated. I think it's probably in the best interest of our users though to have it in both locations. SGTM.  If you create both PRs, I'll take a look at both and submit. I forgot that they were different branches on github
FYI 
Indeed, the cited comment in #2150 applies here too.
I consent.
yep, just make seekbar focusable and workable
I've signed the CLA. Why  produces diffs like: Did I use the wrong branch ?
I've upgrade to a version of the plugin that is compatible with Java 11. This PR is now ready.
Just leaving a comment here because i want to follow this PR. Currently we are being bothered with some sporadic ANR's. And i very well believe this could fix it. 
Thanks for the pull request. I'm not sure that we should silently filter out null entries. If an import has been configured with a trailing comma, as shown in the tests (), this is likely to be due to a typo. I think the NPE is preferable to silently hiding the mistake, but something that fails and describes the cause of the null entry (if we can figure that out) would be preferable to a NPE. Let's see what the rest of the team thinks.
has done some work for type annotations. That may be sufficient for your needs (though I don't believe there's been a release yet).
Thanks very much for making your first contribution to Spring Boot. I have applied the changes to 2.5.x and merged them forwards through 2.6.x and 2.7.x into main, picking up changes that were specific to those branches along the way. I don't think any of your improvements were lost along the way, but please let me know if I have missed something.
thank you very much!
Thank you, .
any feedback?
Since "Web Services" is a very generic term it would clarify that this indeed related to Spring WS. Much like chapters 37 and 38 refer to Spring Integration and Spring Session, not Integration and Session. Consistency argument applies here also.
Thanks for clarification in your previous response (although it seems to have disappeared somehow). I don't think you should modify  as part of this change. I'm not convinced it's a good idea to change  either. It feels to me that you're trying to work around a bug in the underlying CDM implementation on older versions of Android. The correct place to do that is probably . There's already a workaround in that method for the Widevine CDM, so you can add a second workaround there that changes  if all of the following are true:      That way the workaround will be applied correctly regardless of where the media is coming from (e.g. if another extractor implementation is used).
Hi  Thanks. Sorry my bad this was my first commit in code previously in docs, was on it but you were too quick. Noted henceforth will make sure to do the build. Thanks once again for the opportunity.
We managed to get someone else reporting this issue (#12716), and I forgot we had this PR. Sorry about that. It's now fixed in a657a28f58e0eb8487eede9c60062186d850408d
It is actually amazing that no else found this sooner.
Thank you for giving me this opportunity 
I'm very sorry. Should be fixed by now  
Thanks! I'll submit internally and a commit will reflect this when we sync later today!
Closed in favor of 
They all look safe but I think we should do this in 1.5. If nothing else it's another reason for people to upgrade.
removed logging the exception in ZuulServletFilter. Also removed similar line in ZuulServlet. Added logging to the example ErrorResponse filter in zuul-netfilx-webapp.
I was looking at  repository and seems that adding the following dependency the example will work. Do you think this would be fine or the original PR is the right approach to handle the neo4j version's server?
Very nice. Thanks very much! I've taken the liberty of splitting the PR into a number of distinct commits and also backported a couple to 2.7.
Not a problem  . This is why we call these "code proposals"  üò∫ . The effort was minimal and I learned a little something along the way.  The struggle I had was between creating a Spring Cloud Stream Rabbit Binder (SCSRB) Rabbit config and re-using the Spring Boot (SB) Rabbit config.  Some pros/cons (mostly converse of one another): Re-use the Spring Boot Rabbit config classes (+) DRY principle  (+) parity sync - the SCSRB will use the same Rabbit config code as SB (-) violates the  principle (-) tightly coupled, another integration point to SB Create a Spring Cloud Stream Rabbit Binder (SCSRB) Rabbit config  (-) duplicates the SB Rabbit config code (-) parity drift - the SCSRB version will get out of sync w/ SB version quickly (+) does not violate the  principle (+) less coupling I think the false assumption I was making is that the SCSRB version needs to have all the config knobs the SB version has. If this is not the case then the argument above for "parity / lockstep" can be thrown out the window. Identifying the minimal set of config options needed by SCSRB would be a good start.  As you suggested, I will comment on spring-cloud/spring-cloud-stream-binder-rabbit#187 when I have other ideas. Also, the fact that the binder service config looks like it will be largely re-worked, this Spring Boot auto-config aspect of it may not exist once that happens.  Thank you for the quick turnaround and feedback.
Great - I'm on it. On Wednesday, December 9, 2015, Andy Wilkinson  wrote:
The related change has been done and tested OK, could you please have a review? thanks!
I don't think that logging the information via the banner is the best way to make it available. Personally, I'd use the Actuator's JMX support and the existing info endpoint. I still believe that applications where the Actuator isn't available in any form are a niche. A builder is an improvement from an API perspective, but it doesn't do much to reduce the additional internal complexity that I am still not convinced is justified. It also leaves the banner with knowledge of build info and git properties. Those are currently only dealt with by the Actuator so the proposed changes introduce a conceptual cycle between those two modules.
Damn, I'd have a longer sleep if I'd just wait for you to answer :D I wrote  class and was trying to write some tests of  from scratch. After about half on hours I found out that there already is a  class without missing 's'. After that I thought that the first thing should be writing a test to test well... a test. Which was to test if  is set correctly: public void InMemoryXmlWebApplicationContextRunsWithNewestXSDAsDefault() throws IOException {     InMemoryXmlApplicationContext defaultContext = new InMemoryXmlApplicationContext("");     String computedXSDVersion = getSpringVersionFromSpringSchemas();     InMemoryXmlApplicationContext versionedContext = new InMemoryXmlApplicationContext("", computedXSDVersion,             null);      Resource defaultXML = Whitebox.getInternalState(defaultContext, "inMemoryXml");     Resource versionedXML = Whitebox.getInternalState(versionedContext, "inMemoryXml");      assertThat(defaultXML).isEqualTo(versionedXML)             .withFailMessage("InMemoryXmlApplicationContext is not using a current XSD schema as a default"); }  Than I was trying to find out how to test it without  and without getting direct access to the . Then I thought it's really time to sleep, so I turn off my PC and... read the message from you on my phone :-)  If you say that  should be computed, I'll do that. If I'd ammend a commit on forked repo, push it (with ), will this force a test retrigger here on this PR?
Unfortunately not, because I am not able to build spring-boot locally right now. Will rework the PR as soon as everything builds and tests run locally. Maybe  can look at the PR in the meantime (and has probably a better idea how to test the mapping). 
I did try to restore the anchors with two values (using this SO answer but that didn't really work as expected. Given the link is broken for quite some time anyway I went ahead and remove the outdated duplicate. Thanks for the PR!
This commit is not so efficient because  is always called. However I think this is enough because it's easy and this functionality is usually not required to perform fast.
Hi,  I have reworked my commit so that it implements a generic MediaCodecParameter messaging between the application and the exoplayer renderers. The new MediaCodecParameters class defines the DIALOG_ENHANCEMENT_LEVEL Key and should be extendable with any other codec parameters. In this commit only the audioRenderer has been modified to manage the message.
Nice, thanks a lot! 
Fixes #1146 
Hi ,  Sorry I was busy recently. I read that you would like to improve the documentation later. But maybe it could be useful even for reviewer to better understand how this functionality works üòÑ  Anyway, thanks a lot for your efforts to complete this PR. Could you try to fix your commit with the comments provided by -nflx ?
Thanks for taking a look! Oh, I was convinced we skip javadocs by default, but I see it makes sense to run them after the integration tests if we also publish them on each commit. I agree that punishing 17+ -using users and requiring a 3y-old JDK is not good :) What do you think would be the best thing to do: 1. Support correct Javadoc generation on all JDKs (8, 9‚Äì12, 13+): requires a JDK-version activated Maven profile, like in this POM):     - (+) Don‚Äôt depend on migrating all our release scripts to 17 ‚Äî can fix this issue right now     - (+) Will produce correct Javadocs on all JDKs     - (-) / (?) A bit of extra complexity in the configs, but not too much     - If we eventually accept that JDK 17+ is required for development, and javadoc generation is not needed on earlier JDKs, it is a temporary measure. 1. Skip Javadoc generation on 8 and 12+ (conditionally set maven.javadoc.skip through a JDK-version activated Maven profile):     - (+) Don‚Äôt depend on migrating all our release scripts to 17 ‚Äî can fix this issue right now     - (-) Same complexity as ^, but less benefits 1. (If you anticipate that 17 issues will get addressed soon) Wait till migrate to 17:     - (+) No changes needed , no extra complexity in the configs     - (?) Search won‚Äôt work on Javadocs generated with 11, but, arguably, it won‚Äôt matter
Despite us repeatedly asking you not to, you continue to close and reopen the same pull request. I'm now blocking you from this repository.
To reproduce, and see that the outline is painted with the foreground color: either manually change user captionning style Launch Captionning manager, switch caption style to custom (last row radio button), then select Edge Type -on tv, enable then disable Show background to workaround an initialization value bug in leanback, on phones select no background then back back back or you can programmatically do (my codebase is in Kotlin) in library/ui/src/main/java/com/google/android/exoplayer2/ui/PlayerView.java:449 Test in exoplayer demo in Subtitles -
~ looks good? or needs more changes, I am bit confused with the implementation üëÄ^^ related to Issue #9797 as well.~ will make it ready for review post verifying again, this doesn't seem to work :(
I tend to agree since there is a lot of different ways to configure Jackson, and this one is IMO the less relevant. It only allows to configure 2 properties that could be configured thanks to the spring.jackson.* ones or thanks to a  . Also, current implementation also has some unexpected side effects, cf. this PR I created yesterday: . ,  Would you consider removing  before 1.2.0 release ? It may have some impact on Boot 1.x apps, but it could make Jackson configuration and documentation more obvious, and could avoid some strange behavior like the one described in his previous comment by  or in my PR  ? We could just explain in the release notes that apps using http.mappers.* properties should now use their spring.jackson.* equivalent. Last argument in favor of removing it, current property names (jsonPrettyPrint, jsonSortKeys) may be confusing when using Jackson for XML serialization.
ACK, the autoconfiguration part should work out of the box.
Fixed in  . Not required anymore.
Is there anything else you'd like me to do? Thanks again
Thanks for re-sending this! We will figure out a way to get it merged.
thank you for making your first contribution to Spring Boot. Well done writing a test for testing the default, although we already had one. It is interesting we had the same chain of thoughts! Turns out those two tests are identical and  wrong since they assert the outcome of the auto-configuration rather than the actual default in Spring Kafka. I've moved that test where it belongs now. Thanks again!
Squashed all my commits into one. and for commits messages I am already following convention stated in guideline of:
Thanks for your contribution. I'm trying to verify these changes locally by running , and have been running into issues launching the UI from local. Here's my error stack trace: Also, here's my gulp details after running : Let me know if I'm missing something.
Thanks for the PR but we already have #33654 for this.
Merged in 678f36cfefc7 (any chance the defaults could go in a parent pom?).
Thanks again  
I've bumped Spring Boot 1.0.2 to use Codd SR2 but I'm going to leave the BOM out of the 1.0.x lines. We'll merge this into master when it jumps to 1.1.x.
Closing in favor of #14793
I'm somewhat unclear what the aim is here, or exactly what the desired workflow is. If you want to depend on a local snapshot, why not just build the .aar and then do "File -> New -> New Module -> Import .JAR/.AAR Package" in Android Studio? Please clarify. Thanks!
 Remove the test stream I was a bit confused about what happens with unsupported regions in the current implementation. Am I right in thinking all text content gets assigned to the anonymous region id (see , specificall the switch statement case for ). The generated cue will set everything to "unset", and it'll be left up to whatever UI component ends up drawing it to decide where to place it. Is that correct? If so, can it work in the same way for bitmaps as well? You probably need to modify  to do something sensible if  to make this work properly. I would expect some tests in  checking that the right thing is output from the decoder at least. Probably one for the bitmap with unsupported region case as well. 
Nice idea, thanks! I think Mock MVC should be used a lot more in the samples.  It's particularly useful as a test of Views that actually render out of container (like Thymeleaf). Have you filled out the individual CLA (link in CONTRIBUTING.md guide)?
Sorry, I'm still not keen for a couple of reasons: - I can't see much benefit in externalising this configuration - It's less concise than the Java API In short, I think it's adding the cost of there being another way to achieve something without any benefit.
Thanks very much for the PR. I've merged it to master and also restored the same behavior for Jetty and Undertow.
Precisely, Java 9 has introduced that the  may be used only with  without   That's why I closed the PR  #2275  and open this one :)
Duplicate of #20547 
Thanks for the PR. Unfortunately this seems to break one of our tests. I've reverted for now and opened #7810 to investigate.
Hmm, maybe samples should not be updated to , it has side-effects on the execution graph of the reactor build (i.e.  will not build the annotation processor but will instead resolve it from the repositories). See  for details. It's also worth waiting for version 3.6 of the maven-compiler-plugin that will fix the incremental build issue introduced in 3.2 (three years ago or so). Feel free to close this PR following those findings.
I've logged  to outline Hazelcast IMDG Client & Server and Hazelcast Jet Client & Server, with a link to sample project on github -  I'm happy to make a fork to fix the issue myself, but just don't want this to clash with work already underway for this issue. Let me know what you'd prefer.
I need to move on to some of the more pressing bugs so this might need to take a back seat for a while. I'm still hoping that we can get it in to 1.3.
Great, thanks  ! I looked into your changes to learn the style... what do you mean by  Just curious :)
See #3223 for details.
Oh sorry for that. All the groovy tests pass with gradle 4.4. But indeed, using the pluginManagement stuff in settings.gradle for snapshots only works since 4.10. Using the  block instead of using  to apply the plugin is important for Kotlin, because otherwise, none of the extensions provided by the plugin are available in the DSL. That's why I chose to use that consistently: almost the other Kotlin samples would fail if the plugin was not applied using the plugins block. So maybe I can  - make a separate PR that only removes the usages of the deprecated configurations  - rebase this PR on the new PR (to avoid using the deprecated configurations in the new kotlin samples)   - add an introduction saying that the Groovy samples are compatible with gradle 4.4 and above, and that all the Kotlin samples are compatible with gradle 4.10 and above  - leave all the samples as is, except the 2 snapshot and milestone samples of the getting started section. For these samples, we can provide two sets of samples: one only for groovy as it was before, that must be used for gradle versions less than 4.10, and the ones I introduced that can be used for version 4.10 and above. Please tell me what you think.
thank you for the PR! As mentioned above, these changes are not passive. Do you have an alternative solution that does not modify the method signature?
I Followed the instruction and now only one commit is visible. Thanks
Thought about opening up all of the available options, but decided against it to increase the likelihood of the change being backported. 3.x is unfortunately far away for most of these applications. But it would be definitely better to offer all of the configuration options in the future
Yes but the problem is that you're not providing a path in your configuration, you are providing a placeholder that's going to be replaced with the database that you are using. If you are using two databases and one of them does not need specific scripts, the startup will fail because the directory does not exist. It means that the use case of this feature is quite narrowed IMO: all the databases that you support must require database specific scripts. Does that make sense?
Thanks for the explanation. In the future, I will not review the coding style.
 Could you please attach or send us a sample media file? Thanks! 
I'd say the answer to both questions is yes. Regarding registration by name, IMO registry should maintain a name, or key, for each of managed s. Take the  as an example of registry user - originally it contained  which is again a map of s. If  has a key to reference some , I'd expect to be able to use the same key for that indicator in other parts of the system. Invocation of indicator does make it two responsibilites, but it also seems somewhat natural, doesn't it?  Having invocation service separated from the registry IMO seems more complicated for the users. Do you see any downsides of this approach?
Thanks for the contrib  
How do you do deserialization,  e.g,  abcdefghijk -> ?
Thanks, . I see the problem now. A number of the  files in Quartz 2.3.0 use a comment prefix other than . To support this, the property needs to be added to  and then honoured in . Would you like to update this pull request?
Our rule of thumb is that we don't change a minor version in a maintenance release and I consider the move from RC1 to RELEASE to be a maintenance release
In order for us to consider it, you have to sign the CLA. Please follow the instructions above.
One small difference, i just fixed it by removing 'IF NOT EXISTS' syntax. Mysql DDL can't support 'IF NOT EXISTS' syntax, but it works fine for miradb, and the syntax for #1280 is also for miradb.
Thanks for feedback. I haven't really thought about this, it's been a while now :) But looking at the fact that you would prefer returning an empty string, here is how it would look Which would lead to; Which is bad too IMO. As a security library, I finally think that it simply should fail by throwing an exception.  Anyway, the decision is yours, and I can adapt the PR if still needed. Otherwise, feel free to close this issue.
If you're going to fix the Javadocs, you should fix the original source code, not the generated output.
Thanks for the feedback. I have reviewed your suggestions. The default values now match those of RabbitTemplate. A test ensures this. I am not sure whether the test is the way you would want it though. Let me know if you want me to refactor it. I have removed "The" from the descriptions to match the existing style. If you have any further suggestions let me know and I'll be happy to review them.
I've updated the PR to use the latest 4.9.0 driver, which allows for a simple Customizer bean to enable metrics on the session. I've also added a driver config Customizer bean to siwtch driver metrics from Dropwizard to Micrometer and enable all of the driver metrics.
The changes seem good to me. Good unit test coverage.  Perhaps this should be canaried before release though to ensure both functionality and performance has not impacted existing high-throughput use cases since this changes the guts of a hot code path?
Please don‚Äôt use our repository for testing GitHub‚Äôs pull request functionality. It‚Äôs a waste of time for all involved.
I'm closing this as it appears that it was sent by mistake since there are no files that have been changed.
See discussion in #3301
My main concern is that it will be standardized using some other attribute name or mechanism, that we'll have to change it, and that we'll end up annoying a bunch of people who have come to rely on it. So I'd feel much happier if the approach were documented somewhere. You could file a request asking guidance to be added to the DASH-IF guidelines here or here, for example.
Thanks for the suggestion but we don't want to do this ad-hoc and adding equals/hashCode on all  type can be tricky. 
-nflx    I have made a few more changes, can you please have a look? As for conductor 3, I'll open a seprate pull request soon. Also, do you have any idea why the integration tests for sqlserver are failing? They are working locally and I'm clearly setting the maxPoolSize here
Thanks,  , for feedback! Even if my preference would be do not encourage end-users to use  when they build Spring Boot application, I would say during the migration path, when they already have that file, it would be really beneficial to see those properties in the . So, yeah, I will add respective  today to re-map  to the appropriate  entries to have a proper merged instance in the end.
Okay, I have pushed my amended commit and the pull request appears to have updated automatically with my new commit. However, I'm very confused. I made one push, not two. However, there are two commits there. One of them has a comment "Merge remote-tracking branch 'origin/master'." But I did not write that comment or make that commit. And the contents are confusing. Can you just ignore it? I can't seem to make it go away. All you need to worry about is the new "SEC-2002: Added events to notify of session ID change ...". I swear,  was way easier... :-(
Thanks, , but we prefer to apply this sort of one-line version upgrade ourselves. If we've missed an upgrade that you feel is important, please feel free to ping us on Gitter or Slack to give us a nudge.
closing since MessagePack hasn't supported Jackson 2.9 yet
Thanks for the suggestion, but having reached RC1 it's too late to do this for Boot 2.2. We'd also need to be sure that the rest of the portfolio, such as Spring REST Docs (), is compatible with REST Assured 4. We can consider this again once we've started work on 2.3.
Sounds reasonable, thanks. Would you also:   Add your tests for the AssertionError cases   include the 2 input ranges in the exception message  
Hey thanks for pointing that out. Another way is by forcing OkHttp to request the full file each time using a network interceptor and removing the  header that ExoPlayer uses. Then you'll get 200 responses instead of 206's, which OkHttp's Cache will handle. I'll update my other comment for posterity.
The idea is that repackager may do other things than messing up with archive layout. In may populate manifest with custom SpringBoot metadata, for example. So you may not want to disable it completely. My understanding was that NONE layout is used in unit testing and has no real world application. Anyway, let's wait for what  has to say.
SDG in Hopper is fixed on 8.2.0. GemFire versions do not work the way Spring project versions do, unfortunately.  I.e. GemFire versions do not follow a logical  cycle as one might expect.  There are in fact versions such as 8.2.2.1, etc along with additional hot fixes (e.g. 8.2.2.1_01 for specific customers)  Fortunately, those versions are not available in any public repo and I do not support those in SDG. Additionally, a GemFire dot dot release can include interface breaking changes and/or other source and runtime incompatibilities.  The only thing GemFire guarantees between dot or dot dot versions is binary protocol compatibility between peers and client/server, so that a customers cluster and clients continues to function as before with no disruption in communication.
They are indeed without the recent improvements as I was testing specifically with 1.5.9.RELEASE and to my shame overlooked these. Thanks for pointing them out! I hope the PR still gets accepted to enhance the cases were we can't early out.  I generally use JProfiler as a first step to fire-up my JAR for those profilings and take a look in the java -XX:+UnlockCommercialFeatures -XX:+FlightRecorder -XX:StartFlightRecording=duration=30s,name=startup,settings=profile,filename=startup-boot.jfr -jar path\to\my.jar`
Did you sign it using your github name? I can't find a record of it in our system. Thanks!
I remember why I didn't support  in . It is a Neo4j 3.0.0 specific thing and it wasn't available at the time we implemented the feature. I am a bit confused. I see no indication in your PR that Spring Boot provides dependency management for the bolt driver. We don't have dependency management for  which looks suspicious to me. It isn't used anywhere in the codebase, not even in a sample. What did you add to your own project to use it?
can you send this against the  branch? 
We're going to need the code as the source of truth so we need to migrate these edits either way. I've made a start here.
Looks good to me
 For what it's worth it is possible to transmux MP4 to TS at the CDN level, and I think some CDN providers support this. Quite a few major streaming providers have moved to DASH now, and I've yet to hear any negatives. Quite the opposite in fact. The CODECS attribute is optional, and even with it I don't think there's enough information to properly reconstruct the codec specific data. From an ideological point of view I think I'd argue that you should penalize legacy formats (and devices that require them) by preferring to evict them from the CDN, but I acknowledge that this isn't a particularly practical suggestion ;). Since Android doesn't support AAC Main we'll likely "fix" this issue by blindly mapping audioObjectType == 1 to AAC LC and hoping for the best. I'll push a change to do this soon. 
It's better for us if you can add some comments to the pull request/issue, it's sometimes hard to follow the reasoning if we need to look at the code. I think I get it. If the user specifies an  directly, we should back off?
Thank you for the PR. Actually  takes precedence over so I've added a separate entry to make that more explicit.
Perhaps we can run though the classpath and directly add the additional JARs to . I'm not particularly keen given the current release schedule. How badly do you need a fix for this? Is this specifically for the Cloud Foundry build pack? I wonder if an alternative property might be a better solution. Similar to  on the .
I have updated the review, if there is anything I missed or something else you noticed, please feel free to do a polish commit to get this into 5.8.0
Thanks for making this, it looks good to me so I'll go ahead and patch it internally.
I was wrong in my previous comment. Sorry for bothering you.
Thanks for feedback .  sorry for the delay, comments have been applied.
I have modified the commits myself and pushed them to master. I also modified the regular expression slightly to more eagerly terminate. I used your test cases, so left  as the author on them but updated the commit message to conform to the contributor guidelines. Once again thank you for your submission.
Thanks very much, . This was solved as part of the effort to migrate to Spring Framework 6.0 .
Yes. People can enable this checking by compiling with . We could indeed add  to the various  files, and we might yet do that, but it could potentially be a bit intrusive. I've updated all of Google's internal source code to add the appropriate  but I'm not sure I want to impose that on external users.
Looks like this was opened by mistake.  please use your own fork for experiments.
Thanks again for the PR! Another PR please. This one is an optimization and what you've described is quite different. 
Sorry, "each method" was a little imprecise. I should have written "each method that's relevant". Assuming that we can identify a relevant method programatically, my hope is that it would be possible to test that there's a corresponding top-level function for that method.
The  is usually a singleton bean in the context, but we wanted to allow users to provide further customization at injection time. For example, you might have something like this: If the builder is mutable then it's possible that  is called before  and  gets unexpected basic authorization configured.
Actually I did not. Now I did. The facts make sense in my particular context. Thanks for pointing me to that discussion! I actually tried to migrate some code from an HystrixCommand to an asynchronous callback like code. Therefore, as mentioned, the observable is already matched on a pool. 
Thank you and congratulations on your first contribution!
Thank you for your contribution ! We are so lucky to have community members like you :smile: 
Thanks! I agree with the principle. I had a couple of small comments. Another approach that would avoid having so many  annotations would be to have a second, package-private  constructor with a dummy parameter, and use that in the subclasses. But I think  is probably better.
It's my first commit here. Did I do everything right?
Thanks for the PR. Merged into 1.3.x in 7ba16e37e812e714425593ea11c66fab3899df92.
thank you for your contribution. I've polished it to prevent users using the (now) deprecated host property to get their host/port configuration ignored (which is a smell of you having to add an empty broker-url property here). We now rather check if no broker url is set by the user and if a host is set we configure as we previously did. Of course, if a broker url is set, we'll always use that and I've added an extra test to validate that scenario.
Thanks! Updates in progress. I have issues with paint-on captions in general, as it does not make sense with digital transmission, character alignment and fonts any more. As each character was exactly defined how to look like and the character width was uniform, overwriting a character in the middle of the row did not cause any necessary repositioning of any other characters. But today, this is not true. I tested two versions:  - saving every text and modifying them before repaint: every character position to the right of the overwritten character is constantly changing: the text is not readable. - creating and showing a new caption over the first one: as character width is not uniform, the overlap is unpredictable leading to unexpected results. So, at the moment, I just hope no one wants to use paint-on mode any more... 
good catch, thank you!
Thank you for all your valuable feedback so far. When you have a moment, I would appreciate it if you can take a look at the updates in this PR and provide any feedback. Thank you.
I'm afraid that it can't.  offers a wrapper around commons-digest or Java 8's  class. We want to remain compatible with Java 6 and we don't want to force people to have a  dependency.
Of course, please do :) FWIW, I think AprLifeCycleListener should be always added, regardless of the status of the new http2 setting.
Looks like it. I switched the ci build to use Java 8. Can you rebase and try again?
That seems fine.  Ultimately I used this just to add outlining to the text so you can read it no matter what picture is displayed behind.  I'll make the change later.  Thanks!
Thanks for the PR, -orange! This is now merged into  with ab9a310485b43e7a5cd08e0ffba3cb641cb43991 and 69336fb3ec40e1c62ad1700e15fa0d6e03cb57d4. Also, I polished it the new section with 8b7751f5f400d1663b3a8f60885b1837983906ea to update some of the indentation and standardize the explanations to fit the typical writing style of the reference manual.
Thanks for the feedback . I agree that it should respect the content type encoding and not log non-string responses - I'm happy to update the PR for that. I understand your concerns but it would be great to see this functionality in Spring Boot as it's a requirement that many of my colleagues have come up with time and time again. I see it as akin to enabling wire logging in HttpClient. I'm open to any alternative approaches that would satisfy the same wire debugging use cases.
Hi -nflx, Indeed what I said in my first comment is not anymore valid. I succeed to expose metrics for Prometheus via micrometer (supported by Spectator) that has a sort of adapter for formatting data in a friendly format supported by Prometheus.  I tried before using Dropwizard but the metrics exported were not compliant with Prometheus data. Furthermore, I followed your suggestion, using Spring boot
Hopper RC1 has been released and we're using it. Isn't that enough to submit an updated PR? Please push force on this branch if you can to keep the history.
FYI, there appears to be a suitable test stream in , which also crashes (native crash in the MP3 decoder) using this patch. I suspect the codec configuration data is being parsed incorrectly from the stream, although I didn't check.
I understood the difference in thinking with you. You think that loadPlaylist from other parts is unnecessary while the tracker is functioning normally. Because there is almost no probability that a difference will occur at the time of reloading. However, I think that as long as there is a possibility that a difference will occur depending on the playlist distribution environment, I should reload it. Even if multiple trackers are activated by this correction, they are suppressed and converged in the next routine. My answer on the question, That was all it was. As long as you named "RefreshRequired" you should have the most priority other than the tracker. Your answer to this, And I have not obtained a specific answer. Do you consider Tracker's behavior to be the highest priority in any case?
I have updated the PR according to your comments, the remaining point is related to collection for signing algorithm. I keep list because of the order, but If you still think collection is better, let me know, I will do the change
Good catch ... sorry I missed this when I did  Merging now ...
Fixed via . Thanks for your contribution! 
As soon as the few minor comments are resolved, it will be merged.
This seems like a reasonable request for an environment with a dynamic set of commands.  I haven't encountered that case personally.  I think your point about possible performance degradation is good - calling the  method on every transition through each command's lifecycle could certainly impact performance.  For that reason, I'd like to work on getting a performance baseline set up with #578 first to actually answer that question. Also, if you could give me some context around why a dynamic set of commands are necessary for you, that would help me understand your use case better. 
External jars can also contribute endpoints so we need to find a way for the list to be extended by them.
sorry I didn't wait but I see no reason to as using  is not right IMO. It's not really about what you've described but more about formatting  the data. And when I need that (like carriage  return support, I use . Hope that makes sense.
I use this to annotate one plain test (not a ) with  to get: A mongo client and if available, Spring Data Mongo repositories and nothing else.  should also provide an embedded mongo db for those tests. I am happy to explicitly provide  myself because I have to add the dependency myself and assume that I know what am doing. But I want to have  enable it. I don't expect Spring Boot to solve that problem of random ports for me at that point. Spring Boot does not have to be smart about the port. The user has to take care if he brings in embedded mongo that the port doesn't conflict during 
Thanks for the PR ! This is now merged into master.
That's fine. I took a look at that and I think it will work for me. Is the filter documented anywhere? I never came across anything.
Thanks -silveira!
Thanks .  I'm going to try to summarize your changes, to make sure I understand what you've done and the implications.  Please correct anything I get wrong. There are 4 cases: 1) No concurrency strategy supplied, HystrixRequestLog or request caching are on (default) 2) No concurrency strategy supplied, no request functionality needed 3) Custom concurrency strategy supplied, HystrixRequestLog or request caching is on (default) 4) Custom concurrency strategy supplied, no request functionality supplied I've added unit tests in #953 that demonstrate the custom concurrency cases. In master without your PR, the situation is as follows: 1)  gets supplied on the first lookup to resolve .  If an initialized context is found, it is used for the request log.  If not, then the request log is null for the command. 2)  gets supplied on the first lookup to resolve .  The request log is unconditionally null for the command, since the request log is unwanted. 3) The custom  is found when accessing it for the first time and cached for the JVM lifetime.   and  must be called in order for command construction to succeed.  Without that, the call to resolve  throws an exception. 4) The custom  is found when accessing it for the first time and cached for the JVM lifetime. The call to resolve  would throw an exception but it is never made, since the requestLog functionality is off.  The currentRequestLog is null. After your PR: 1) Same as above 2) Same as above 3) Same as 1 above 4) Same as 2 above If I'm interpreting this correctly, this basically drops the distinction between custom and default concurrency strategies.  The only important bit is if the request context has been initialized.  If it has been, then objects that need request-scoped access (like ) work properly.  Otherwise, they are null. On the compatibility side, I think this should never change the result of any method call that was already returning a value. It will now return a null instead of throwing an  in cases where the  is null for 2 cases: 1) Computing  at command-construction time when  is null and custom concurrency strategy is used 2) Static access to  when  is null The 3 method calls that were throwing exceptions in #953 all return null instead with your change.   The downside to this change is that the immediate feedback of the  is missing when using a custom concurrency strategy, request log is enabled, and the request context is missing. This is also the upside, as it allows forward progress when request log is only enabled by default, and your custom concurrency strategy doesn't care about request context, and you've not initialized it. On balance, this seems like a good change and a good opportunity to document all of the above. Anything I missed,  /  /  /  ?
Thanks a lot for this decision . I am going to adapt this PR to take into consideration for 1) and 2). What about exposing  as a bean when the  is not present, but the  is. Will you accept a separate PR for 2.6 that will do this? I have managed to achieve what I need with 2.5 already, but the way I did it is not the best approach, since I am doing some nasty magic with , and I would rather get rid of that nasty magic we have.
Hm, no one has complained about this in a while, and we've moved over to bazel, so I'm gonna close this. If it comes up again, I'd be happy to entertain the idea of shading more.
-fine Unfortunately it doesn't seem possible to do either of the things that I suggested. It seems that  can never be registered programmatically via the Servlet 3.0 API (the way that Spring Boot currently does things). Looking at  in a little more detail it seems there might be other problems with that class. It appears to be making a hard assumption that WAR packaging is used (often not the case with Boot). I'm not too familiar with the internals of CRaSH, but perhaps we need an alternative to  that gets the  from a  Spring Bean rather than the . Spring Boot by default will auto-configure its own  class (an implementation that's tied to the Spring lifecycle). Unfortunately  is currently quite tied to . Perhaps the CRaSH team could extract a  method that you could then override. Otherwise you'd probably need to recreate that entire class.
Hi , thanks for your pull request! It looks good for merging, but before: 1414 requires support for custom tags (this can already be access via ). 1847 asks for support for a master playlist attribute (EXTINF is a media playlist tag). Note: Can also be obtained via tags. 2176 is about emsg, so I suppose it is not strictly related. Would you kindly explain the exact usecase for ? How exactly does it get used by an app. If possible, It would also be great to explain why  is not enough. Again, thank you very much!
Thanks   Thought I would share the snippet we are using for selecting the best stream based on current bitrate estimate.
Thanks for the updated PR! Unfortunately it looks like  fails. Can you look into fixing the test? For your convenience you can find the error below:
Thanks for the PR ! This is now merged into the main branch via 1cfe84922c9b26d08da4a2003777d1a82f7ce1e9.
Good catch, thanks!
I just logged #8536, which is the equivalent of the changes you applied in this PR but for the WebFlux stack. Let me know if you're interested and free to take #8536.
The message looks more descriptive. Thanks for your attention. . 
-ms  The  structure has to have the 3 parts or it's not a . So the existing class  is designed to spec. I guess I'm a little confused on why you would create a  without a  to simply provides overrides for claims? It sounds like you are thinking the  would look like: If that's what you're thinking then that is where the confusion is coming from. The return value is obvious  but the input will NOT be . This is what we need to iron out first before the implementation is started. As far as the way I see it, the  would take in client and resource owner constructs and additionally be configured with the target JWS alg based on the client input. Take a look at  and the configuration it allows for supplying a , eg. , ...we might need something like  (that can do overrides) I would suggest that you open up a Draft PR so we can decide on the API for  and keep the discussion going on there. Yes
Thanks for the quick feedback!
: I finally finished with what was asked. I still let the second commit unsquashed, since it takes the decision to avoid using  and do its own error message instead. I'm not sure that's the right way to do this so I'll let you decide. If you're ok, I'll squash the two commits together!
Subtracting one from the divisor didn't work because a/(ab-1) != 1/(b-1). Instead have done 1/ ( (ab/a) -1 ). Would easily extend/swap to  which replaces  in Torch 2.0
I wasn't aware of #15724. (i miss the typescript, damn ! ^^) And yes i clearly understand the "why" you did this, and why you won't. But to make easier parsing for batch/convert script this will be useful. Did you plan to split/remove this file ? Or re-export all import statement like in Materials intermediary exporter file (I think this is the target, no ?) ?  In case you go this way i could easily find/replace all ShaderChunk import by their real shader import and keep backward compatibility. Tell me and i will open an other PR for this purpose.
This occurred to me today and seems like having a method called  inside the  property will cause this error.
IMO: (1) No (2) I don't see a value in publicizing install size for this package. For something like webpack which is bloated beyond reason (10x the size of express according to the badges), sure, because it is a problem they have.  But that is not a problem we have. (4) Sure, I hardly ever visit the badge board so I don't have a reason not to lol.
would appreciate you reviewing this--you seem to have a knack for finding things I've overlooked.
I think the move here is to always initialize a new object for classes. The object pooling is a micro-optimization that doesn't matter in the grand scheme of things.
My concern was that node may not run because it may see ES modules even when they aren't used and complain.
re #10973.  and  are methods that, at this point, have good browser support and are standardized, so this PR adds support for Vue to observe mutating changes from those methods. <!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [x] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [x] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [x] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [x] All tests are passing:  [x] New/updated tests are included  If adding a new feature, the PR's description includes: - [x] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
something seems wrong with the CI -- my first submission of this PR had a failing test (and failed code coverage) and it still "passed all checks".
Thanks for the feedback! I'm glad this was well received :sweat_smile:  I didn't uncap the other extras because those shouldn't really be extras, they are development dependencies, for tests, docs, and local development. I should not have them exposed in the released versions/wheels. I plan on removing those extras that shouldn't be public and replace them with something else, probably  files with pinned dependencies that Dependabot can suggest to update later.
It seems to me that it was necessary to specify the step of creating the hello.py file, because some newbie may be confused, even if the creation of the file is implicit
, I'd like to share 2 things about semantic versioning:   It doesn't prohibit backporting to version 4. (I'm not sure, but from     your comment seems you imply semantic versioning prohibits it)    The current release is 4.2.13, the fixed release will be 4.3.0 - all according to the quote you provide.    Semantic versioning doesn't work for Java when we want an old version     of a library to be used simultaneously with the new version in one application.     Simply because Java doesn't allow several versions of classes with an equal     fully-qualified name. (In the same class loader. Using different classloaders,     as OSGI does, is an overkill unpractical in most real situations, of course. Honestly,     I haven't used java modules, but the impression they don't solve the problem     in a convenient way too, unfortunately). How often we need several version simultaneously? Almost always. First, dependency tree of any moderate size application has some libraries present in multiple tree nodes, with different versions. The second (more relevant for spring-security): migration easiness. We may want our old REST API endpoints to remain protected by spring-security 4, because it's already tested stable code. But for new endpoints, we'd like to use the modern, latest version 5. If this is not allowed, then we have a much more difficult "all or nothing" situation: unless you found resources to migrate and test your existing code, you must continue using version 4 for old endpoints, thus bogging down deeper and deeper into the old version, which has limited or sometimes no maintenance (in some large system I know some components still use spring-security 3).   In order to allow several versions of your library in an application, give them different artifact name (spring-security3, spring-security4, spring-security5) and different package names (org.springframework.security3, org.springframework.security4, org.springframework.security5). commons-collections, commons-lang use this approach In short - the principle of immutability applied to versioning, dependency management and backward compatibility. Here immutability of values (APIs) assigned to names (class / artifact names). If version 5 is incompatible with version 4, they should not share fully-qualified class names and artifact names.
-c I would really like to have it in 2.2. reworking the PR now. The thing is, our use case (however "not-ansibly") involves running potentially dozens of ansible-playbook processes each against a single node, but from the server-side component w/o human interaction. Unfortunately this one-node-per-playbook restriction is imposed by the outer framework we are using Ansible under. That is why being able to save even couple of CPU% is important for me.
Having such an artifact feels like more indirection. It would be easier to add the file yourself. I am closing this per  Thank you for opening the PR and discussing this feature, sorry to not make it in!
, actually, I really like  because that's what actually is (but we have vue's event modifiers too), maybe you could just do a poll with the members of core team to find out which one is reasonable? 
:+1: I don't know if this is the way I prefer, but makes sense. Also, it is easy to make  always return https, if this is what the user want.
38448
PR Summary MEP22 was intended to provide a way to customize user interactions, in particular with the toolbar via the implementation to "tools".  In practice, it remains currently difficult to add general customizations; for example, the color-vision deficiency simulator recently proposed does not fit in the MEP22 framework.  Moreover, there is no way to register MEP22 tools to be added to all figures. This patch proposes an alternative approach for toolbar customization: it adds a rcParam () which is a list of callables (actually, of "modulename:functioname" strings, so that they can be specified in the matplotlibrc file) that get called whenever plt.figure() creates a figure is instantiated; each of the callable gets the figure as parameter and can modify it as it sees fit (note that it is equivalent to pass the figure or the toolbar as parameter, as one can reach one from the other; passing the figure was deemed nicer). This makes it easy to distribute such customizations as plain python modules than can be installed from PyPI.  Also note that figure hooks are intentionally not applied when figures are created without going through  -- when embedding, one can easily explicitly call the hooks directly on the figure (this is one reason why passing the figure is nicer than passing the toolbar). As an example, the color-vision deficiency simulator is modified to use this hook (see docstring of the  example). The advantage of this approach is that arbitrary modifications to the toolbar become possible (here, adding a menu-in-a-toolbar), but this naturally means that each GUI toolkit needs its own code.  Likely we will need to provide "template" implementations that can be copied by third-parties.  (There is also some functionality currently only available as private API, as mentioned in comments; one such API is , which provides theme-dependent icon recolorization.  These APIs should be made public in some form, but that should be doable.) (One should check to what extent this approach is generalizable to the macos and notebook backends -- customizations to the former could possibly be implemented via PyObjC(?), and the latter via js injection?) PR Checklist <!-- Please mark any checkboxes that do not apply to this PR as [N/A]. --Tests and Styling - [ ] Has pytest style unit tests (and  passes). - [ ] Is Flake 8 compliant (install  and run ). Documentation - [ ] New features are documented, with examples if plot related. - [ ] New features have an entry in  (follow instructions in README.rst there). - [ ] API changes documented in  (follow instructions in README.rst there). - [ ] Documentation is sphinx and numpydoc compliant (the docs should build without error). <!-- Thank you so much for your PR!  To help us review your contribution, please consider the following points:   A development guide is available at .   Help with git and github is available at   .   Do not create the PR out of main, but out of a separate branch.   The PR title should summarize the changes, for example "Raise ValueError on   non-numeric input to set_xlim".  Avoid non-descriptive titles such as   "Addresses issue #8576".   The summary should provide at least 1-2 sentences describing the pull request   in detail (Why is this change required?  What problem does it solve?) and   link to any relevant issues.   If you are contributing fixes to docstrings, please pay attention to   .  In particular,   note the difference between using single backquotes, double backquotes, and   asterisks in the markup.   We understand that PRs can sometimes be overwhelming, especially as the reviews start coming in.  Please let us know if the reviews are unclear or the recommended next step seems overly demanding, if you would like help in addressing a reviewer's comments, or if you have been waiting too long to hear back on your PR. --
i just don't like how complex it makes the function due to all the type checking. very little people use this as well. why not just stringify it yourself?
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [x] Bugfix [ ] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [ ] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [ ] It's submitted to the  branch for v2.x (or to a previous version branch) [ ] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [ ] All tests are passing:  [ ] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
No need to call  every time  is called, cache the runtime object instead. Also renamed  to .
I should to say the script 'antd-tools run ts-lint' can not run when i run it on windows, so I change it run in mac, anyway i have fix cli fail  
 I took a stab at doing the rebase, check out .  There were some non-trivial conflicts in  and , so you should look carefully at the diffs between your version in  and the new rebased version.  Once you are happy you should do something like: 
/cc  
hey, haven't tried this before, but we could try this? basically, you write this in setup.py: that way, we do issue warnings when stuff's old and we don't require some random package version upon install. i didn't previously know you could do a requirements.txt` (for pip) file (i don't have an elegant way to issue warnings based on that file though... it seems like a messy way to do it, unfortunately)
It appears that you were able to take care of the rebasing? Just a small note that your name appears differently in some of the commits. CI isn't happy right now, but it is raising a cryptic error. We will have to try a local build to figure out what is wrong.
Fixed typos I saw in the Request Context documentation. <!-- Commit checklist:  add tests that fail without the patch ensure all tests pass with pytest add documentation to the relevant docstrings or pages add versionadded or versionchanged directives to relevant docstrings add a changelog entry if this patch changes code  Tests, coverage, and docs will be run automatically when you submit the pull request, but running them yourself can save time. --
could you have a check on this and perhaps initiate a review? Just curious when I can use this or what needs to change?
All PRs must either fix bugs, improve speed (>20%), refactor on a conceptual level (big line reduction), or add tested functionality.
Thanks! It'll got out the next time we update the docs.
Thanks, I don't think it's strictly necessary and having the value in a variable before returning helps sometimes while debugging, to set a breakpoint before returning. So, for now, I'll pass on this one. Maybe in a future, when I'm doing some benchmarks and trying to optimize the code I'll optimize some places like this, but for now, I think it's fine as it is, so I'll pass on this one. But thanks for your interest! :coffee: 
Hmmm hitting some pip-related snags:    These all seem to relate to unicode in the path name though, and i don't know where that would be occurring?
I was having this error for revision 1069273, then bumped to puppeteer 19.6.2, deployed to Google Cloud Function, and the error went away. Then a little later I did another deployment for an unrelated reason, and the error came back again on a new revision 1083080. So it doesn't seem that 19.6.2 fixes the issue.
Give me a few minutes. I'll take a look this morning.
It's OK since we have list  in our document. And we can override this prop.
This is ready for your review . Let me know if you want me to move the function  from  to .
Oops, I did working for this quite a while and did not notice another pull request #11605. It seems in progress, so please close this if we do not need this.
In C# there's an expectation that these comments parse XML tags within them, like `<summary Other than that, I don't see much of a reason to bother, since it's not like any other JS tools interpret comments like this? Like, I get that there's probably not much harm done by it (expect potentially confusing future SO questions asking why doc tool X doesn't read "doc comments")... But... Eh?
Sorry, wrong button üòÖ  mind rebasing?
That means stable JUnit5 support will only be available when mockito 3 final is released. I guess this will not happen before Q4 2018.  An other option is to release junit5 support as seperate mockito 2 addon artefact which requires java 8, like junit 5 itself. It can be released much earlier. What do you think?
-HD WDYT?
Ah... answered just here: 
and  are still using examples files from the  directory. This PR ensures that both scripts use modules. Since the ES6 module support in context of node is complicated, the scripts now require the usage of esm. Tested the change with ,  and . Sidenote: I also like to suggest to remove both scripts and refer to the editor instead. The project only provides for two 3D formats such converters which is somewhat inconsistent. Besides, even the current implementation of  does not cover all features compared to the browser version and requires some ugly monkey-patching so textures can be handled. Not a proper solution, IMO.
Okay, permissons are not copied. Maybe it is enough to check for Unix OS/POSIX support:
Hmm, it's strange that it would be due to #32856, because it's failing inside  before the location that was changed in that PR. Maybe the  causes it? 
Yes. I got distracted but I'm adding tests now to wrap this up.
Thanks for the contribution ! :cake: :coffee:  And thanks for the reviews -hub and  :bow: :coffee:  As I couldn't push to this branch to fix the extra files, I did it in this new PR (), it even preserves your commits. :nerd_face: 
Summary Generates a single tag when the parameter is a string, such that  generates tag test instead of t, e and s. An alternative may be to reject such parameter: see #4525. Motivation I often use a single tag in my routers, which even the documentation states is very common. When I include a router in my app, I often do the mistake of using a string instead of a list, which generates a very weird result, as seen below:   This lead me to try implement a fix for this itch which often annoys me. I don't know how often it happens to other users, but I find it hard to see a use case for the current behavior - hence the PR. Description In this PR, I test if the object is an instance of string, and if such convert it to a list with one element. This results in a single tag, which is the correct behavior in my opinion. See example below for the same code:  I also added tests and updated some single-tag examples. Request for comments I'm a first time contributor, so comments are welcome. Specifically: - is this a desirable improvement? - could there be unwanted behavior which I'm unaware of? - should we update documentation to mention that strings are allowed? - do these tests make sense? I would also consider the alternative of raising an exception when the parameter is a string, to force the user to use another iterable such as a list or a tuple.
I'm not sure why some tests are failing. ~~I added a new parameter to the init-function in . I updated all references I could find to also use the new parameter. But still some tests () are failing, because the new parameter is not applied. I would need some help to figure out what the problem is.~~ Another test that is failing is: . I find it is a bad test, because it compares the generated output 1:1. The test will always fail if the code would look slightly different. It does not test any functionality. As I can see currently only tests like these fail. Can someone please help?
Ah yes.  I had IndexError and a more exact boto exception being captured previously.  I've since changed it as requested. Apologies, I'm not sure I understand the question.  How do you mean "two stages"?   The variable  is (and was previously) used to track the number of instances where termination was requested.  The variable  is a count used to indicate the number of instances referenced by  where . Also note, the logic around  was largely duplicated from the existing logic within .
I found this bug. The property "options" is of the same type of its parent, not making sense.
<!-- Thanks for submitting a pull request! Please provide enough information so that others can review your pull request. The two fields below are mandatory. -- <!-- Please remember to update CHANGELOG.md at the root of the project if you have not done so. -- Summary We OOM if we run the entire lint run with type info (see ), so I've added a script. We have a toooooon of errors, so I just fixed a few of them. Should chip away at this when people have time üôÇ  This is somewhat annoying as IDE integrations etc won't apply, but better than nothing <!-- Explain the motivation for making this change. What existing problem does the pull request solve? -- Test plan Added CI run <!-- Demonstrate the code is solid. Example: The exact commands you ran and their output, screenshots / videos if the pull request changes UI. --
Thanks for your feedback,  and ! Now all identified issues should be fixed.  TODO: Add support for multicite commands. TODO: Expand integration test. 
This makes debugging the reason for the error much easier, e.g. in keycloak / OpenID. Before the patch: 400 Client Error: Bad Request for url: <url After the patch: 400 Client Error: Bad Request for url: , response body is {"error":"unauthorized_client","error_description":"Invalid client secret"}
Instead of . The conceptual model is that the only difference between sync default updates (in React 18) and concurrent default updates (in a future major release) is time slicing. All other behavior should be the same (i.e. the stuff in ). Given this, I think it makes more sense to model the implementation this way, too. This exposed a quirk in the previous implementation where non-sync work was sometimes mistaken for sync work and flushed too early. In the new implementation,  is only used for truly synchronous renders (i.e. ), which should make these mistakes less common. Fixes most of the tests marked with TODOs from #21072.
I can confirm that the problem still persists with "abstract: LaTeX cleanup" enabled in version 4.0.0-dev. Every time I enter \%, it is immediately changed to % and % ends up as % in the bib file which causes LaTeX to fail.
/ping 
Fix #3674 If using globals, check for template_scope for bindings as well. Before submitting the PR, please make sure you do the following  [ ] It's really useful if your PR relates to an outstanding issue, so please reference it in your PR, or create an explanatory one for discussion. In many cases features are absent for a reason. [ ] This message body should clearly illustrate what problems it solves. If there are related issues, remember to reference them. [ ] Ideally, include a test that fails without this PR but passes with it. PRs will only be merged once they pass CI. (Remember to !)  Tests  [ ] Run the tests tests with  or ) 
Thanks for finishing the work on this PR   - looks good - and a big improvement over the default GitHub Pages 404. The footer looks much better - thanks  ! I was thinking it might not be a good idea to include a search as a user might have been looking for a Bootstrap v3 class in which case the search (if it was search for v4 may not show results)... and if it were to combine search results for all versions it could get confusing.
Related to #8583  This is just the start. I'd like to dynamically pull in versions some how, and  mentioned renaming  to , but it accomplishes most of what we need (I think). Next step would be to create a basic template for a fixture.   Should we start working from a branch other than master? I can't do that, but I'd be happy to adjust the base of this PR to a  (or whatever) branch on the main repo.
<!-- Thanks for submitting a pull request! Please provide enough information so that others can review your pull request. The two fields below are mandatory. -- <!-- Please remember to update CHANGELOG.md in the root of the project if you have not done so. -- Summary Fixes #3879. I absolutely hate this solution. Maybe we should figure out a plan which allows us to run the test environment outside of the user sandbox? Would allow us to ditch the babel plugin, which is turning into a monster <!-- Explain the motivation for making this change. What existing problem does the pull request solve? -- Test plan The test that was never run will now run, and hopefully pass <!-- Demonstrate the code is solid. Example: The exact commands you ran and their output, screenshots / videos if the pull request changes UI. --
There are a few concerns I think we should discuss.  is public, and therefore deserves to be tested. I'm not too sure as to why it is public though. Suggesting it is not used directly, and therefore not need testing, suggests it should be private. Types influenced by  spans across a large number of api. Picking one or two for the purpose of testing that node type is derived from given selector is at best weak. Covering each and every instance where some selector depicts some type would be superfluous. Wouldn't we rather test  in isolation and take for granted that types built on top of it are correct, given the on top building are trivially simple and/or tested. Implementing tests along existing tests would suffer the limitation of              4. Unless types are the primary artifact of a library or that .d.ts files were hand written, it does not make sense to test .d.ts files, i.e. after compilation. Once types are generated by a project, it is the description of that project's api. Testing that the type of the api meets some expected type is questioning the spec, not the implementation. This does not dismiss the need for type testing. For the sake of organization, we would want to separate tests - including type tests, from the projects that implement them. For this I propose: Have a dedicated project  for type testing. This project does not emit any build. This project uses  for type testing. (Or other compile-time type testing utility) This project is the last but to  in the dependency build chain. If  fails to build (i.e. typecheck), build fails. Drop use of . Partly because of the above limitation. But also to put type testing in the realm of building.   
Please don't close this one, my other PR is just for whitespace! :slightly_smiling_face: 
 [x] closes #39347  [x] tests added / passed [x] Ensure all linting tests pass, see here for how to run them  I fixed all the issues raised by .  But one of the changes I've made led to some fails. After inspecting those logs I've identified that when I've replaced  with  at objToJSON.c, line 1399, to fix the issue , it led to these errors when it tried to build pandas  and .  So to make it work, I reverted  to  so that function will keep working as it was before, and, in , I added this new filter  to the list of filters so  will not raise the  error again. I also included this new line of comment:
Well, this didn't work... Will try pinning as  suggested. But, but, it is already pinned! :confounded:  Ah, wait, nvm, I confused myself. Nope. Pinning in intersphinx didn't fix the problem either. And I don't know why Travis CI ran even with  directive, so I cancelled it.
No problem! Do I need to fix something so that it auto-merges? The tests seem like they flaked out...
:+1:
It was discussed in the core IRC meeting today, that this PR should only add the plural (list) variables. The singular forms should be removed.
Apologies,  is not an exported function I think.
Avoids cluttering app.locals, and is consistent with the assignment of the "view engine" settings: The intent is also stated more clearly in comparison to:
This is really quite unexciting: #2431 had a tentative +1 from , pending a rebase and retargeting against 3.0.0, but it‚Äôs been sat unloved for nearly eight months. üò¢  This patch does the required rebase and targets the 3.0.0 branch.
You're right.  I'm trying instead to write a _gather() that mimics torch.gather()'s behavior that uses , a , and a  like you mentioned in issues 858. I'll then express , , and  using _gather() by reshaping the tensors a little. I'll close this pr for now, sorry. I'll reopen one when I figured it out.
As described in #17860, the import code fix for UMD modules has been updated such that it  - uses  import under --allowSyntheticDefaultImports  - uses  syntax where supported  - falls back to  syntax where necessary  - displays a diagnostic message matching the import that results from applying it <!-- Thank you for submitting a pull request! Here's a checklist you might find useful. [x] There is an associated issue that is labelled   'Bug' or 'help wanted' or is in the Community milestone [ ] Code is up-to-date with the  branch [ ] You've successfully run  locally [x] You've signed the CLA [ ] There are new or updated unit tests validating the change Refer to CONTRIBUTING.MD for more details. -- Fixes #17860 I'm not sure how to go about writing unit tests for this.
be careful about that, I heard people who hate spammy git diffs are getting fired from joyent (even those who never worked for them) ;)
This file is tiny, extremely simple, and should never change. So we're probably fine.
This was actually the original scheme I had in mind, but someone (unfortunately, I don't remember who) complained because this means the docs get re-built every time there's a new git commit (because the  variable changes).   Having said that, I actually prefer it this way (the way this pull request will make it).  So I'm happy with it as long as there isn't someone else strongly objecting.
The parameter  is no longer present in the latest version of the  constructor and the constrained layout cannot be selected in this way any more. There is instead the  parameter which can be set to  to obtain the same effect. PR Summary PR Checklist <!-- Please mark any checkboxes that do not apply to this PR as [N/A]. --Tests and Styling - [ ] Has pytest style unit tests (and  passes). - [x] Is Flake 8 compliant (install  and run ). Documentation - [N/A] New features are documented, with examples if plot related. - [N/A] New features have an entry in  (follow instructions in README.rst there). - [N/A] API changes documented in  (follow instructions in README.rst there). - [x] Documentation is sphinx and numpydoc compliant (the docs should build without error). <!-- Thank you so much for your PR!  To help us review your contribution, please consider the following points:   A development guide is available at .   Help with git and github is available at   .   Do not create the PR out of main, but out of a separate branch.   The PR title should summarize the changes, for example "Raise ValueError on   non-numeric input to set_xlim".  Avoid non-descriptive titles such as   "Addresses issue #8576".   The summary should provide at least 1-2 sentences describing the pull request   in detail (Why is this change required?  What problem does it solve?) and   link to any relevant issues.   If you are contributing fixes to docstrings, please pay attention to   .  In particular,   note the difference between using single backquotes, double backquotes, and   asterisks in the markup.   We understand that PRs can sometimes be overwhelming, especially as the reviews start coming in.  Please let us know if the reviews are unclear or the recommended next step seems overly demanding, if you would like help in addressing a reviewer's comments, or if you have been waiting too long to hear back on your PR. --
oh sorry. I saw that PR but I wasn't sure if you want to test against iojs3
Fixes #12198 Re-do of #12268
CC:  
I've already completed the CLA, I am (was) AdamFreidin on codeplex. I'll work on a unit test later today.  Assuming you really think it's necessary to track that obviously poor regex-based XML-ish parsing needs a unit test to be incrementally improved.
I spent some time trying to get it to repro on StackBlitz and had no luck yesterday, but you're right, I think this issue is very similar to #22581 (sorry for not finding it). FWIW the unit test added in this PR fails before and passes after the fix. I can keep trying on StackBlitz though.
PR Summary PR Checklist  [ ] Has Pytest style unit tests [ ] Code is Flake 8 compliant [ ] New features are documented, with examples if plot related [ ] Documentation is sphinx and numpydoc compliant [ ] Added an entry to doc/users/next_whats_new/ if major new feature (follow instructions in README.rst there) [ ] Documented in doc/api/api_changes.rst if API changed in a backward-incompatible way  <!-- Thank you so much for your PR!  To help us review your contribution, please consider the following points:   A development guide is available at .   Help with git and github is available at   .   Do not create the PR out of master, but out of a separate branch.   The PR title should summarize the changes, for example "Raise ValueError on   non-numeric input to set_xlim".  Avoid non-descriptive titles such as   "Addresses issue #8576".   The summary should provide at least 1-2 sentences describing the pull request   in detail (Why is this change required?  What problem does it solve?) and   link to any relevant issues.   If you are contributing fixes to docstrings, please pay attention to   .  In particular,   note the difference between using single backquotes, double backquotes, and   asterisks in the markup.   We understand that PRs can sometimes be overwhelming, especially as the reviews start coming in.  Please let us know if the reviews are unclear or the recommended next step seems overly demanding, if you would like help in addressing a reviewer's comments, or if you have been waiting too long to hear back on your PR. --
I'll note  ‚Äî¬†it seems in principle deepcopy might be much faster through rust than through python if we could get the logic to be equivalent. However, I'm a bit concerned that we'll find ourselves in edge-case-hell if we try to perform arbitrary deepcopying outside python. Maybe it's simpler than I'm thinking, but the nice thing about this approach is that (as far as I can tell) it should work for arbitrary inputs with minimal code. (And I don't think python's overhead is likely to be significant for shallow copies.)
The fetcher tests are throwing HTTP 401, 403, and 429 errors, which are Unauthorized, Forbidden, and Rate Limit Exceeded. I only made one very minor change to a single importer, and many are throwing errors. Should I ignore the continuous integration tests for fetchers?
Is there a way in the examples to more clearly show how multiple locator differes from maxN differed from auto? Like maybe change to a 1-10 range to have more wiggle room?  Or use different scales-dunno,  but I figure this image is at its most useful if readers don't necessarily have to read the code to get what it's trying to show. 
That's likely a deal breaker on this being in v4 as an update to the existing button group. We'd have to deprecate the existing one and provide this as a new component. Breaking changes are a no-go heading into stable v4.0.
Thanks. With "unfortunate" I meant that the same functionality will not be there out-of-the-box for those not being able to jump to 2.x yet. But I do understand the need for rules, and to stick to them :-) Thanks for the feedback !
Will need to extend this again in an upcoming PR, so wanted to make that simpler.
I wouldn't be comfortable including this in 2.8.1. 2.9.0 definitely, but not 2.8.1
Ok, done! I've added a comment to explain why it's not in global scope.
I made new PR #19124 This migration is a thing.
Summary Fixes: #11608 Test plan N/A
skip change file check
Yeah, I agree, we should link from the getting started page - just added that! I put it under "tips" since package management seemed less about React and more about general javascript programming.  Somehow, in my mind, JSX is more like "tooling integration" and everything else is "general javascript tips/practices".  Otherwise, it's a little unclear where to draw the line (gulp?  jest?  nuclide?  microsft visual studio?  typescript?  flow?).  Maybe the pages should be categories (transpilers, package managers, languages / type checkers, etc).  But I'm happy to create some pages under tooling integration if you'd like, just let me know!  My temptation is to merge this now and figure out the tooling integration pages in a separate PR.
PiperOrigin-RevId: 371026165 Change-Id: I26ac6372c87246e03c7eb8c94e84c84d86054b36
Demo here: (top red box uses Verlet with soft & hard sets, bottom is existing)
Shiny new commit with all the logic in the transport adapter. I added an  function to the  because I suspect most future transport adapters will heavily rely on this one. Adding specific headers is useful logic, and this allows the adapter to be easily subclassed and have new headers added: only one function override is needed.
<!-- Thanks for submitting a pull request! Please provide enough information so that others can review your pull request. The two fields below are mandatory. -- <!-- Please remember to update CHANGELOG.md at the root of the project if you have not done so. -- Summary I was bored on my flight home, so went over a random assortment of tests and fixed some type errors. Ignore whitespace for this one:  <!-- Explain the motivation for making this change. What existing problem does the pull request solve? -- Test plan Green CI <!-- Demonstrate the code is solid. Example: The exact commands you ran and their output, screenshots / videos if the pull request changes UI. --
-coders  Thank you for your review. I accepted your points and pushed the new commit.
Hi  , I have refactored my projects with the orm_mode and the latest updates from both pydantic and fastapi. Enum are still encoded with their values, whatever the Config is... ~~I think this PR is still relevant~~
104.75
Oops! Good catch, thanks for your contribution  ! :rocket: :lock: :cake:  And thanks  as always! :rocket: :tada: :bowing_man: 
I‚Äôm working on a library that will make this task easy. Even easy for you to do yourself. I have a different priority at the moment but plan to implement Stream-K in a few weeks. I have it outperforming MPS at around half of my test cases (notably FP16). If you want to get a head start, I can post some of the raw source code from my repo, and a few tables of perf data. I‚Äôm not interested in the bounty just trying to prioritize my own interests.
The weights may take a while to load, but let me give it a try
 [ ] closes #53077 (Replace xxxx with the GitHub issue number) [ ] Tests added and passed if fixing a bug or adding a new feature [ ] All code checks passed. [ ] Added type annotations to new arguments/methods/functions. [ ] Added an entry in the latest  file if fixing a bug or adding a new feature.  pretty simple, hoping this can be bundled together with the other interchange fixes in 2.0.2
Okay, after some fixes, there are no remaining issues with my app. This is mergable AFAIK :smile: 
Sorry, I think that feature isn't yet working on Windows.  : can you confirm that, or should that be working?
Thanks  -- I'm the one who opened #1203 .
Release branch for 4.3.0
thanks, thats what i was missing. Would any of this Just Work if this were implemented in numba instead of cython? I don't have a strong opinion on this per se, but am wary of a) using a cython feature (prange) that we don't currently use and that i don't know i) how well supported it is or ii) if its behavior is e.g. platform-dependent and b) user-facing kwargs that will give us combinatorially more cases to test
/fyi  
That would probably work. In ‚Äútheory‚Äù, you shouldn't need to rebuild it. Anyway, that part is why this issue is a bit of a mess. As is, this PR is imo an improvement on the previous behavior without that part as well.
I rebased  on . Sadly you have to rebase again :sob: but it should be good to go now!
Sorry for the issue, please open a new PR.
I ended up including your  check to ensure correct behavior in e2e, sorry for closing it!
this is not the way to go, this is rather future hostile. Latest DRE does not patch Chrome 67+ which landed with native support for both Custom Elements V0, V1, and builtins extend. In forcing DRE 1.7.2 you are basically patching forever even native browsers. You should consider better transpilation via  or use Babel 7 that should fix this for you.
Actually, there is a way. Since 1.5.0 we generate  annotation for each inline class. So, I see three possibilities  I pushed the use of  with known parameter type, as you suggested. We bump Kotlin version to 1.5.0-RC and check for the annotation, or We wait for Kotlin 1.5.0 release and then bump the version and check for the annotation. 
Now that I've written this, I'm somewhat skeptical of it: given the way tracebacks are printed and the length of , the original exception is a page or two up, so the "from-ness" of it could be easily lost on the user. I also wonder under what other cases this message would appear: I'm not sure what other cases to test. Suggestions, or should I just drop this? EDIT: Fix #8487 
Thanks!
SUMMARY This PR is to add support for using  parameter of . I will add a separate PR to add support for accepting test script parameters. <!--- HINT: Include "Fixes #nnn" if you are fixing an existing issue -- ISSUE TYPE <!--- Pick one below and delete the rest --- Feature Pull Request COMPONENT NAME win_pester ADDITIONAL INFORMATION This allows user to pass tags like below
\o/
Yeah, well. I don't like the outcome of this update using rebase experiment of mine. Subsequent updates from upstream will be via a classic merge.
That's pretty cool! Thanks for letting me know! On 26 Sep 2014 17:41, "Szczepan Faber"  wrote:
The new method fails because  is Python 3 only.  x_x  The only alternative would be to hand-spin a  subclass, which I feel is an overkill.  x_x
this doesn't work because  is a . also, should return , but it returns a  of s, open a GH issue?
Not necessarily, it might be an event with different state : success or failure. Yes it's not out of question (my suggestion on the factory methods indeed lean in that direction). But at this moment, I fear we are over-engineering this.  and  are the primary users of this, could you show us some concrete code snippets outside (not tests) how you want the listener to be registered or how the code you're working with can/should process the verifications. Basically the design question is wether we want this : Or 
Thanks  for this patch :+1:  I left some comments. please update
Fix and test for #537. Please first fastforward master into develop and then merge #572, though :-)
would you mind signing the CLA and update ?
i'll just fix it up  - thanks though man
Like I sort of feel this speed isn't worth it. I'm fine with NamedTuple for the immutability, but the last PR probably went a bit too far. Again, readability, understandability, modifiability is absolutely number one, not perf and not line count. I'm tempted to rip out all the slots for example to prove this (though they do function as a guard from setting other crap on the class). The last speed PR made a few major conceptual refactors, and that's why I valued it. The removal of this "MovementOp" layer of indirection was super valuable and faster. I accepted the other stuff but wasn't thrilled about it.
Maybe it's best that I wait for your neew PR that deals with the backend  issue, then I rebase on that and see if that changes anything. I might also try  check to reset html.py and see if that  passes. and last I will be in my office again tomorrow where I have a  Anaconda installed (instead of the system python on my linux laptop) and  see if i can reproduce the problem there.
Hello, I've found some minor typos in the documentation, solved with this PR. Fix typo: we we -typechecking -typecheck  -reentrancy  -> re-entrance
Actually, I looked again at the XMLHttpRequest 2 specification and apparently there is already default behavior for the Content-Type header when posting data: So it would seem that setting a default Content-Type header to "application/x-www-form-urlencoded;charset=utf-8" is divergent from the specification, which defaults to "text/plain;charset=utf-8". Therefore I'm going to remove this behavior. I'll think some more if there is a better way to post parameters easily.
:dancer: good idea
Can you please copy both pages to the  directory? Otherwise the mismatch might be confusing for the Chinese translators. 
Updated <details to_replacevalueto_replacevalueto_replacevalueto_replacevalueto_replacevaluevaluevalueNonevaluevaluevalueregexvalueto_replaceto_replaceto_replacevalueto_replaceto_replaceNoneto_replacevalueNaNregexto_replaceto_replacevalueto_replaceregexto_replaceto_replacevalueto_replaceto_replacevalueto_replaceto_replaceto_replaceto_replaceto_replaceto_replacevalueto_replacereplace Ôªø</details 
I already have class like . My problem is that this is class that can be registered many times, not like the blueprint. So, the problem is the same, I need to be able to write: and then: By the way, to avoid collision, my blueprint is declared with an url_prefix: If you look at the code, there was an attribute meant to implement that: . The problem: it wasn't working and induces me in error. This is why I started this pull-request.
i think that's the main differentiator. i totally understand how this makes sense in a viewer. but i hope you see that this makes little sense in anything else. in a normal application that relies on assets, how is  anything different from  and why does the latter throw while the former is silent. i think we're breaking very basic and widely agreed upon programming principles here. if  is still a possibility for both this and the texture thing  then i would suggest we revert both and add it. and it would allow both the viewer to plow on and everything else to be reliable through testing and error response.
review_need
I am so sorry I find a issue just now.     <div          <div v-for="(item, index) in list" :key="index"            <component :is='comp' v-once          </div        </div  in third test, I got , but  it is ok. I am not sure is it a bug, cause  is variational. Thanks
Even if it's just refactoring? 
It seems to have the same purpose as our  check, except it uses what appears to be a somewhat inferior approach.
This PR was merged into the repository by commit 4d8cc709e29096171c4f13138b32ef2ec4e0dd4c.
hell yeah! Nice work, thanks  
Thanks for the contributing! But I see that no CLA was signed so I cannot merge it. Also, in the meantime it became outdated. Perhaps, we should introduce some automation to automatically update versions in examples. I will close this PR. Feel free to re-open if you would like to update it and sign CLA.
The first sentence of the Session docs reads: Is there a reason we need this change? Do we need to improve the Session docs directly?
I'll merge too since those failures are very distracting.
Looks okay. Could you add a whatsnew note in ?
What do you personally suggest for implementing outside of React? IMO staggered animation are a desirable feature.
You could have just edited the title :)
I will revert this one once the other revert lands
The README used ‚Äúnpm run build‚Äù but the correct build script seems to be ‚Äúnpm run sapper‚Äù.
That makes some sense. Of course, in principle one can also override the numpy functions using ... But for , we also have , etc., rather than specific methods.
'layout.jade' obsolete after start new express project. Fix using 'doctype html' instead of 'doctype 5'
, I changed the implementation to keep the original  strategy and fallback to  if if fails with the error I mentioned in the issue. I included tests for the changes so I am not sure why the code coverage is not catching it.  I also updated the changelog.
Can we have tests for this, both for  and ?
Sweet!
That's what i thought.  In this case, i would say that we should not take this change.  'normal' Enums are mutable values as far as the language is concerned.  If you want enums that cannot change value, then the new 'const enum' feature is likely what you want. Thanks!
Changes made in :
Cloud someone give some attention to this little PR?
Got it, thanks for the clarification! Sorry to keep pestering you  on this PR. I'm confused as to how to adopt the module resolution logic to working in an extensionless form. Do you have any pointers you could share please? Just to show where I'm at (and prove good faith in my investigation! üòÖ ), I looked through  ->  since that's what's used right now. They necessitate returning a  and I'm hesitant to make big changes around no longer requiring an extension.
sure
PR:  r151:  r152: 
Update copyright year in license. Looks like it was forgotten in 52098e1e4fc4d9c962e9ecb09dfbbcc6ac80a4d7.
Noticed this weird side case when I tried to build in a virtualenv with matplotlib but not Sphinx installed
http://test/OCL:248834900:BASE:248834905:1558155226853:8842a15a
All right, I am closing this PR for now. Thanks for the investigation nonetheless! Now when we have similar feature requests, we can point to this discussion and explain why we are not going to adopt such a feature for the time being :smile: 
Also, just switching branches gives me issues where it thinks I have a pending commit to google/protobuf.  If I'm on my local master branch and do "git checkout update_pb_lib" and it tells me I have a pending commit to google/protobuf (it wants to make it go back to using the old version). Then I do "git checkout update_pb_lib -- google/protobuf" because I want to revert this unwanted commit and use the version I selected in "update_pb_lib", but it just ignores it and the pending commit remains active. I assume git is treating it differently from a regular file because it's actually a submodule, but I'm not sure how I'm supposed to switch local branches cleanly with this behavior.
Sorry, have not had a chance to use Jest again since submitting this. I should hopefully get some time to look into this in the next week or so
Hooray! Really happy to see this feature returning. Thanks for the flood of pull requests!
NUMA support message on ARM64 system With this patch, on ARM64 system, tested 2 GPUs connected on different sockets. Both are functional. Hardware: Dual socket ARM64 N1 system. 2 GPUs connected on different sockets Software: Ubuntu 20.04.3 LTS Kernel : 5.4.0-89-generic (Linux devBox 5.4.0-89-generic #100-Ubuntu SMP Fri Sep 24 14:29:20 UTC 2021 aarch64 aarch64 aarch64 GNU/Linux) CUDA SDK : 11.4 (cuda_11.4.2_470.57.02_linux_sbsa.run) cuDNN : v8.2 (cudnn-11.4-linux-aarch64sbsa-v8.2.2.26.tgz) TensorRT: v8.0.1.6 (TensorRT-8.0.1.6.Ubuntu-20.04.aarch64-gnu.cuda-11.3.cudnn8.2.tar.gz) GPU: Tesla T4 PCI slot info: $lspci | grep -i NVIDIA 0005:01:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1) 0009:03:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1) NUMA Info : $ cat /sys/devices/pci0005:00/0005:00:01.0/0005:01:00.0/numa_node 0 $ cat /sys/devices/pci0009:00/0009:00:05.0/0009:03:00.0/numa_node 1 TensorFlow GPU access info: Script to get info:
Not sure, I guess you could do something like I have done in the  field, which is not nice, but does cover "most" of the cases.  Also, I have seen there's a new  var, I will update  so it makes use of it instead of .  Edit:  I have rebased the branch on latest devel. 
Under heavy optimization mocks might get garbage collected during the dispatching of a mocked method if the mock instance is not used after this method dispatch. To avoid this, we escape the mock instance during the dispatch to make sure that the GC cannot collect the object. Fixes #1802.
Fixes #4649
969
This, or something similar, would be a great addition for our use too. We have a few code bases at work that require some hoop jumping to work around system  using system certs[1] and virtualenvs in  runs attempting to use the certs in . I ended up adding something along the same lines to github2 to work around  using bundled certs on some hosts, and it would be nice if I didn't need to worry about it when using  ;) 1. Debian and Gentoo patch system certs support in to their packages, possibly others too.
Merged in 6114f66e57db5446a7f7995d801bb59a6e882d04
I really don't like the comment hack, experience shows that's in general a terrible idea. What about just putting that stuff into a  file for the  expressions, and  for the TypeScript variant?
3.10.0 should be available on Maven Central in a bit.
LGTM!
LGTM :+1:
If you do  the expected behaviour is: , but you get , since typeof String is "object". I am working on a PR to fix this,
Don't like "additionally" and prefer "thus"  ? :)
462
-amd
Re  / - Good idea (matplotlib's gridspec allows it). But it would require some work to code it up. It also somewhat breaks my initial philosophy: the width and height of each subplot depend only on the number of row and columns. Col and row span - with  the width and height of all subplots would have to be recomputed in order to preserve  and . Re ordering  - You're on 's side on this one.  - To me, it's a little weird that the first spec item (i.e. ) does not correspond to  / .  - What about this solution  ? Re  layout  - With , we allow   With , we allow    Should we make  specs opitonal at the end of rows and columns ?  
What are "Active headings" ?
Hi  , We lock the plotly.js version constraint for  because the Python library is code generated off of the schema for that specific version.  This is admittedly a bit conservative since the plotly.js project does work hard to keep everything backwards compatible, but there are still cases where it could cause an issue. For example, if Plotly.js fixes a bug that plotly.py had worked around then the release of a new version of plotly.js could break  mid cycle (though I suppose that is just the nature of bounded dependency resolution) In any case, there are already so many moving parts in getting the JupyterLab installation working that I'd prefer to not add another free variable that can change between releases. I am a bit confused about why this warning is issued though.  states a dependency on plotly.js version  and  states a dependency of .  Do you have any idea why this doesn't resolve to 1.40.1? Also, the installation still succeeds and I'm able to use both  and  but I'm not sure how to check what version of plotly.js was actually installed.
I‚Äôm pretty sure you can use custom projections from the command-line, but you need to require them (and npm install them) first. The projection definition is just JavaScript that gets evaluated and returns the projection object, so anything that can be run in Node should be available for you to use. You can even define the projection definition in a separate JavaScript file and require that if escaping it through the command-line is a pain. That said this needs better documentation and the design of the command-line tools needs work (specifically decoupling into smaller UNIX-y tools). It‚Äôs on my long list of things to do after I finish D3 4.0.
By default, the sphinx build uses intersphinx, which links documentation to other sphinx docs like scipy or numpy. This is good for the actual docs, but causes a sphinx build warning if any of the other sites are offline or the web momentarily hiccups.  In #760 this led to a false sphinx build warning on travis.  So this just turns off intersphinx for the travis doc build to prevent that in the future.
-bot test this -bot user test this inline -bot run dt -bot perf test faster -bot test top100
I like Universal. Kinda like iPad/iPhone apps Universal. :+1:  (Edit: not being sarcastic. Isomorphic is a weird word.)
Summary of Changes  To prevent version changes of  breaking old html exports, these exports now included a version URL that matches 's bundled . This is the default behaviour of . added to preserve original behaviour. Refactored tests and code that rely on the  URL to use a function in   Code PR  [x] I have read through the contributing notes and understand the structure of the package. In particular, if my PR modifies code of , my modifications concern the  files and not generated files. [x] I have added tests (if submitting a new feature or correcting a bug) or   modified existing tests. [x] ~~For a new feature, I have added documentation examples in an existing or   new tutorial notebook (please see the doc checklist as well).~~ Not Applicable [x] I have added a CHANGELOG entry if fixing/changing/adding anything substantial. [x] For a new feature or a change in behaviour, I have updated the relevant docstrings in the code to describe the feature or behaviour (please see the doc checklist as well). 
New Starting
ok, silly me, it was just a question of adding the new subpackages to the  list in . All green now!
Corresponding changes for data-sveltekit-replacestate addition within SvelteKit:  Also related:  Before submitting the PR, please make sure you do the following  [x] It's really useful if your PR references an issue where it is discussed ahead of time. In many cases, features are absent for a reason. For large changes, please create an RFC:  [x] Prefix your PR title with , , , or . [x] This message body should clearly illustrate what problems it solves. [ ] Ideally, include a test that fails without this PR but passes with it.  Tests  [ ] Run the tests with  and lint the project with  
The servers we provide in our tutorial work fine with, and several are even expecting, the default  of  so I think we're going to leave this as is. Unfortunately we can't support people running the tutorial with a setup different than we expect as there is just too much we would have to test and support. Again, sorry you had that experience - this is exactly why we provide servers you can run.
Sorry - not sure what happened when I was rebasing...getting this sorted.
What is ?  It's not a standard part of Flask.  Your example doesn't demonstrate the need for your patch.  Class creation should not have side effects that you might need to bypass.  Use decorators to check for permissions, which is already supported by .  This seems like an incorrect design choice rather than a missing feature on Flask's part.
great thanks, somehow forgot about that.
This PR addresses . Fixing the immediate problem only required removing a brittle runtime type check of each  field in a  arg (passed to ). Putting in a more robust version seemed to lead inexorably to making changes in a few other places. The same type checking effectively happens in parts of the code that accept a  and returns a . As it turns out, that logic is repeated in a number of places: - Processing any  fields in the  arg to  - Doing the same for the  arg to  - At various places in : here, here, here Given that, it seemed best to factor out that logic into a standalone function, for the sake of DRYness. That also makes it easier to raise -specific exceptions, with clearer error messages, when invalid types are passed. And it means that the  args in  and  undergo the same type checking.
What.... Does  use ?
I want to make some add-ons or wrappers on components e.g BigButton.svelte But it doesn't work so I have to wrap slots in useless and interfering divs or spans like this:
Presumably these extensions do something. Disabling them because it makes our API easier to use sounds to me like you are "fixing" this problem at the wrong layer.
Summary At Facebook, in a common situation where you've changed a couple of files in the largest haste map, this PR cuts off 25%~ of the startup time. In other less common situations where you've working on a smaller haste map, the improvement is 60%~. The improvement is gained by: - Not re-serializing and writing the haste map to disk if it was loaded off of disk and then not changed. - Not re-creating from scratch the  and  part of the haste map on startup when we know what specific files were changed. Instead, just re-process only the specific changed files. I've benchmarked the startup time by: 1. Setting up a single test 2. Running once to prime the cache 3. Changing a test file 4. Running the test again with  (measuring at this point via ) I've been a bit conservative and I'm just doing a full re-process when files were deleted (same as current behavior) but I may improve that. It's much less common to delete a file than to edit a file and I wanted to keep the code as simple as possible initially. In cases where Watchman isn't being used or is freshly started, there is no difference. I'm always a little suspicious when something relatively simple yields such a large performance improvement, so please help by casting a very critical eye on this PR and all assumptions that I made. Test plan  All tests pass. Tested manually in multiple situations. No change in behavior without watchman. Manually verified the cache file is updated appropriately in a variety of situations. 
No worries. Quick question, are you happy for quick little changes like the above? As I read through the documentation, its pretty easy to make small changes to English/grammar. Does that work? Or do you prefer larger documentation changes? 
:+1:  as  noted, this needs to go into branch release-1.4
These tests passed but I had to increase the tolerance on some of them. Particularly when  and ( or ).
This PR replaces the previous use of a  file for the study definition file with a  (YAML) file. An example study definition in YAML format:   [ ] Change in CHANGELOG.md described (if applicable) [x] Tests created for changes (if applicable) [x] Manually tested changed features in running JabRef (always required) [x] Screenshots added in PR description (for UI changes) [x] Checked documentation: Is the information available and up to date? If not created an issue at < 
Oops forgo to target the  branch, closing and opening a new one.
We should also check that all our locators actually adhere to this before documenting it! I've been having a play around with  to test this, and have found that for  with , the smallest tick returned is  which is not ...
I do not currently have good Internet access (vacation). Please repush (forced) and see if it works. Thanksfor the effort. This will be merged eventually. 
Thanks , without looking into , I'd be happy to try and support it. Could you create an issue on  so we don't forget this.
We don't really have good coverage enough internally to really know if this is fast/safe in production environments. The best we can do at this point is probably just to release it in a patch. 
also  if it's so confusing, that's a sign of bad readability 
I'm not sure, sorry :( Might need to contact AppVeyor support about it.
Alright, that's a good point. If the decision already has been made, so be it :smile: 
The failing tests are unrelated so... Merging! üéÜ üçæ 
I have little time right now, so you're most welcome to continue based on #5691. It seems I accidentally deleted my fork (again ü§¶‚Äç‚ôÇÔ∏è) so I can't continue working on #5691 anyways. Just clone and open a new PR, and mention that it supersedes #5691 so it can be closed.
/preview
You've missed renaming in a few places, also linting is failing. If it's a pain to fix, I'll do it in a couple of days.
This needs at least a note in the api_changes explaining the change and how people relying on the old behavior need to update their code. In practice I think(?) "absolute" paths should still be detected and understood relative to srcdir; this is consistent with how sphinx treats /absolute/path
This pull request adds the capability to create/delete alias records with the route53 module.  In addition, ELBs created with ec2_elb_lb will now return the hosted zone id which is required when creating an alias record in route53.
recieve -> receive
READ THE TEXT: FOR ADDED AND DELETED! 
That doesn't seem to be the case? With this branch, and the example of the whatsnew docs: Further a general comment (will try to do more detailed review later this week): I am not sure we can just change this. First, it is a API breaking change in several places, eg also pivot_table*. And second, I think the current behaviour can actually useful in certain cases and it would be nice to have a way to keep this behaviour.  I know this is very ugly, but it would be worth to have a keyword for this in  ? * but I agree we should look into it and try to make this more consistent. As, for example,  does not seem to include unobserved categories (already currently on master), while  does include them but apparently only for the index and not columns? (try  with the example of whatsnew). On the other hand,  does include them (and I think rightly so), but that also introduces an inconsistency with groupby.
the only thing I dont like about this, is that debugging the locals object within a template, or options within the view system ends up spitting out such huge objects
Hey ! Sure thing, go ahead! I just updated the docs that use that tutorial example to account for the changes, but that's done. And thanks a lot! BTW, I commented out the pytest ignores to see if they would explode or not. Also, I think the errors are because some recent tests used Pydantic models with  in the name that were added in a recent PR. If you wanna fix those, that's awesome, but otherwise, you can just let me know and I can do it. :nerd_face: 
Seems reasonable to me. On Fri, Dec 14, 2018 at 4:12 PM jbrockmendel <wrote:
Hehe :-)  Still need to add the other orientations, and clean up the height computation. I think I should probably add  and  support too like in the Protovis version.
Weird, something must have gone really wrong when I merged my reformat from 1.0.x.
i still think it's weird behavior to pass dictionary keys and optional functionality in the same call... however, the standard python update keeps these references intact. which makes we want to keep it as is and include a keyword option as you suggest. We don't actually need a default, we can do it like this: this seem ok?
I respect that -- readability is incredibly subjective; I think what's lost is the variable names, but those could easily be replaced with comments. Readability isn't made worse everywhere -- there are a lot of places where the code is doing something like this: turning that into: doesn't seem to hinder readability, and gets us back two more lines. the trickier ones -- where readability might be overly hindered are the lambdas; I don't think the sum, pow, etc (basic ops) are bad at all, but I'll admit some of the others might be tricky IMHO it boils down to a question of 'readable to who?' -- if someone isn't familiar with lambdas this wont be as readable, but IMO -- if someone isn't familiar with lambdas I doubt they're reading a python ML lib. Would you mind reviewing the PR and indicating which lines you feel like suffer from this change? I'll see if there's a more readable approach to line reduction in those places or revert them if the consensus is that they're not readable
I'm not by any means saying this is best practice. Just that having the hardcoded example accompanying the docs, might lead to less confusion for those reading it. (And a sanity check that what's in the docs works as it should.)  how would you feel about adding a patterns directory under examples?
OK, I replaced the  parameter with the existing  parameter. For backwards-compatibility, I added a new "bundle" interpolator, which is the same as "basis", except it uses the tension parameter to straighten the spline. This seems like a reasonable interpretation and avoids adding a new API, which I like.
Hi bot, maybe one of your humans can chime in and see what it would take for this to be added to our badge board?   We have taken the approach of not adding to the readme badges, and for now, especially with this less common one, I am not sure we want it on the readme. That being said, any way we can get more contributors to the project would be great.  Can you talk more about who recieves emails and how they are chosen?  Are the self selected for projects or types of projects?  Do they get issues tagged with ? or just random ones? Thanks!
yes that‚Äôs the idea üí° 
I enabled JS profiling, and fixed the other concerns.
106.41
Sorry, the previous set of commits were a WIP and I ran out of steam before getting d3.xml and d3.text working. Should have left a message about that. On the other hand your comments were very helpful for coming up with an approach. All unit tests are passing now and I think the method overloading should be working properly as well.
In agreement with ‚Äîall those variations get added for little use, and then folks will want responsive variations. Gotta call it somewhere unfortunately‚Äîthanks though!
Did it fix it for you  , the link works for me?
Anyone against this patch?
I'll target 5.0, sure. This appears similar to #2809, however this PR's promise detection should be more generally applicable (not all Promises follow the A+ standard and implement a  method). This PR also adds tests. So I understand correctly, does rebasing on 5.0 alleviate concerns about breaking any existing uses? Or if it does not, then I'd love to know more about the specifics of those cases to protect against.
Hmm weird, the  seems to be . Maybe the processor is running too early?
I still have an extensive Mockito API investigation planned to see what our current API surface is. Based on that outcome, we have to decide whether we want to expand our public API in this direction. Therefore this PR is blocked on that process, sorry :cry: 
LGTM
So far, these fixes only apply to d3.behavior.drag. There‚Äôs a small fix we could make to d3.behavior.zoom. And major changes that we could make to d3.svg.brush if we wanted to support multitouch brushing (not multiple brushes, but just being able to drag handles independently, say). Though I think adding multitouch support to the brush component might be too large of an undertaking for 3.4.4.
Source files that contain directives or components that need an inline type constructor or inline template type-check block would always be considered as affected in incremental rebuilds. The inline operations cause the source file to be updated in the TypeScript program that is created for template type-checking, which becomes the reuse program in a subsequent incremental rebuild. In an incremental rebuild, the source files from the new user program are compared to those from the reuse program. The updated source files are not the same as the original source file from the user program, so the incremental engine would mark the file which needed inline operations as affected. This prevents incremental reuse for these files, causing sub-optimal rebuild performance. This commit attaches the original source file for source files that have been updated with inline operations, such that the incremental engine is able to compare source files using the original source file. Fixes #42543
haha, oops! Was just trying to make a simple doc change as my first PR. It does look like gitwash is pretty ignored. Including some PR's from .
In virtual-dom system of vue 2.0, when we are necessary in order to communicate the parent-child components, need to use the .
what is your screen resolution/devicePixelRatio? I have a suspicion that this has to do with scale/zoom.
Thanks.  The .gif file is still not getting installed.  You need to add a line for  to the  list in . 
cc:  Maybe you can help?
I dont know what goes wrong with the 2.7 tests... :(
Unfortunately, you will no longer be notified if the tokens expire. Sorry for the delay. BTW: It was not possible to renew the WebXR Gamepad Support token. Seems this trial is over.
237
cleaning <!-- Please uncomment this block and take a look at this checklist if your PR is making substantial changes to documentation/impacts files in the  directory. Check all that apply to your PR, and leave the rest unchecked to discuss with your reviewer! Not all boxes must be checked for every PR :) If your PR modifies code of the  package, we have a different checklist below :-). Documentation PR  [ ] I've seen the  file [ ] This change runs in the current version of Plotly on PyPI and targets the  branch OR it targets the  branch [ ] If this PR modifies the first example in a page or adds a new one, it is a  example if at all possible [ ] Every new/modified example has a descriptive title and motivating sentence or paragraph [ ] Every new/modified example is independently runnable [ ] Every new/modified example is optimized for short line count  and focuses on the Plotly/visualization-related aspects of the example rather than the computation required to produce the data being visualized [ ] Meaningful/relatable datasets are used for all new examples instead of randomly-generated data where possible [ ] The random seed is set if using randomly-generated data in new/modified examples [ ] New/modified remote datasets are loaded from  and added to  [ ] Large computations are avoided in the new/modified examples in favour of loading remote datasets that represent the output of such computations [ ] Imports are  /  /  [ ] Data frames are always called  [ ] fig.add_fig.update_go.Figure(data=..., layout=...)fig.add_shapefig.update_xaxesfig.update_layoutfig.show()plotly.plot()plotly.iplot()plotly.graph_objectscodegen` files and not generated files. [ ] I have added tests (if submitting a new feature or correcting a bug) or   modified existing tests. [ ] For a new feature, I have added documentation examples in an existing or   new tutorial notebook (please see the doc checklist as well). [ ] I have added a CHANGELOG entry if fixing/changing/adding anything substantial. [ ] For a new feature or a change in behaviour, I have updated the relevant docstrings in the code to describe the feature or behaviour (please see the doc checklist as well).  --
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [ ] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [ ] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [ ] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [ ] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [ ] All tests are passing:  [ ] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
Thanks for the idea.  However a few comments.   1) why would this need a special axes, and not just a special artist and/or method on a normal ? 2) I'm surprised that downsampling at the numpy level would actually be faster than just letting the renderer downsample.  Did you check actual speed performance?  3) your downsampling seems to be assuming the line is a timeseries, where x is monotonic and y the dependent variable.  Matplotlib can't make that assumption, and indeed many people will plot a "time series" with the independent variable on the y axis, not to mention plots that are not monotonic in either axes. 4) even if it were a time series, your method of downsampling is very susceptible to aliasing and will definitely have strange artifacts due to preserving the local extrema.  Downsampling requires a low-pass filter, and you are not going to preserve extrema by definition.   So overall, this doesn't not seem general enough to be used by core Matplotlib.  Some level of simplification for Line2D drawing seems possible, if it is not already there.  
Sorry, haha :)
ready_for_review
You mean the API docs? Now is does, it never showed up for  by the way.
<!-- Thanks for submitting a pull request! Please provide enough information so that others can review your pull request. The two fields below are mandatory. -- <!-- Please remember to update CHANGELOG.md in the root of the project if you have not done so. -- Summary <!-- Explain the motivation for making this change. What existing problem does the pull request solve? --Fix #9809  After clone and run  repository doesn't contains backers.json. This bug has appeared after , #9375 and #9377. For correction is necessary revert postinstall and remove waste code from circleci.
Those types should probably be part of the  module (which I forgot to add to this PR anyway). Perhaps we add them there, and re-export them from  but also deprecate them, so that in v5 we can safely drop them altogether?
Hmm, I'm not sure if I want to since it's a strange library and not needed for 95% of tinygrad. Is there a 50 line reimplementation?
Oh, you know what? I'm stupid. I'm actually using . Please, accept my apologies üôá‚Äç‚ôÇÔ∏è
Pretty simple fix. This list in the docs doesn't render properly. This commit fixes the markdown source, and for one other list just like it. Documentation PR  [x] I've seen the  file [x] This change runs in the current version of Plotly on PyPI and targets the  branch OR it targets the  branch [x] If this PR modifies the first example in a page or adds a new one, it is a  example if at all possible [x] Every new/modified example has a descriptive title and motivating sentence or paragraph [x] Every new/modified example is independently runnable [x] Every new/modified example is optimized for short line count  and focuses on the Plotly/visualization-related aspects of the example rather than the computation required to produce the data being visualized [x] Meaningful/relatable datasets are used for all new examples instead of randomly-generated data where possible [x] The random seed is set if using randomly-generated data in new/modified examples [x] New/modified remote datasets are loaded from  and added to  [x] Large computations are avoided in the new/modified examples in favour of loading remote datasets that represent the output of such computations [x] Imports are  /  /  [x] Data frames are always called  [x] fig.add_fig.update_go.Figure(data=..., layout=...)fig.add_shapefig.update_xaxesfig.update_layoutfig.show()plotly.plot()plotly.iplot()` are not used in any new/modified example [x] Hex codes for colors are not used in any new/modified example in favour of these nice ones 
Whats new: Update BS script tags in template Replace jumbotron with utilities Replace font-weight-bold with fw-bold Replace ml-auto with ms-auto Replace float-right with float-end Replace data-target with data-bs-target Replace data-toggle with data-bs-toggle Add CSS rules for <a - [x] closes #41457  - [x] Ensure all linting tests pass, see here for how to run them - [x] whatsnew entry
Thanks for the feedback . How about this?
No further comments other than the one I just made. I know it's not even really relevant to the purpose of this PR, but it seemed like a good opportunity to review the developer docs on the whole.
Closes/related to #872 The missing server option has been a drawback when it comes to the swagger UI (e.g. provide prod and test servers) and portability of the openapi.json to services that is based on knowing the servers. Example usage: It would also work to just pass a dictionary, but then the typechecker won't be happy:
Should this be  maybe?
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [ ] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [x] Other, please describe: Add store field into types for TypeScript  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [x] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [x] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [x] All tests are passing:  [x] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
we support osx-64 and win-64 right now (not yet linux), man i find this process tough. there must be an easier way! but i can't seem to find it... in order to do a: we need to provide a build for your specific platform ( sad face ), or so i'm lead to believe...
Add exception handling and going to merge. Thanks !
Updated to match current spec.
Thanks  for this patch :+1:  We are working on Pydantic V2 and the plan is to don't accept the new features on . So, I think you need to wait for V2. what do you think Sorry for that!
also fixes the test (ignore the ...). I suspect that this is telling us that although we have corrected the dpi on the figure, the (doubled) value is also through the restored transforms so the figure is in an inconsistent state.  Setting (and resetting) the DPI restores the consistency. 
üåê Add Chinese translation for Tutorial - Debugging
gentle ping; lots of PRs are touching this file and it is particularly hard to rebase
The "exec stub" wrapper is also in extra. The bindings code is ugly, it really belongs in a well tested and maintained pyhip library. But yea, I'm fine with it now since it's not default, but will have to do something before the 0.7 release.
589 aimed to fix the javadoc rendering, but the assumption was that the javadoc tool of the Sun JDK6 will render javadoc the same way as openjdk6. Unfortunately this is not the same, the javadoc rendering of openjdk6 is a pre work that avoid the use of table elements, this making the stylesheet incompatible. This PR aims to fix that and thus fix #552  Bonus I changed the  and  by  in the javadoc, this way we have aligned version numbers
I‚Äôm going to punt on a lot of tests because this is just the beginning. Someone else can help with getting this to the finish line. I need to focus on getting the shell in place.
Description This switches the wheel building and publishing machinery from Azure to GitHub Actions, making use of the OpenAstronomy workflow (). To start with, I am copying over the configuration as-is, and we can then see if any improvements can be made. Remaining things to do:  [ ] <s* [x] Set up nightly build machinery, which will require changing the URL for development wheels to a different URL (assuming we do this, we should clearly warn people in advance - nothing will break since the old dev wheels will still be available at the old URL but no new dev wheels will be added there) [x] Consider whether to drop 32-bit wheels for Linux - I think for now we should actually leave it in this PR so that we can backport it to 5.0.x and 5.1.x and then remove 32-bit Linux support in main (if we decide to) [x] Don't build all the wheels for all PRs - build only a couple for regular PRs, and all on release branches and tags. [x] Add back all the regular CI builds (remove the TMP commit)  <!-- Provide a general description of what your pull request does. Complete the following sentence and add relevant details as you see fit. -- <!-- In addition please ensure that the pull request title is descriptive and allows maintainers to infer the applicable subpackage(s). -- Checklist for package maintainer(s) <!-- This section is to be filled by package maintainer(s) who will review this pull request. -- This checklist is meant to remind the package maintainer(s) who will review this pull request of some common things to look for. This list is not exhaustive.  [x] Do the proposed changes actually accomplish desired goals? [x] Do the proposed changes follow the Astropy coding guidelines? [x] Are tests added/updated as required? If so, do they follow the Astropy testing guidelines? [x] Are docs added/updated as required? If so, do they follow the Astropy documentation guidelines? [x] Is rebase and/or squash necessary? If so, please provide the author with appropriate instructions. Also see "When to rebase and squash commits". [x] Did the CI pass? If no, are the failures related? If you need to run daily and weekly cron jobs as part of the PR, please apply the  label. [x] Is a change log needed? If yes, did the change log check pass? If no, add the  label. If this is a manual backport, use the  label unless special changelog handling is necessary. [x] Is this a big PR that makes a "What's new?" entry worthwhile and if so, is (1) a "what's new" entry included in this PR and (2) the "whatsnew-needed" label applied? [x] Is a milestone set? Milestone must be set but  check might be missing; do not let the green checkmark fool you. [x] At the time of adding the milestone, if the milestone set requires a backport to release branch(es), apply the appropriate  label(s) before merge. 
Sorry, I'm not having time to work on this and probably will not be able to do for a while. I'll close the PR to give the chance of other people to work on this. Anyone feel free to fork my repo and continue
This PR updates protobuf-java to 3.9.2, to match C++ version in tensorflow/workspace.bzl (3.9.2), and to fix the issue raised in #39381 about Java9+ specific warning messages (related ) This PR fixes #39381. Signed-off-by: Yong Tang <>
+1
fixes #1989 
Note that I haven't tested that this actually helps, but it doesn't hurt.
This PR aims to vastly improve our TS types and how we ship them. Our previous attempt at shipping TypeScript was unfortunately flawed for many reasons when compared to the /puppeteer package:  It only worked if you needed the default export. If you wanted to   import a type that Puppeteer uses, you'd have to do . This is not something we want to encourage   because that means our internal file structure becomes almost public   API. It gave absolutely no help to CommonJS users in JS files because it   would warn people they needed to do evaluateunknowntsimport puppeteer from 'puppeteer'tsimport type {ElementHandle} from 'puppeteer'tspuppeteer.ElementHandletsfoo.evaluate(x =1. In a  file using CJS, you can do  and get good type help from VSCode.  To test this I created a new empty repository with two test files in, one  file with this in: , and a  file with this in: . These files included enough code to check that the types were behaving as I expected. The fix for our types was to make use of API Extractor, which we already use for our docs, to "rollup" all the disparate type files that TS generates into one large  which contains all the various types that we define, such as: If we then update our   field to point to that file in , this then allows a developer to write: And get the correct type definitions. However, what the  file doesn't do out of the box is declare the default export, so importing Puppeteer's default export to call a method such as  on it will get you an error. That's where the  comes in. It appends the following to the auto-generated  file: This tells TypeScript what the default export is, and by using the  syntax, we make sure TS understands both in a TS ESM environment and in a JS CJS environment. Now the  step, which is run by GitHub Actions when we release, will generate the  file and then extend it with the default export code. To ensure that I was generating a valid package, I created a new repository locally with the two code samples linked in Gists above. I then ran: Which gives me a base to test from. In Puppeteer, I ran , which packs the module into a tar that's almost identical to what would be published, so I can be confident that the .d.ts files in there are what would be published. I then installed it: And then reloaded VSCode in my dummy project. By deliberately making typos and hovering over the code, I could confirm that all the goals listed above were met, and this seems like a vast improvement on our types.
Any Mac testers want to verify this at least doesn't make things worse and merge?
Whoops! Yep. :) Man, I wish I knew. I know it's on Listen's end (or wdm's end), and not Jekyll's. If you want to take a stab at debugging this, run  with the  environment variable set to . It'll print out a bunch of debugging statements about what Listen is doing in the background and might make the issue more clear.
While running the coverage tests for my other PR I found this: Module | statements | missing | excluded | coverage -- | -- | -- | -- | -- fastapi/concurrency.py | 28 | 6 | 4 | 79% This PR should fix up to 100%
will do that and mark this as draft for now.
WHAT IS GOING ON???!?? hahaha
please merge once you've given a quick sanity check as well
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [ ] Feature [ ] Code style update [x] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [x] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [ ] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [ ] All tests are passing:  [ ] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
:+1: 
In HSL space, grayscale colors can now have undefined hue rather than assuming a hue of 0¬∞; likewise black and white can have undefined saturation rather than assuming 0%. In HCL space, black can now have undefined hue and chroma. (For non-black grayscale colors, including white, hue and chroma are implied by the D65 standard referent.) When interpolating between colors with undefined hue, saturation or chroma, the defined value is used when available. For example, when interpolating from black to blue in HCL space, the intermediate colors are now dark blues (#241178) rather than dark purples (#600054). Fixes #833.
add ctrl, shift and alt modifiers for v-on
I've done the manual testing and , and looked at the PR diff. The only thing left to do is test it in Oracle. The code is simple and it is a hassle for me to work with Docker. I think if we merge it in, it might be easiest for GitHub's CI to tell us if it passes the Oracle tests. I know Oracle's not important, but we are so close! But for that, you have to merge it into the upstream because I can't do it from my fork.
extra/datasets #1155
In case user pass non-string as a tensor name, the code raises ValueError. One common mistake is to specify tensor object instad of its name. Unfortunately, in this case current implementation fails to produce an error message resulting in misleading errors like shown below. This PR introduce explicit type-checks of input parameters.
Remember to update the main readme () as well üôÇ This probably conflicts with #10691, so a rebase is needed
SUMMARY The sample value given for the 'mode' parameter is shown without quotes, but the data type is string. If you actually try to use an unquoted numeric string for this value (and don't use leading-0 octal notation...) you're in for a nasty surprise! I added quotation marks to the sample value. ISSUE TYPE  Docs Pull Request  +label: docsite_pr SUMMARY <!--- Describe the change below, including rationale and design decisions -- <!--- HINT: Include "Fixes #nnn" if you are fixing an existing issue -- ISSUE TYPE <!--- Pick one below and delete the rest --- Bugfix Pull Request - Docs Pull Request - Feature Pull Request - Test Pull Request COMPONENT NAME <!--- Write the short name of the module, plugin, task or feature below -- ADDITIONAL INFORMATION <!--- Include additional information to help people understand the change here --<!--- A step-by-step reproduction of the problem is helpful if there is no related issue -- <!--- Paste verbatim command output below, e.g. before and after your change --
You can preview ad81207 at . You can preview 2cbe888 at .
We voted against it at #514. At that time, the test worked locally, too. It seems, we are relying on the tests on Travis only. Can the tests themselves be fixed? Simon said:
Sigh. I have a working implementation, but I'm unhappy with the large code burden it adds.
I've changed my mind again: I think we should instruct people to install redbaron manually and run the script from the repo directly. With proper documentation, I can't see any disadvantages of this approach, given that this is a script that is probably used once and never again. With this reasoning, I'd like to close this PR.
Please check if the PR fulfills these requirements - [x] The commit message follows our guidelines:  - [x] Tests for the changes have been added (for bug fixes / features) - [ ] Docs have been added / updated (for bug fixes / features) What kind of change does this PR introduce? (check one with "x") What is the current behavior? (You can also link to an open issue here) 9613 What is the new behavior? On the first received value from an observable, decide to continue or cancel (de)activation. Waiting for completion is not required. Does this PR introduce a breaking change? (check one with "x") If this PR contains a breaking change, please describe the impact and migration path for existing applications: ... Other information: I believe this isn't a breaking change, even though the behavior is changed (accepting more than one value in the stream), because this wasn't properly documented. Also, I think is much more convenient to not require the observable to complete.
Regretfully, I ran into a case where I needed to mock a six-argument method. One can of course claim that such methods ought not to exist, but sadly, this is not always the reality and I think that some pragmatism is useful in tools like Mockito, so here is my attempt at adding support for it. Of course, it's possible to use the plain  interface in this case, but adding a dedicated  interface makes it more convenient on the user;  is a quite raw interface. (I'm not sure if this should target the 2.x release or  also, but feel free to cherry-pick as needed after review/merge.)
I'm not convinced this change pays for itself / is worth the extra dependency. The supported Node.js version is already defined in  as you point out, and our general policy on supported Node.js versions is well-documented. Generally it's a good idea to provide helpful error messages, but in this case I don't think it's worth introducing a new dependency. WDYT?
Many many thanks! üòä
Yup, I forgot about those. I'll take care of it later.
SUMMARY <!--- Describe the change below, including rationale and design decisions --updated an examples which includes how to use reboot module to include a message  ISSUE TYPE <!--- Pick one below and delete the rest -- - Docs Pull Request COMPONENT NAME Ansible built in reboot module  ADDITIONAL INFORMATION <!--- Include additional information to help people understand the change here --<!--- A step-by-step reproduction of the problem is helpful if there is no related issue -- <!--- Paste verbatim command output below, e.g. before and after your change --
Suggested as part of #1488.
so, it's a bit difficult for me to test this in a correct way.  on windows, tests are completely skipped. so i can run jest in the jest-haste-map package, but there 8 failing tests on a fresh master branch. also i created a linux mint virtual box, cloned a fresh jest repo, but tests are failing too. with just reading the code, i can not find the problem ('jest-util' is unmocked) :-( any ideas to get this running?
Hi there! Thank you for your advice. I close my pull request.
Sorry, maybe I poorly explained what my original problem was, or used poor choice of words. I had already read the quickstart, and was following along with the tutorial, and then hit a chapter that started talking about how to install my webapp. I had no idea why this would be necessary, since in the quickstart all I had to do was set some env vars and do . Further, I had no idea that it was even possible to install a package into my venv and have auto-reload automatically work (). I just wanted to set some env vars and run  and have it work. What I was shooting for in the paragraph I added in the PR is: "don't panic, when your webapp is a package (instead of a top-level hello.py script), you must install it and that's just part of the dev process". I'm fine with that explanation, and I think the reader will be as well (at least, where they are for now, in chapter 3 of the tut). I'm guessing that later, during deployment, when the instructions say something like, "so, install your webapp package into...", then the reader will be pleased to know that they already have their webapp set up as a package, and that this is one of the reasons it was useful to set that up in chapter 3 of the tut.
Closing since -opensource thinks that the added complexity does not justify its benefits.
please review (and merge if it looks good)
I also modified the generation of update() code, which is useless when the tag is not dynamic. In this case the generated code will correspond to this: I also edited an unit test for ajusting the expected result accordingly.
We were appending f to NAN and INFINITY constatns, and now we don't! Constants taken from 
I've seen that the bounty is already locked, but still wanted to post my take on the Bert's pretraining code.  If it's not worth including in the repo, feel free to close the PR. Details: For the Bert model, I've modified models/transformer.py to use prenorm, new_gelu activation and turned on gradient for the embedding layer, the rest is the same. Dataset prep is a modified version of nanoGPTs dataset preps. During training batches are sampled from the pretokenized train.bin blob and masked. I've ommited the NSP (Next Sentence Prediction) loss as it was shown in later papers to not improve models' quality.  I've run the code on A10 gpu, achieving ~6s/step with bert_base architecture (12 layers, 12 heads, 786 embed_dim, ffn = 4*embed_dim), context 128 and BS=32. Original Bert was trained for 1,000,000 steps with BS=256.
10
, I'm sorry that the merge could not be achieved this week as the PR enables hybrid model support by default in XNNPACK delegate which requires much more thorough testing internally with other Google products. So to move it forward, we may guard your change with some pre-defined macros. Thanks for your patience, and hope you could understand this. Many thanks again for your contribution!
Having this as a config flag sounds reasonable to me. For the reasons discussed in  I don‚Äôt think it‚Äôs good as a default, but for large apps it seems like a reasonable trade-off. Shouldn‚Äôt we make TypeAdapter lazy as well?
Good job! And sorry I didn't have time to do it yesterday :|
This PR adds support for the  method on event responders. This is essential for handling cases where an event component unmounts part way through workflow of an event that has multiple states (Press, Hover etc). To enable this, EventComponent fibers now have commit phase logic that triggers these from the DOM renderer. I also added TODOs with follow up logic to be added next week along with a test to confirm this behaviour works.  Ref #15257
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [ ] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [x] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [ ] It's submitted to the  branch for v2.x (or to a previous version branch) [ ] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [x] All tests are passing:  [ ] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
My mistake; I mistakenly introduced master. I will reopen another PR.
Hi! We appreciate the time you took to make the pull request, unfortunately this is not a change we desire to accept. Turning off the header provides zero security benefit and removes our advertisement from free software (similar to how your free WordPress site would declare it is WordPress at the bottom of the page, one could say). Please feel free to read previous discussions on this in  and 
IMHO blindly halving the specified timeout is not a good strategy, specially if the underlying issue is still unknown. Besides, there are a few issues with that implementation, from not handling a  value to shadowing the imported name
Thats true for almost every refactoring on this planet ;-).  Exposing implementation details to other classes are a no go even if it looks handy. I've seen more than one product that became unmaintainable after the sum of all technical depts get out of control. Every tiny improvement is a good invest for a healty product.
Closing it.
Some of the contents of  are specific to the three.js built-in materials. The remainder are handy, but may not be needed by the user.
Unlike what I said, travis-ci tells me the tests don't pass... i'll have a closer look.
WOW 
The argument name in the usage demonstration is wrong as per:  <!-- Please uncomment this block and take a look at this checklist if your PR is making substantial changes to documentation/impacts files in the  directory. Check all that apply to your PR, and leave the rest unchecked to discuss with your reviewer! Not all boxes must be checked for every PR :) If your PR modifies code of the  package, we have a different checklist below :-). Documentation PR  [ ] I've seen the  file [ ] This change runs in the current version of Plotly on PyPI and targets the  branch OR it targets the  branch [ ] If this PR modifies the first example in a page or adds a new one, it is a  example if at all possible [ ] Every new/modified example has a descriptive title and motivating sentence or paragraph [ ] Every new/modified example is independently runnable [ ] Every new/modified example is optimized for short line count  and focuses on the Plotly/visualization-related aspects of the example rather than the computation required to produce the data being visualized [ ] Meaningful/relatable datasets are used for all new examples instead of randomly-generated data where possible [ ] The random seed is set if using randomly-generated data in new/modified examples [ ] New/modified remote datasets are loaded from  and added to  [ ] Large computations are avoided in the new/modified examples in favour of loading remote datasets that represent the output of such computations [ ] Imports are  /  /  [ ] Data frames are always called  [ ] fig.add_fig.update_go.Figure(data=..., layout=...)fig.add_shapefig.update_xaxesfig.update_layoutfig.show()plotly.plot()plotly.iplot()plotly.graph_objectscodegen` files and not generated files. [ ] I have added tests (if submitting a new feature or correcting a bug) or   modified existing tests. [ ] For a new feature, I have added documentation examples in an existing or   new tutorial notebook (please see the doc checklist as well). [ ] I have added a CHANGELOG entry if fixing/changing/adding anything substantial. [ ] For a new feature or a change in behaviour, I have updated the relevant docstrings in the code to describe the feature or behaviour (please see the doc checklist as well).  --
+1 It will be very helpful to fix this. For instance, I'm trying to use fastapi with Mongodb, and I'am having trouble with the Decimal128 type for pymongo.bson which is not  natively supported by pydantic, so I would need to provide a custom serialization. The problem seems to be with collection types like sets, lists, etc.   
This affects the time spent in d3.interpolateString while building the interpolator, not time spent on interpolator execution. Fixes  #1826 and #1827. Two major changes here:  1) Use algorithm with compexity O(n) instead of O(n^2).  2) Replace calls to  with constructing a new array.  is not guaranteed to be fast and it's compexity could vary between implementations,  is always fast. First change makes the algorithm a lot faster, it was incredibly slow when some of the corresponding numbers in a and b were equal. The new algorithm: 1. Linear pass, using : fill  and , no significant changes. 2. Linear pass, using :    - fill  with interpolators for not matching values    - replace  with strings  for matching values, removing elements only from . 3. Linear pass, using the remaning of :    - replace  with strings  and pop data from . 4. Linear pass on , coalescing non-null values while accumulating the number of elements removed till the current moment in a counter, for example . Null values correspond to elements from , for each null value perform a single . This efficiently fixes all references to elements from . The second change makes the algorithm much faster for cases when many small intervals have to be removed or coalesced, but makes the algorithm about 10% slower for the case when no elements have to be removed (keeping the whole array). The interpolator complexity and execution time have not increased. The test results are not too precise, I ran each one only a few times. Worst-case for the old algorithm (0% different numbers between a and b):   12000 numbers:  20 ms instead of 300 ms.   60000 numbers:  90 ms instead of 13 seconds.  300000 numbers: 300 ms instead of 9 minutes. 1500000 numbers: 1.6 seconds. Average-case for the old algorithm (93% different numbers between a and b):   12000 numbers:  50 ms instead of   60 ms.   60000 numbers: 130 ms instead of 1250 ms.  300000 numbers: 520 ms instead of 41 seconds. 1500000 numbers: 2.8 seconds. Best-case for the old algorithm (100% different numbers between a and b):   12000 numbers:  25 ms instead of 20 ms.   60000 numbers: 100 ms instead of 90 ms.  300000 numbers: 550 ms instead of 510 ms. 1500000 numbers: 4.4 s. instead of 4.4 s. 1500000 numbers is a string with 2.1e7 chars, that's 20 MiB in one-byte encoding. Chromium 33, x86_64 GNU/Linux, i5-3317U. The results in Firefox are similar.
This PR aims to resolve #3602 by replacing all pandas'  calls by  calls in alignment with the corresponding 1.4.0 Release Notes. Since there should be no functionality affected, no bug fixed, no interface changed or similar whatsoever, we only changed the according calls in  and . To make sure we did in fact not change the intermediate results of these calls, we temporarily kept the old calls in, and asserted them equaling our new calls to . Locally all tests passed and after successful pipeline runs we removed these assertions and the old calls, to finally get rid of the s. This is my first contribution to Plot.ly, so please let me know, if I can improve anything. As of now the  job keeps failing although I have the impression, that  this is unrelated to my changes. Please let me know, if I can do anything to fix this. Code PR  [x] I have read through the contributing notes and understand the structure of the package. In particular, if my PR modifies code of , my modifications concern the  files and not generated files. [ ] I have added tests (if submitting a new feature or correcting a bug) or   modified existing tests. [ ] For a new feature, I have added documentation examples in an existing or   new tutorial notebook (please see the doc checklist as well). [ ] I have added a CHANGELOG entry if fixing/changing/adding anything substantial. [ ] For a new feature or a change in behaviour, I have updated the relevant docstrings in the code to describe the feature or behaviour (please see the doc checklist as well). 
Huh... The error I thought I would get didn't happen. I guess I'll fix the test failures and see what happens next.
Sorry it if it seemed hostile, it wasn't meant as such. Just that I'm dyslexic and long responses take me a long time to parse, as you can see from the volume of issues on pydantic, avoiding such time sinks is helpful. I actually skim-read your message above, but missed the part about duplication. That's my fault, but also kind of an example of what I was saying. I'll look into this more soon and let you know what I think.
SUMMARY <!--- Describe the change below, including rationale and design decisions --Fix copy-paste typo which breaks cluster argument of vmware_content_deploy_template <!--- HINT: Include "Fixes #nnn" if you are fixing an existing issue -- ISSUE TYPE <!--- Pick one below and delete the rest --- Bugfix Pull Request COMPONENT NAME <!--- Write the short name of the module, plugin, task or feature below --vmware_content_deploy_template ADDITIONAL INFORMATION <!--- Include additional information to help people understand the change here --<!--- A step-by-step reproduction of the problem is helpful if there is no related issue --If you try using the cluster argument of vmware_content_deploy_template you will get an error about how it cannot be found because it's looking for a resource pool with that name instead of a cluster. This fixes that problem.
I can add rest of them as well, #861.
I just was worry that we're opening a whole new can of worms while we're closing one üòÖ
These changes look good to me.
I was able to drop a field (subject = true | false), which helped a bit.  The switch to a constructor doesn‚Äôt seem to speed it up (even when allocating next/prev) but the code feels clearer.
In that case, I would suggest to revert #4579. But in 2.1.2, literally every invalid type was accepted. Yes, being able to reject all invalid types before runtime is ideal, but not at the cost of also rejecting valid types. With , all invalid non-Mapping types are still rejected, and non-dict Mapping types cause a very clearly written runtime error:  which cannot be misconstrued. Surely that is still a significant improvement over 2.1.2. In 2.1.3, where TypedDicts are not accepted, we would lose the ability to strongly type check our JSON-based API endpoints.
it looks like the tests fail? Did I do something wrong here?
Apologies on the late reply, it is easy to lose github comments in the stream. You would set "aliases" in the argument_spec as many modules do, and then the "if" statement when it detected those values would set to the others or otherwise key off the possible values. Example:
Unfortunately HTTPS cannot be activated on Github when there's a CNAME
Addressed your comments . I can make another issue between docstring templating between  and  as many methods share the same docstring (not just ) 
I think the error code constants make the code much more readable and show intent more clearly. Especially because new people are reading through the docs I think it's important to make constants the default. Also I'm not sure but I think in the docs the usage of constants and ints is rather inconsistent.
This moves us off of typescript@next to the slightly more stable release candidate version.
late comment re new-style class, please make a new PR to make that change.  I suspect it uses the old-style classes because it was written before new-style classes existed and never got updated.
Hmm, nevermind, weird, your change is already up-to-date. Let's try this again: Jenkins, test this please
Thanks indeed!
See the also the discussion on the issue: . Someone will need to understand why the docstring validation sees iteritems and items differently
thanks
You can preview 36dd6bb at .
Why is this PR not yet approved?! Are you owners just stalling or wth?!
thank you, that's made it super clear and I think I understand the problem now. I like the fact we could land such a change without needing to introduce breaking changes to the API.  what do you think about this?
This is just for the FB linting. (The directive is not respected by eslint ‚Äî only by arc lint.)
Hi I'm afraid no. But with  it should be easy to add the tag without adding it
The prominent use of "Symmetric logarithmic" in the tutorial and the call for a "symmetric" norm in #1806 makes me think that  might be a more intuitive name than . What do others think? I know we have a couple of votes already. One of the most difficult issues with adding the new norm to the tutorial was where to place it. It seems more commonly applicable than  which is appearing very early on and makes the case for symmetrical data in its description. The  appears quite late in the tutorial, so I have scrapped the use of  from the example and placed it above  for now. I am happy to move it.
Weird. It must be broken locale specifications in Mac OS X, then? The thing is, Mac OS X clearly understands the fr_FR locale correctly, because if you go to System Preferences  <img src="" width="245" height="57"
I altered border radius mixin for my in house team. We do a lot of sass work and I wanted a single mixin to reference that would also reduce markup in v4-dev it only reduced the bootstrap.css codebase by 27 lines. My team uses it a lot in development so it the code reduction is greater. I thought I would hand it over to the repository to see if it had any merit. I removed the dist changes, and am resubmitting a new request... my apologies.
actually, I think I still got it wrong and the correct way is to define params via the command builder interface.
Yes, I got the same relative results after compiling (and recompiling):
OK. Thank you so much.
I'm with you on being very cautious about introducing features without user feedback or request. I think that this exactly the approach the core team should have to build a great library. Thing is that in this situation there are users needing it. For example, I'm frustrated that myself and other engineers at LinkedIn cannot use strict stubbing (most of the tests use TestNG, there are also usages of custom runners). Another use case are existing integrations like Jukito, Springockito, etc. Users of those frameworks won't be able to take advantage of strict stubbing. In general, if the team chooses to implement a feature such us strict stubbing, then we should make the usage of the feature easy and flexible. We should not lock in users with JUnit. For example, Mockito has "" annotation and offers flexible way of using that annotation: with JUnit Rule, Runner and without them (initMocks() method). Also keep in mind that the new API is "" so we could potentially take it away if we don't find it valuable. Thoughts?
-Rath  hi, Sorry the delay.  I'm a triager and I've added a question on the pull request which contains instructions for triaging, .  I'm not sure yet if I have to do pull requests reviews.  If yes, then maybe the document can be updated with that information about PR reviews.  If not, then is good to know right ? :+1: 
I also just yesterday reviewed a PR to  where I pointed to this very awaited feature. Please also note from the examples provided by  and , that people are expecting to use it with generics on a right-hand side. You were against it, weren't you?
Thank you very much for this pull request, but changes to the router need to be made against the  package. On that note, the changes you are proposing are already part of  release, which you can try out with that release of the package mounted in your express instance 
PR Summary This PR adds gridlines to the last plot in the stylesheets example and adds an annotation  as well as a divider to clearly distinguish between subplots. This addresses  PR Checklist <!-- Please mark any checkboxes that do not apply to this PR as [N/A]. --Tests and Styling - [x] Is Flake 8 compliant (install  and run ). <!-- Thank you so much for your PR!  To help us review your contribution, please consider the following points:   A development guide is available at .   Help with git and github is available at   .   Do not create the PR out of main, but out of a separate branch.   The PR title should summarize the changes, for example "Raise ValueError on   non-numeric input to set_xlim".  Avoid non-descriptive titles such as   "Addresses issue #8576".   The summary should provide at least 1-2 sentences describing the pull request   in detail (Why is this change required?  What problem does it solve?) and   link to any relevant issues.   If you are contributing fixes to docstrings, please pay attention to   .  In particular,   note the difference between using single backquotes, double backquotes, and   asterisks in the markup.   We understand that PRs can sometimes be overwhelming, especially as the reviews start coming in.  Please let us know if the reviews are unclear or the recommended next step seems overly demanding, if you would like help in addressing a reviewer's comments, or if you have been waiting too long to hear back on your PR. --
Hello   Sorry i can't merge
OK
The CL rewrite install.ts to use the /browsers package. It should keep all existing functionality and have no observable changes.
thank you!
But this introduces the DoS attack vector the qs is trying to prevebt by having that limit in the first place.
I did a bit more testing. I don't seem to be able to poke a hole in this: results are exactly the same with or without these settings.
It's poor style - it's not clear for newbies what the "$" stands for.
When building  with makefile using this command,  we observed this error for determining host architecture
I get no error message related to signing from either the dmg or pkg. A minor "nitpick" is that the pkg displays a warning for it not being notarized ("... can't be opened because Apple cannot check it for malicious software.")
it'd be awesome if it's possible to have the best of both worlds :-). I tried with conda envs and specific versions of Python, and this branch: py3.6, tab completion works well with , but with py3.8, it does not work. Is it a linux thing then? To be continued...
<!-- First of all, thank you for your contribution! üòÑ For requesting to pull a new feature or bugfix, please send it from a feature/bugfix branch based on the  branch. Before submitting your pull request, please make sure the checklist below is confirmed. Your pull requests will be merged after one of the collaborators approve. Thank you! -- [‰∏≠ÊñáÁâàÊ®°Êùø / Chinese template] ü§î This is a ...  [ ] New feature [ ] Bug fix [ ] Site / documentation update [ ] Demo update [x] Component style update [ ] TypeScript definition update [ ] Bundle size optimization [ ] Performance optimization [ ] Enhancement feature [ ] Internationalization [ ] Refactoring [ ] Code style optimization [ ] Test Case [ ] Branch merge [ ] Workflow [ ] Other (about what?)  üîó Related issue link fix: spinÁöÑicon‰ºöÊØîËßÜËßâ‰∏äÁöÑÈ´òÂ∫¶Â§ö6px #42150 <!-- 1. Put the related issue or discussion links here. 2. close #xxxx or fix #xxxx for instance. -- üí° Background and solution <!-- 1. Describe the problem and the scenario. 2. GIF or snapshot should be provided if includes UI/interactive modification. 3. How to fix the problem, and list the final API implementation and usage sample if that is a new feature. -- üìù Changelog <!-- Describe changes from the user side, and list all potential break changes or other risks.  | Language   | Changelog | | ---------- | --------- | | üá∫üá∏ English | fix(style): keep Spin's container height the same as the son element | | üá®üá≥ Chinese | fix(style): ‰øùÊåÅspinÂÆπÂô®‰∏éÂ≠êÂÖÉÁ¥†iconÈ´òÂ∫¶‰∏ÄËá¥ | ‚òëÔ∏è Self-Check before Merge ‚ö†Ô∏è Please check all items below before requesting a reviewing. ‚ö†Ô∏è  [x] Doc is updated/provided or not needed [x] Demo is updated/provided or not needed [x] TypeScript definition is updated/provided or not needed [x] Changelog is provided or not needed   <!-- Below are template for copilot to generate CR message. Please DO NOT modify it. -- üöÄ Summary <!-- copilot:summary --### <samp Improve the appearance and layout of the  component by tweaking its style file. üîç Walkthrough <!-- copilot:walkthrough --### <samp * Fix the vertical alignment of the spin component by setting the font size of the spin container to zero and restoring the font size of the spin text to the base font size (link, link) in 
Nah, I like it more the way it is today ü§∑‚Äç‚ôÇÔ∏è If it hurts your perf somewhere - I'm open to the change. But there should not be any observable perf gains from this change. 
Replace them with an explicit list of files in tsconfig. I got this list by adding --listFiles to the jake-generated command. I did this because I mistakenly added a depedency from compiler/utilities.ts to compiler/factory.ts and couldn't figure out how dependencies were resolved because I forgot about triple-slash references.
Adding our Organizations. We extensively use tensorflow for all our AI applications. (I am also confused why this page is empty)
:+1: We need to fix #140; this is getting annoying.
Go for it. =)
Could you please check this commit for the mutable schema interface? It builds the host-side flatc using cmake ExternalProject_Add(). Then, we could use the flatc to generate the mutable schema interface.
Sorry for the delay in responding to this thread.  I have had to explore some of the implications of this change especially with respect to input_signature and TensorSpecs.  I submitted a change a few days ago that updates tf.function to accept composite tensors (including ragged tensor and sparse tensor), and will follow up with another change to add support for input_signatures.
This doesn't actually work and causes weird issues in the coverage graph:  (Coveralls doesn't merge coverage reports from different CI: )
Probably the same reason why the plist file doesn't get copied. Do we need to specify the resource folder somewhere? 
The documentation of  is unclear because it shows the input as an already sorted list. A result for a non-sorted list should be shown to clarify the operation.
LGTM! :+1: 
This spawned from the discussion on #732.  Rather than take a functional argument to 's  argument, a more specialized function seems to make more sense here.
I rebased against master and re-added my changes. Looks like I missed a couple of wonky space changes, in . I also changed to a hashing check rather than a iteration check.
I find being able to emit the 'all' group in an inventory script a handy way to support a kind of "group_vars/all script". For that the inventory script just have to emit { "all" : { "vars": { "var1": ...., "var2": ... } } } So raising an error for { "all": { "hosts":  [...] } } would not bother me, but I'd like to keep the "vars" entry ;-)
I think I still prefer keeping  option at least for one more release. While I don't think there have been any bugs reported with the v8 coverage, I assume that's because people don't use it. And instead of people upgrading, seeing numbers they don't like (hopefully report it as it might be a bug) and staying on v29, they can still use 30 and just flip a config option. Then for Jest 31 remove it. Thoughts?  If we're sure we want to do this (clean break in v30), then I think we should try out some big repositories using Jest and see how the coverage compares manually and try to fix any regressions (if there are any). Moving to something that's faster but worse (i.e. less accurate - I don't care if coverage numbers goes down (or up, for that matter), only accuracy of coverage reported) isn't necessarily a net win in my eyes.
This is a follow-up bug fix to #11090, so I think it doesn't need a changelog entry?
Fixes #27552
All this can be done with standard string operations, but you would have to implement parts of what the re module already has. It would be easy if we could just do a s_auth.lower() on the whole thing and replace what we need, but the case on the rest of the string is important. The way I see it there are 2 choices. Either we use the re module, or we add code to do a case insensitive replace in requests itself. Basically its a choice between overhead (which I'm not convinced is much) and code complexity. :) Pisses me off that web server developers don't read the damn standards before implementing something :angry: .  P.S. Get better soon! :D
Were or are? üòï üòõ I definitely agree this should be in the guide üíØ  My concern is that we are complicating the conventions one has to follow, which will inevitably result in them not being consistently followed üòü I would love if we could simplify things. For example, if  should always be used with , then we might be able to get rid of the nested  and style the  (or the contained imaged) instead. Or if most s will use , we could make it the default and have another class to "opt-out" of the  styling.
Agreed, but there are some situations where  headers are acceptable; the most notable example being the pseudo-standard  used by  to determine if the originating request originated from an  from the browser. I do like your middleware solution idea, but I'd rather not pollute my query strings with metadata that is better represented in a header.
These are 2 installers plus one portable version. So in the end 200mb for one installer, which is approximately the same size as install4j
From a positioning PoV, a twinned axes is just like an inset axes whose position exactly matches the parent's position.  Doing so removes the need for the heuristic in / where a non-gridspec-managed Axes would track the position of any Axes with which it shared either xaxis or yaxis, which was a proxy for twinning (per 721b949).  This would cause incorrect behavior in rare cases such as where the  call would make the second axes go on top of the first. PR Summary PR Checklist <!-- Please mark any checkboxes that do not apply to this PR as [N/A]. -- - [ ] Has pytest style unit tests (and  passes). - [ ] Is Flake 8 compliant (run  on changed files to check). - [ ] New features are documented, with examples if plot related. - [ ] Documentation is sphinx and numpydoc compliant (the docs should build without error). - [ ] Conforms to Matplotlib style conventions (install  and  and run ). - [ ] New features have an entry in  (follow instructions in README.rst there). - [ ] API changes documented in  (follow instructions in README.rst there). <!-- Thank you so much for your PR!  To help us review your contribution, please consider the following points:   A development guide is available at .   Help with git and github is available at   .   Do not create the PR out of master, but out of a separate branch.   The PR title should summarize the changes, for example "Raise ValueError on   non-numeric input to set_xlim".  Avoid non-descriptive titles such as   "Addresses issue #8576".   The summary should provide at least 1-2 sentences describing the pull request   in detail (Why is this change required?  What problem does it solve?) and   link to any relevant issues.   If you are contributing fixes to docstrings, please pay attention to   .  In particular,   note the difference between using single backquotes, double backquotes, and   asterisks in the markup.   We understand that PRs can sometimes be overwhelming, especially as the reviews start coming in.  Please let us know if the reviews are unclear or the recommended next step seems overly demanding, if you would like help in addressing a reviewer's comments, or if you have been waiting too long to hear back on your PR. --
I could have add this method in the ArgumentMatchers class (which would have been a better solution), but I didn't want to change it because it has not been updated since last year
This isn't a mistake actually.
Oops, sorry. Yes both StringPiece and Status should be passed by value.
üìù Update docs for testing, fix examples with relative imports. Should solve, related to 
For networks that have both a v4 and a v6 subnet, the floating IP plugin currently has two problems: - When determining the subnet for the provided , it   assumes that the first item in the list of subnets is the one you want.   Instead, it should pick the first v4 subnet. - When multiple fixed IP's exist for a given port (as is the case in a network   a v4 and a v6 subnet), neutron needs a hint as to which fixed IP to associate   to the floating IP address (the v4 one).
You can preview 09ea2eb at .
<!-- Thank you for creating a pull request. Before submitting, please note the following:  If your pull request implements a new feature, please raise an issue to discuss it before sending code. In many cases features are absent for a reason. This message body should clearly illustrate what problems it solves. If there are related issues, remember to reference them.  Ideally, include a test that fails without this PR but passes with it. PRs will only be merged once they pass CI. (Remember to !) Because the site probably shouldn't deploy links to . 
Unfortunately, we still can't update grunt to 1.x. /CC  
As long as it picks up the installed freetype package to build with, LGTM.
thanks for this. Sorry it went unreviewed for awhile, but it will need to be rebased now if you're still interested in getting the change in
This relies on a globally-installed copy of Vows, rather than using the version of Vows that is required by D3. This is undesirable because it means the user will have to install Vows manually (as ) rather than the standard method using package.json (). Also, this approach won't work if the user‚Äôs globally-installed version of Vows is different from the one D3 depends on. I'm not familiar with Cygwin, but I'm afraid you'll need to solve this error a different way.
removed, check please.
In my personal actual experience, the  badge might be more useful than , ü§™ let me explain: I've seen a lot repo with  but they are working fine, and a  means not too much unless I checked the source to make sure it has a complete test suite, it's time consuming so I don't do this often. On the other hand,  are simpler and clearer. When I first saw a package I would check it's install size, and when I saw a new competitor I would compare it with the famous champions too, like  vs  vs . Overall, build status more like for developing, and install size more like user land concern, relatively speaking. +1 for (1).
I've updated as suggested. 
PR Summary More information, less wordy. :smile: 
<!-- Thank you for your contribution! --<!-- Unless your change is trivial, please create an issue to discuss the change before creating a PR --<!-- See  for help on Contributing --## Change Summary <!-- Please give a short summary of the changes. --We introduce a new Model config attribute  ( by default) which is the case of being set to True enables invalid data output, i.e.: Related issue number 1421 <!-- Are there any issues opened that will be resolved by merging this change? -- Checklist  [x] Unit tests for the changes exist [x] Tests pass on CI and coverage remains at 100% [x] Documentation reflects the changes where applicable [ ] `changes/<pull request or issue id  (see changes/README.md for details) 
Good though, kennethreitz! Please, apply this pull request, it will make world better ;-) 
Please review 
I'm with  that the tab-completion shouldn't do any magic hiding - I've learned the hard way (in some of my own personal code) that this can cause a lot of mysterious confusion. As for returning a value and not a quantity, I see 's point that this is a bit arbitrary.  But my concern with only turning it on some of the time is that then users will get even more confused because once they start using e.g. , they won't be used to it from more generic  objects.   Also I don't really see why this is any less useful for a generic  vs. something specific like .  In both cases I sometimes want to "quickly" get a value in a particular unit. 
I went through all the changes and created a follow-up PR at .
Yes indeed. Were you able to get Gradle working on your machine?!
I see a couple of failures from  that I wouldn't expect to be related to this change, eg: "should throw with non-object in the initial state property" (from the various class-equivalency tests) That's a bit odd though b'c you didn't even change this line with the diff. Edit FWIW, it looks like the  method that throws this error is only run in dev, so these tests should probably be DEV-only. Maybe we should change them too? eg
The confidence of one of the predictions is much lower on the CI server. I'm getting over 90% on my machine, and around 58% on the server. I guess it has something to do with the dependencies. But the test is passing now.
I don't think this should be in v5.0.0 project. I see some issues with the tooltip being stuck in shown state.
thanks! :) On Fri, May 27, 2016 at 5:31 AM, Chelsea  wrote:
Inheritance schemes:   All dictionaries containing data now subclass from Trace. Data means   something completely different now. For example:   Data now refers to a PlotlyList, which makes more sense.   No more mako:  using templating from mako was starting to be more trouble than it was   worth. We were forced to develop in a hidden file, installing required   extra steps, and the documentation was scattered.  Added metaclass:  meta classes are classes that create classes. Python's usual meta   class is , this creates all classes. By subclassing type, you can   make python < 3.3 docstrings mutable, hooray! so far, only DictMeta, a class to create PlotlyDict subclasses has   been created. IMPORTANT. A lot of headache was saved by cheating a bit and using   class names as keys in the INFO dictionary. Therefore, ALL CLASSES   SHOULD HAVE A MATCHING (lower case) ENTRY IN !!! 
I don't think there is a reason for the leading underscore in this section of documentation, but if there is, this pull request can be ignored, or used to clarify the documentation. 
Vertically centered modal example code requires .modal-dialog-centered class with the .modal-dialog class to correspond with the working example.
Conflicting files pandas/tests/arrays/categorical/test_replace.py
Thank you  for your contribution! :rocket: :bow:  And thanks  for the review/approval! :coffee: :cake:  I'll just wait for an approval review from someone else before merging. Maybe  or  , if you have the chance, could you review this? :pray: 
This just makes the accordion into the panel‚Äîthat's not something we'll accept. And thinking about it more, we should just drop the accordion entirely and focus on extending the collapse functionality. Will look into that.
Yes, I have updated Xcode to 8. Here is my environment: - Xcode: Version 8.0 (8A218a) - iOS: 10.0.1 (14A403) I can run an application with this change on iOS simulator, and iPhone 6. As you said, I built and ran successfully without this change on Xcode 7.3 in the past (2 months or so). Recently I updated my device's OS from 9 to 10, and it requires Xcode 8, then  error happens. I'm not sure this is caused by some source code change in the repository, or by Xcode 8.
PiperOrigin-RevId: 387738023 Change-Id: I83d18d36a7b82ffd2a40b5124a4e5b4c72238f27
PR Checklist Please check if your PR fulfills the following requirements:  [x] The commit message follows our guidelines:  [ ] Tests for the changes have been added (for bug fixes / features) [x] Docs have been added / updated (for bug fixes / features)  PR Type What kind of change does this PR introduce? <!-- Please check the one that applies to this PR using "x". -- - [ ] Bugfix - [ ] Feature - [ ] Code style update (formatting, local variables) - [ ] Refactoring (no functional changes, no api changes) - [ ] Build related changes - [ ] CI related changes - [x] Documentation content changes - [ ] angular.io application / infrastructure changes - [ ] Other... Please describe: What is the current behavior? <!-- Please describe the current behavior that you are modifying, or link to a relevant issue. -- Issue Number: N/A What is the new behavior? Does this PR introduce a breaking change?  [ ] Yes [x] No  <!-- If this PR contains a breaking change, please describe the impact and migration path for existing applications below. -- Other information
Can you give some more details about this change? What's the source?
non-blocking, are we pushing this up to pypi though? i feel like we might want to just allow folks to download from github master for a bit? :dancers: 
The original sentence has incorrect grammar. The change corrects the grammar error and expresses the intended meaning better <!-- Commit checklist:  add tests that fail without the patch ensure all tests pass with pytest add documentation to the relevant docstrings or pages add versionadded or versionchanged directives to relevant docstrings add a changelog entry if this patch changes code  Tests, coverage, and docs will be run automatically when you submit the pull request, but running them yourself can save time. --
Kenneth Reitz is still the author, but David Baumgold is now the maintainer; there doesn't seem to be a good way to indicate this. :(
I REALLY like where this is going. In general, it feels that if someone uses JUnit, lazy verify should be the default, no? I‚Äôm not happy about extra public on Mockito class and the VerificationStrategy. Both APIs seem to be ‚Äòinternal‚Äô, not really for regular users. Also, I feel uneasy about adding mutable state MockitoCore object. If we need such state, MockingProgress is the way to go (thread safe to the level sufficient/required in Mockito). I‚Äôm wondering if we should start implementing some kind of listeners to the Mockito frameworks so that it is possible to implement such features easily. (brainstorming) Mockito.framework().addListener(x); VerificationListener {   verificationStarted } I need this kind of API/listeners, too. However, I‚Äôm not sure how well it fits your use case. I‚Äôm working on adding automated validation of unused stubs to the JUnit runner and the Mockito JUnit rule. In order to fail the test when it has unusued stubs, I need to a) set a listener that gets notified when stubbing is done / stubbing is used b) run test c) ensure that all stubs were used out. Thoughts? If that works better, we can brainstorm & discuss before you cut code. I don‚Äôt want to discourage you by my endless grumbling about how things should be implemented üòÉ THANKS for pushing for this feature. I think it‚Äôs cool.
Ahh those use NVIDIA's nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04.  That explains why they do not use the same process.  I would guess (CONFIRMED, see next comment) nvidia already moved those to 7.6.2; but I am feeling good and will give a look this morning and report back.  The good is they are likely updated faster than our offiical dockers, the bad is they may not always be aligned; which may be ok 95% of the time.  The 1% or 5% is the fun.  
did you open a new issue for this discussion? 
It is the same error as in #26800 (when trying to customize LESS variables):
if you can thing of a better name that storer let me know) you don't need knowledge of the internals just reading the docs for various formats that u can store lmk if this is still unclear
y u no squash button
The codesandbox with your solution raises  which is probably rooted in  where checks the existence of  in , i.e., . In your code,  is set as  that does not include the . Although it does not resolve the issue, to get rid of the error, you may add  to the object. Please see codesandbox
Previous attempts at fixing the time related tests failed. Indeed the previous attempts are not bullet proof when the CI can run schedule some threads slower than expected. A proper harness should be implemented, but in the meantime, I implemented the retry rule as proposed in #731 to gain back stability on the build.
This is a similar pull request to  but for r1.4 branch, not master. When using tensorflow as a submodule in bazel, importing bazel rules from tensorflow.bzl is not working. The main reason is that some of the dependencies are hard coded instead of using str(Label(...)) and this makes bazel to generate dependencies like //tensorflow instead of //tensorflow. Most of bzl files under tensorflow use Label mechanism to allow supermodule to import tensorflow bazel rules like tf_cc_test, etc, but there were two files that did not use the Label mechanism and these two files block supermodule to import tensorflow bazel rules. This change updates those files to unblock bazel rule importing.
Sorry for the late reply, I went on a vacation last week :) This isn't directly related to Google's adoption of a new test runner (I don't work there anymore so I'm a bit out of the loop). I got started on this project as a means of making the  run under bazel more or less without any special customization. The Angular CLI is capable of running jest when using the  package that my company I work for maintains. And in addition to that, I just like jest and want it to be the defacto test runner for running JS tests under bazel. One question. I'm willing to augment  to have the same behavior if need be (it doesn't affect the bazel use case, but if its a requirement for getting the PR merged I could be persuaded to make a PR). So my question to you is, is that a hard requirement for getting this logic merged? Could it be made to be follow up work after merging this PR?
TEST
Yeah, so how we approach this is basically dependent on whether we think it's acceptable for  to go in . I personally think that's the best place for it, because it allows us to avoid duplicating the large amount of knowledge  has about how this variable is structured. However, IIRC  originally objected to that idea so I'd like to hear from him.
(or  for highly-specular materials) should be specified in linear space. Without handling this correctly, the rendered color will be incorrect. Scene light colors should be specified in linear space, too.
Thanks ! :sparkles: :cake: :sparkles: 
You misunderstand the ,  is different from ,  limits which dates the user can navigate.
‚ú® Add support for Pydantic v2
I guess I tend to be pretty conservative about what to call a bug if it is going in a bugfix release. Basically the question is whether it is credible that some user out there is taking advantage of this existing behavior and their code will break after installing a bugfix release. I take that contract very seriously. It seems very unlikely that anyone is using that, but it is tough to prove otherwise. Usually to me for an API change like this to get put into a bug fix, I would say it is OK if the original behavior was so wrong that nobody could be relying on that behavior. Here that is not unambiguously the case, but I agree it is in the grey zone.
oops
This should be there. <track kind="captions" Before submitting the PR, please make sure you do the following  [x] It's really useful if your PR references an issue where it is discussed ahead of time. In many cases, features are absent for a reason. For large changes, please create an RFC:  [x] This message body should clearly illustrate what problems it solves. [x] Ideally, include a test that fails without this PR but passes with it.  Tests  [ ] Run the tests with  and lint the project with  
That's awesome, thanks ! We've had reports of slowdown on large suites for 23 vs previous, this might be part of the issue (#5085 landed in 23 (thanks changelog!))?
We have a use case where we run TensorFlowOnSpark from Apache Livy. When we set HADOOP_USER_NAME then we get an impersonation error saying that User_A cannot impersonate User_A, which is correct since we don't give permissions to User_A to impersonate other users, hence not itself. Nevertheless, when I set HADOOP_USER_NAME Tensorflow does access HDFS as that user, so I suppose there is no need for a patch.
Personally, I'm not a fan of this yet. This will be easier to achieve when we have CSS variables available, otherwise this will be a PITA to maintain. We can't also just add a dark mode to our docs and don't support it in our components. It will just look too weird to have light components (like modals or dropdowns) in a dark documentation. An other aspect is color contrast, we already struggle to get the color contrast on point without the dark mode, checking two modes won't make that easier.
It was merged almost a year ago:  milestoned 1.1, released Jul 28, 2020.    They are currently on 1.2.4.  I would guess that if someone updates Matplotlib they would also update pandas?  Worse that happens is someone gets a deprecation warning for a while if they use a new Matplotlib and an old pandas.  
Yes please. Let's get this PR done. What relevant function that we can add at  section? Any hint? ?
Backport PR #15556: Fix test suite compat with ghostscript 9.50.
Not sorting the indices is fine. This looks good to me. Thanks, !
Anyone who wants something fancier should use modules. - fixes annoyance with not being able to set 'name' property on locals This is for 4.0 and is a breaking API change.
Fixes #33325
Just removed the arrow function.
I believe  is the way it is to specifically catch badly (i.e. non-ISO) formatted dates and raise a . Also,  states that you cannot use PositiveInt because of coercion, but then end up coercing the value anyways? 
Do you know if this handler is still needed? I suspect it isn't, but I'm trying to think as to whether or not this is needed for Windows or something.
Thanks in advance! No hurry. Happy holidays!
Adding an error message to an assertion that I have experienced on two separate occasions, that all custom exceptions must inherit from the builtin Exception class. This PR will throw the new message to those who decide to create exceptions that aren't subclasses of Exception, e.g. BaseException
Mostly for my sanity. It's hard to keep track of what is enabled where if it's not enforced.
is not meant to be used as an instance method, and should never modify the input object. It seems this is just meant to address the case where you do an invalid  as brought up in , but: * Using  to create improperly-initialized models is not how it's meant to be used, and is not a workflow we want to accommodate * As a rule, passing an input to / shouldn't modify that input * This adds some overhead to / for everyone to avoid issues caused by invalid ; and given how performant we've made validation through the use of rust, I suspect this overhead is significant for some cases (such as , for example). As a result, I think this PR is not likely to be merged.
Thanks for the PR! We just released new docs mostly written from scratch. However this means that all old localized content is gone, as new one needs to be written. We will track this effort in . The goal is to make it easier for people to review localizations so you wouldn't have to wait for the core team, and your PRs would be reviewed much faster. Sorry, and thank you for your work!
I don't think it is appropriate to create "official" support forums without previous notice. Also, i don't think many people are using Facebook for open source projects or even anything development related.
adopting TypeScript more widely is great! do you think we could break up this PR into multiple smaller PRs? E.g. upgrading dependencies seems like it could be fairly separable
As of the last time I checked, no. I'll try again though and edit this comment with the results. Clearly I was wrong. :)
Thanks for the interest! I'm actually not sure about this. I don't think that "valid" fully conveys the message here, I feel it makes it look like the code is valid or not, but it's not about having the code valid, but the fact that Pydantic has support for it. I would think the word "supported" could work better, but it is also used in the same sentence afterwards. What do you think?
If nobody has a better way to implement this, should we call it good? Tests are passing. üôÇ 
Fixes the type we return in  for . and  when the expression is an `Iterable<Promise<T Fixes #24570
Improves error message for when a  call uses the hidden: true option. Rather than just saying it will say (when appropriate). Addresses #2854, replaces PR #2909
Signed-off-by: Trishna Guha < SUMMARY <!--- Describe the change, including rationale and design decisions --fixes  <!--- If you are fixing an existing issue, please include "Fixes #nnn" in your commit message and your description; but you should still explain what the change does. -- ISSUE TYPE <!--- Pick one below and delete the rest: -- - Bugfix Pull Request COMPONENT NAME <!--- Name of the module, plugin, module or task --modules/network/nxos/nxos_bgp_af.py ANSIBLE VERSION <!--- Paste verbatim output from "ansible --version" between quotes below --
fixes#9703
Hi , could you please rebase this PR, so we rerun all tests against the latest master? Since it's a pretty major upgrade, I just want to make sure master is still green. Thank you.
‚Ä¶ total. This is confusing. Assuming only two test suites have no-runtime errors here is the output: Previously: 77 tests failed, 8 test suites failed, 9 tests passed (86 total in 2 test suites, run time 3.33s) New: 77 tests failed, 8 test suites failed, 9 tests passed (86 total in 15 test suites, run time 3.33s)
Small update: fetch now supports abort  Need to make sure that polyfill (especially that is bundles with c-r-a) supports it. 
I'm not actively participating in the translation efforts any longer but I would encourage you to create a separate pull request with a new translation.
See issue 4142. Currently show() does not exit after all windows have been closed. The relevant code was in src/_macosx.m, but was inadvertently lost in pull request 4006. This bug fix checks the number of windows remaining after closing one window, and calls [NSApp stop: self] if there are no more windows. One open question is how Python show respond to keyboard interrupts (ctrl-c) while show() is running. Currently ctrl-c does nothing (other than printing ctrl-c to the screen). I guess it would make sense for ctrl-c to cause show() to exit.
I'm not sure what the exact training time will be, its taking me about 1 hour 30 for the eval step, but that's for a BS of 1, the BS can def be bumped up on a 7900xtx. Lets say about 10x off, I think the big thing will be multigpu. Is it fine if I lock the multigpu bounty and just do it on a tinybox? cuz my system doesn't have multiple gpus. tho it should probably be doable with like the torch backend on cpu and a gpu, i don't see why not. Do you have a specific communication protocol allreduce should use? NCCL? or just some python multiprocessing stuff?
bc it is only passed from _idxmin_idxmax, could we avoid having the argument at all and just do the post-processing there?
I'd merge the colorizer (if it's clear from code it's just a colorizer), I think the formatting is fine from what I've seen. The risk is that it misprints the ptx and that bug wastes hours of someone's time.
Implementation of commit should not be just a copy. Usually it compares candidate with running and deploys the differences. This is important, as you don't want to have any service interruption or breakage in stats collection in services or protocols untouched. Saying this, implementation of edit-config against running might be different dependent on the protocol stack used. There are implementations which process the edit-config request as single transactions - while others might do more imperative/ordered style config. Unclear, if this really matters to playbook authors. Clearly you would always prefer transactions against no transactions - but it will always depend a bit on the actual implementation and users should be aware about it. Potentially this is one of the bad takes in the NETCONF RFC, as they provide some flexibility which leads to different behavior on different boxes. /wiso -------- Urspr√ºngliche Nachricht -------- Von: Leandro Lisboa Penz <Datum:03.04.2017 23:25 (GMT+01:00) An: ansible/ansible <Cc: "Wisotzky, Sven (Nokia - DE/Stuttgart)" <Betreff: Re: [ansible/ansible] Update netconf_config.py to include option for datastore and improve error handling (#23199) I've tested this with , which uses openyuma, and it's ok. Code is looking good too. I'm just wondering if we shouldn't document a little better the fact that the selected datastore simply selects the mechanism used to activate the configuration. I mean, if you select datastore=candidate, the module sends the configuration to the candidate datastore and then commits it, which will have the effect of copying the candidate over the running datastore. ‚Äî You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<
Hi!  I'm so excited to see webpackbar is being used for ant-design build system! There were minor inconsistencies by one of the 3.x patches that caused an error reported in nuxt/webpackbar#30 (Related commit 5204b45e01e91026c8cc63dba343b1c67ca8f7a0) (Sorry for that üôè) After that I tried to personally investigate some inconsistencies and finally with  not only problem resolved, but webpackbar is much stable with concurrent logs! IMPORTANT: As antd-tools is a dep of this repository and also uses webpackbar, ant-design/antd-tools#81 should be better applied and published first.   [ ] Make sure that you propose PR to right branch: bugfix for , feature for branch . [ ] Make sure that you follow antd's code convention. [ ] Run  and fix those errors before submitting in order to keep consistent code style. [ ] Rebase before creating a PR to keep commit history clear. [ ] Add some descriptions and refer relative issues for you PR.  Extra checklist: if isBugFix :  [ ] Make sure that you add at least one unit test for the bug which you had fixed.  elif isNewFeature :  [ ] Update API docs for the component. [ ] Update/Add demo to demonstrate new feature. [ ] Update TypeScript definition for the component. [ ] Add unit tests for the feature. 
Related issue: - Description This PR ensures  does not support  anymore. If users want to use the exporter with , they have to perform the conversion to  by themselves.
equivalent
Thanks so much, I'll try to cherry-pick this only the 1.9 branch to update docs later.
Damn, sticky fingers today. Closed the issue. 
Would most programmers expect this? I'm not sure that I would. I think the reality here is that we have discovered that a concern originally raised in #3607 was correct: our defense against  being  was there not so much because we needed it but because downstream libraries were patching our objects in such a way that  was . From my perspective then, there are two sensible choices. Number one is to change this patch such that we tolerate the actual problem: namely, that  is . Number two is to decide that we simply don't support  being , and the error is exactly correct. I think I'm leaning towards number one, if only because we've handled this kind of problem in the past (admittedly with an overbroad  block).
Just a small cleanup that uses some newer language features to delete ~10 lines of code form .
LGTM :+1: 
You can preview 3776aa5 at .
4102
awesome, thank you very much.
SUMMARY Fortinet is adding Ansible support for FortiOS and FortiGate products. This module follows the same structure, guidelines and ideas given in previous approved module for a parallel feature of FortiGate (webfiltering): In this case we are providing a different functionality: "Firewall IPv6  EH (extension header) filter". Please note that this will be part of other modules to come for FortiGate, including different functionalities: system, wireless-controller, firewall, webfilter, ips, web-proxy, wanopt, application, dlp spamfilter, log, vpn, certificate, user, dnsfilter, antivirus, report, waf, authentication, switch controller, endpoint-control and router. We plan to follow the same style, structure and usage as in the previous module in order to make it easier to comply with Ansible guidelines. ISSUE TYPE  New Module Pull Request  COMPONENT NAME fortios_firewall_ipv6_eh_filter ANSIBLE VERSION
The issue is that if we still need the context in user space, what do we gain by adding it in the reconciler? Other than slightly more overhead. What you could do is make this a prod context too and use it to swap to RCTVirtualText automatically in the renderer instead of in the wrapper. It's a bit unfortunate because we have to add conditionals that gets tested for every kind of view, not just text.
The failing test seems unrelated to the changes I made.
This is a comment that describes the purpose of a class.   [ ] Change in CHANGELOG.md described [ ] Tests created for changes [ ] Manually tested changed features in running JabRef [ ] Screenshots added in PR description (for bigger UI changes) [ ] Ensured that the git commit message is a good one [ ] Check documentation status (Issue created for outdated help page at help.jabref.org?) 
I am always interested in learning new things. Currently I'm not up to date with this PR. Is this meant to update this PR or address issues in the Rework? But it eventually would be a slow process. What about the JavaFX Team from /stupro  ? :smile: 
Woohoo!  Jenkins, test this please.
fix(Launcher): PUPPETEER_CHROMIUM_REVISION not used when launching chromium #2490 Check for PUPPETEER_CHROMIUM_REVISION when launching the browser, can be used during installation
-Harris  +1!
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [ ] Feature [ ] Code style update [x] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [ ] It's submitted to the  branch for v2.x (or to a previous version branch) [ ] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [x] All tests are passing:  [ ] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
I'm getting some weird behavior now (working off the latest master). calling  now doesn't do anything...it looks to output something, but no plot is ever shown. It looks like something along these lines was changed recently...is anybody else experiencing this?   
for services that require Authorization in the header, all redirect calls to a different domain would result in a 403-Forbidden.  Authorization should be preserved just as Authentication is.
It was not introduced by this PR, but the behaviour when there is a very large number of cols/rows is weird. For example or  give errors like which is not very helpful as an error message. Should we either introduce a limit in the number of cols/rows, or try to catch this and output a better message?
This is a really old one and all callers have since been codemodded away anyway because of problems. This file is not really as rigorously maintained as the official Flow types but has a few more specifics. However, the inconsistency causes problems when you try to pass files typed using the built-in Flow typing for React and mix it with these. We just happen to get away with it because we compile out the types. If we didn't we would hit those problems by even using these in our renderers. We should only use the official types externally. Ideally we should tighten up the external types and then just use those internally too.
/ping  
Remove AUTHORS file Reason  AUTHORS file is hard to maintain Github/Git is single source of truth some authors did not want to be listed by name -- AUTHORS list also includes 12345 and duplicate names that look odd (and that was the reason why we had mailmap and such to avoid it)  Solutions  link to  autogenerate file entirely as AUTHORS and ignore duplicates etc use something like  to generate file  Decision  Change info dialog to link to contributors global RM search for AUTHORS (.gitattributes) RM .mailmap disable fullscreen and resize  <!--  Describe the changes you have made here: what, why, ...  Link issues that are fixed, e.g. "Fixes #333". If you fixed a koppor issue, link it, e.g. "Fixes ". The title of the PR must not reference an issue, because GitHub does not support autolinking there. --  <!--  - Go through the list below. If a task has been completed, mark it done by using . - Please don't remove any items, just leave them unchecked if they are not applicable. -- - [ ] Change in CHANGELOG.md described (if applicable) - [ ] Tests created for changes (if applicable) - [ ] Manually tested changed features in running JabRef (always required) - [x] Screenshots added in PR description (for UI changes) - [ ] Checked documentation: Is the information available and up to date? If not created an issue at <
Cancel my last. Fixed by changing to
Travis CI jobs were failing inconsistently,  The gradle forked process that executed tests was killed by the travis VM, hence the build failed with the following log without much clue, but the exit status code .  On the JVM it is the same as bash or zsh, when a program is "closed" with a signal, the exit code is  + the signal code. There , in other words the process ha received the  signal. Other project have experienced that since a month (e.g. ). Indeed removing the container mode made the build run correctly. I took the time to tweak a bit more the build - by leveraging the travis caches for gradle downloads - by using the compressed oops for the 64bit JVMs (it should help only a little bit) - by upgrading to gradle 2.11 - by reactivating code coverage
I think it makes sense to be able to specify these for the pie chart layout so that one does not need to apply these to the arc. After all, someone using the pie layout most likely does not want to manipulate the individual arc lengths. This change also adds default values so that if an inner radius is not set the arc.centroid function does not return NaNs. As cool as donut charts are, I'm sure there are people who may not specify the inner radius and wonder why they can't have labels (as I ran into while learning).
üëç, will clean dead imports out and rm this PR. Thanks,  -David
According to xt, it only returns  (i.e. not ‚Äú2d‚Äù | "webgl" | "experimental-webgl‚Äù, when new non-standard renderers are omitted). It used to be that way, but was changed part of this (huge) commit, 1c9df8446a1112d7a9c002293d0040068f706416 I cannot find the originating commit in the PR:  but it must be somewhere (my git skills are average). This fix might make some people happy: this error generates tons of useless and annoying non-null  type casts when working with canvases.  [ ] There is an associated issue that is labelled   'Bug' or 'Accepting PRs' or is in the Community milestone [x] Code is up-to-date with the  branch [x] You've successfully run  locally [x] You've signed the CLA [ ] There are new or updated unit tests validating the change 
Giving permissions away is always something that can create concerns, I know. This is why, in more recent PRs, I've added another paragraph to the instructions: The only thing that autopublish.meteor.com does is creating a new webhook on the repository (for which write permissions are required...) and this is once for all. the other solution might be manually creating the webhook, but I would have to add some code to autopublish.meteor.com to pick up the first test payload as a new registration (I'll be happy to do it...) If you still have concerns and you don't mind doing it, running  after the build would be enough (I guess your meteor.com user was already added to the package maintainers). Among the three I'd prefer the second one to get the webhook, but feel free to go for the third (or the first one ;-) ): I'm open to every solution. What do you think ? Thanks for the positive feed-back  !
Yep, I was thinking this as well. Happy to abandon this one in favor of a "jump to provider" feature combined with #18255 You mean like It's not always obvious where the value of a provider comes from. Could be a memo or useState or useReducer hook. I think editing the value directly is more straight forward.
Done.
sorry for the delay. the express docs have moved from the gh-pages branch to 
sounds good.  I'm especially agree/am concerned with this point:  "I do think it's confusing to try to remember which Capital Letter chart types require you to call get_trace and which ones "you can just plot"."
This is a shot in the dark, but can you try removing the font caches in  and ?
OK.
'power cycled' to restart CI and then realized circle does not build the merged version anyway....
We need CUDA in CI, otherwise these PRs are really hard to merge. There's a $200 bounty for doing it. Check out 
Currently, it is possible to manually set a scale value outside a zoom behavior's scaleExtent. This seems broken to me. If you disagree, fine, close the PR. There's already a clipping function  so we just call that.
This does raise a point about this leading to some user confusion, though.  , can you update this PR to add a little bit to the  documentation that gives an example of this, and tries to clarify this point so other users don't make the (very reasonable) assumption  did?
Running  gave errors: and I know you don't like extra lines, but these two changes fixed the issues.
, PTAL.
is confusingly named and never used.  This PR gets rid of it. The deprecated numpy API that causes zillions of warnings includes , so this replaces the old usage with the encouraged usage. A bunch of  isn't actually used in tslibs.util, so the relevant functions are moved up to . Docstrings for most of what's left in tslibs.util. Simplify util._checknull by removing an unnecessary try/except.
Greetings, . I find current issue very useful and groundlessly freezed almost merged. After a glance view I have a few comments (I'm nobody at this community, so just ignore, if you find them useless): - Screenshot contains tiny lines on upper and right borders. - "A look at the Header" section fully copies code from previous one, but really uses only 5 lines of it. - In "API Key in Cookies" and "API Key in Query" where did  come from? As I see, you have copied it from test file, but I don't get why it is named the same there either. - Throughout,  class takes API key and uses it as a username. I think, it's not the variable name you want to use for a secret. - The last lines talk about  being , but such parameter does not even exist here. Move to the previous  description in A "look at the Header". -  makes no sense. May be make external function `can_make_reques_with_key(key) -
Yes. I commented in the wrong place. I greatly dislike the reliance on False-y values for tests. That should have been on #2813 
Hello, This bug fixes #2666, a html file reproducing the bug within it's context can be found here  Since it's only one line I don't think a test is required but I'll explain why the bug occurs and why the PR fixes this. As stated here, the compilation is cached so for all components except the first one the attributes are not removed. Users might want to use the ':is' version. In this case it's not removed from the DOM and visible. This PR fixes the bug in my codebase. Thank you !
sorry
There is some issue with eslint on travis, I'll figure it out.  thanks for working on this, it'll take me a bit longer to get to this PR as there are currently 20+ open requests and I'm still catching up with work at FB after my vacation.
Before submitting the PR, please make sure you do the following  [x] It's really useful if your PR references an issue where it is discussed ahead of time. In many cases, features are absent for a reason. For large changes, please create an RFC:  [x] Prefix your PR title with , , , or . [x] This message body should clearly illustrate what problems it solves. [ ] Ideally, include a test that fails without this PR but passes with it.  Tests  [x] Run the tests with  and lint the project with   closes: #8533 transition slide will become not smooth with min-height and min-width. I think we can add  or  to resolve this problem.
:+1: (for reals)
Added two more fixes related to hovering and delay time: 1) Prevent tooltips from being triggered if their triggering element is disabled. The issue was that mouseleave and mouseeneter events aren't fired for disabled elements (for instance, buttons,) so disabling a button while a tooltip is showing would make the tooltip stay stuck on the page. 2) Quickly mousing back and forth over a tooltip trigger element when using delay could cause the tooltip to be displayed multiple times (quickly flash.) Explicitly clearing timers inside enter()/leave() prevents this from happening.
It's more that  prevents whole-sale replacement, but not in-place modification of arrays. For something that's meant to be immutable, it's a failing. Currently this really applies to m_nu, but I'm envisioning when cosmologies can be array-valued and all the parameters will be similarly susceptible. A good point about changing input arguments. A copy should probably be made. OTOH for large arrays that can be wasteful. A kwarg copy might be warranted. But that's probably better tackled in a later PR when it's more relevant. I'll copy the parameter before setting the writeable flag.
Upon wish of , nothing more to say here
Good :) We should have a github badge for that. I hope it makes it through the commit and export well, I'll be OOO for a couple of days but I believe it should not have issues.
When explicitly asking for the config (using ) we shouldn't honor , because in that case, you expect the main output to be your configuration. And,  was introduced to avoid corrupting JSON coming out as a response; and there is no need for that when requesting the config, because the config is JSON.
:+1: :cake:
Given that 2.8 is current stable I don't think we need this anymore  The size of the backlog gets in the way of spotting simplier PRs like this sometimes, appologies for not getting to this sooner.
Form what I've checked it looks good. Let me some more time to see if there's some weird thing as well ;) Thanks for this work, it muck simpler than to rewrite an  check. For reader's reference : 
will merge after the CI runs
+1 
Use button instead of non-interactive element (div). (Removes a Svelte a11y warning.) Before submitting the PR, please make sure you do the following  [x] It's really useful if your PR references an issue where it is discussed ahead of time. In many cases, features are absent for a reason. For large changes, please create an RFC:  [x] Prefix your PR title with , , , or . [x] This message body should clearly illustrate what problems it solves. [ ] Ideally, include a test that fails without this PR but passes with it.  Tests  [ ] Run the tests with  and lint the project with  
Sorry for the delay on responding to this. We need to keep these aliases for now, because there are certain third-party users of the C++  API that will break if we remove them. Since there's no ETA on when that will cease to be the case, I'm going to close this PR for now.
Yeah... It's fine to add the jade examples... But don't remove working ejs examples :) Kind regards, Jarrad Seers On 9/10/2012, at 8:02 PM, sakateka  wrote:
Summary As reported in , Jest mocks currently do not have the same arity as their underlying functions. This PR attempts to fix that. Test plan Run unit tests locally. Test in a local project using tests provided in issue  Write unit test in jest-mock to ensure arity is set properly
Same question for URLs and passwords. I'm on latest stable Chrome on OSX.
The snapshot should be updated, and this is exactly what has been fixed in source-map 0.5.14. Let's take this snapshot for an example It is produced by In the code above, the error is thrown in the function , according to the stack trace format, it should print on the first line the name of the function called, which is , instead of . source-map v0.5.16 fixed this bug and one can see the snapshot difference on the CI log. You can also verify the correctness by running the following JavaScript program copy pasted from  It will print the following stack trace.
warn that module variables are not reactive when used in a reactive statement however this is a valid use case, which should not have warnings: Before submitting the PR, please make sure you do the following  ~~[ ] It's really useful if your PR references an issue where it is discussed ahead of time. In many cases, features are absent for a reason. For large changes, please create an RFC:  [x] Prefix your PR title with , , , or . [x] This message body should clearly illustrate what problems it solves. [x] Ideally, include a test that fails without this PR but passes with it.  Tests  [x] Run the tests with  and lint the project with  
For posterity, the following changes were squashed into 6de612e7767c4114d65cb06fc6606436e3081dc3 due to a temporary export problem: 141201358   Force fix documentation causing open source blocks. 141198275   Avoid making horrible docstrings when KeywordRequired() is used 141196439   TensorFlow: Update generated OSS Python Op docs. 141195963   Moved cuda_libdevice_path.cc to make the functionality available accross all platforms 141194861   Change head_test size from small to medium. 141189800   TensorFlow: Update generated OSS Python Op docs. 141188581   Part 2c of renaming SparseTensor.shape -141188238   [XLA:CPU] Mac portability fixes. 141187979   Part 2d of renaming SparseTensor.shape -141187865   add name arguments to tf.split and standardize names between tf.split and 141187490   Part 2d of renaming SparseTensor.shape -141186655   Fixed name collision in saver test. 141186135   Part 2b of renaming SparseTensor.shape -141185169   TensorFlow: Update generated OSS Python Op docs. 141180811   TensorFlow: Update generated OSS Python Op docs. 141176394   TensorFlow: Update generated OSS Python Op docs. 141174390   Remove resources from the public API for now. 141172667   TensorFlow: Update generated OSS Python Op docs. 141170685   Part 2c of renaming SparseTensor.shape -141169934   TensorFlow: Update generated OSS Python Op docs. 141167099   TensorFlow: Update generated OSS Python Op docs. 141163858   TensorFlow: Update generated OSS Python Op docs. 141161010   TensorFlow: Update generated OSS Python Op docs. 141158743   TensorFlow: Update generated OSS Python Op docs. 141155653   TensorFlow: Update generated OSS Python Op docs. 141152716   TensorFlow: Update generated OSS Python Op docs. 141152197   Clarify wording in RNN tutorial. 141149578   TensorFlow: Update generated OSS Python Op docs. 141147227   TensorFlow: Update generated OSS Python Op docs. 141145195   TensorFlow: Update generated OSS Python Op docs. 141142798   TensorFlow: Update generated OSS Python Op docs. 141140181   TensorFlow: Update generated OSS Python Op docs. 141139340   Part 2c of renaming SparseTensor.shape -141137926   TensorFlow: Update generated OSS Python Op docs. 141135381   TensorFlow: Update generated OSS Python Op docs. 141132823   TensorFlow: Update generated OSS Python Op docs. 141129991   TensorFlow: Update generated OSS Python Op docs. 141127103   TensorFlow: Update generated OSS Python Op docs.
<!-- First of all, thank you for your contribution! üòÑ New feature please send pull request to feature branch, and rest to master branch. Pull request will be merged after one of collaborators approve. Please makes sure that these form are filled before submitting your pull request, thank you! -- [‰∏≠ÊñáÁâàÊ®°Êùø / Chinese template] ü§î This is a ...  [ ] New feature [ ] Bug fix [ ] Site / documentation update [ ] Demo update [ ] Component style update [ ] TypeScript definition update [ ] Bundle size optimization [ ] Perfermance optimization [ ] Refactoring [ ] Code style optimization [ ] Test Case [x] Branch merge [ ] Other (about what?)   View rendered CHANGELOG.en-US.md View rendered CHANGELOG.zh-CN.md View rendered components/auto-complete/index.en-US.md View rendered components/auto-complete/index.zh-CN.md View rendered components/breadcrumb/index.en-US.md View rendered components/breadcrumb/index.zh-CN.md View rendered components/button/index.en-US.md View rendered components/cascader/index.en-US.md View rendered components/cascader/index.zh-CN.md View rendered components/checkbox/index.en-US.md View rendered components/checkbox/index.zh-CN.md View rendered components/date-picker/index.en-US.md View rendered components/date-picker/index.zh-CN.md View rendered components/divider/index.en-US.md View rendered components/dropdown/index.en-US.md View rendered components/dropdown/index.zh-CN.md View rendered components/form/index.en-US.md View rendered components/form/index.zh-CN.md View rendered components/grid/index.en-US.md View rendered components/grid/index.zh-CN.md View rendered components/icon/index.en-US.md View rendered components/layout/index.en-US.md View rendered components/layout/index.zh-CN.md View rendered components/menu/index.en-US.md View rendered components/menu/index.zh-CN.md
Cool, thanks ! :coffee: 
Hi! I believe that not enforcing the usage of the 'new' keyword when creating a vue-instance would be a tiny but good improvement for the code. All the tests are passing except for the one that goes against the purpose of of the code change, therefore i had to delete it. <!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [ ] Feature [x] Code style update [ ] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [x] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [ ] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [ ] All tests are passing:  [ ] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
Removes deprecated properties and use new rules instead. Please check this change 100% before closing or merge, as I maybe missed something. I removed  because it disallows  ‚Äî a fallback for functions. I can revert that change if you don't like it. :P
-bot perf test this (this almost certainly has a cost) -bot user test this -bot run dt -bot pack this
I got fooled by  :smile: . Might make a good Jest feature request? cc 
this is one of the blockers for Jest 26. Thoughts on how to move forward? One solution is to not touch the parts that use an old version of Jest, which is probably the easiest
I'll happily fix those too. In my opinion, misleading docs are worse than no docs. Those methods have been subject to criticism for years at this point and are targetted for correction in 3.0. May as well correct their documentation until 3.0 is out.
Sorry, I completely missed this PR and had no idea about this üòû  I independently found it today and am working on . If you see something like this next time please ping me directly :-). This is an extremely bad issue and we shouldn‚Äôt have missed it.
I actually don't know if it really applies to FITS or "big data" in any way because JSON (like ASCII) is quite inefficient compared to binary formats (FITS, HDF5, or even ). You just have to check what it does do numpy arrays: ! It would certainly be handy to have some more support in JSON-encoders and decoders but the really nice step forward would be to use something like HDF5 instead. But that's very subjective and I have to admit I don't even know what this  is for and where it is used, the  was always a mystery to me. üòÑ
all understood.
Change Summary This PR allows to provide a value for model field which has a default factory, when the provided value matches the value generated by the factory. Checklist  [x] Unit tests for the changes exist [x] Tests pass on CI and coverage remains at 100% [x] Documentation reflects the changes where applicable [x] `changes/<pull request or issue id  (see changes/README.md for details) [x] My PR is ready to review, please add a comment including the phrase "please review" to assign reviewers 
Sorry for the commit spam! I wanted the ContextVar to be useful enough to replace getenv. You can now do:
Um yes it appears that  manually merged this into master.
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [ ] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [x] Other, please describe: Security Vulnerability  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [x] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [ ] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [x] All tests are passing:  [ ] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
Yep, no problem.
SUMMARY <!--- Describe the change, including rationale and design decisions --Adding functionality from playbooks to add/delete/execute CLI or TCL scripts on a FortiManager (FMGR) to run against any number of devices managed by the FMGR. <!--- If you are fixing an existing issue, please include "Fixes #nnn" in your commit message and your description; but you should still explain what the change does. -- ISSUE TYPE <!--- Pick one below and delete the rest: -- - New Module Pull Request COMPONENT NAME <!--- Name of the module, plugin, module or task --fmgr_script.py fortimanager.py ANSIBLE VERSION <!--- Paste verbatim output from "ansible --version" between quotes below -- ADDITIONAL INFORMATION <!--- Include additional information to help people understand the change here. For bugs that don't have a linked bug report, a step-by-step reproduction of the problem is helpful.   --Fully developed in-house by Fortinet based on other modules by Fortinet (fortios_config.py) but for a different product. <!--- Paste verbatim command output below, e.g. before and after your change --
I see this PR is closed, not sure if there was something else needed here, but I imagine it's no longer needed in some way. Anyway, thanks for the effort! üç∞   Sorry for the long delay! üôà  I wanted to personally address each issue/PR and they piled up through time, but now I'm checking each one in order. 
: You shouldn't really assume PYTHONPATH= anyway (since different flavors of python won't like running the same bytecode) - so if you want to create the subdir, either inject path to  depending on python version or more commonly let the user decide by setting PYTHONPATH. I guess one could say that the latter is already in play (disregarding moving tests) :-)
:smile:  I tested on a live image with no jabref version, with the version in the ubuntu repo and reinstalling the deb. The install seems to never fail and copies the proper json file.  if you want to test it to be sure, then you're free to merge
Sorry to come in late here (I opened issue #5105 that this is a fix for). I think this is not ready to be merged as it only handles one basic path in the lifecycle of an completefalsesrc<img My intention in opening the original issue was that this two-way binding could be used to make it easier to build re-usable carousel components. Imagine a Netflix-style app, where there is a single carousel (consisting of a sequence of complete<img In terms of the whole lifecycle: Bear in mind the possibility of the "error" event during load as well, in case it makes a difference, e.g. allows you to remove the "load" listener until the next  attribute update comes in.
While trying to patch a version of TypeScript 3.1, it was fairly tough to build because the dev-time Node dependency wasn't explicitly listed anywhere. I don't want to have to deal with that again. By adding this field, we can let a version switched like Volta know that it needs to run on Node 14. The only tradeoff is that it can fall out of date if not everyone in the team is using it.
OK, I corrected my comment to prevent confusion. Can it look up/down -- or only horizontally? Also, FYI, macs do not have a middle mouse button.
okay, I think this is ready, please review.
 right on.  It can be a little confusing, but I do think this brings us more in line with the spec.  We would love to get your opinion on it when you're back from your conference.  PR #4607 is ready for your perusal when you're free.  Let us know if you would like to chat about it. 
To resolve PR #49187 , by providing logging messages for  deprecated 'experimental_run_v2'  in Tf 1.x
Closes #2141 and closes #2140  Making it possible to specify multiple rows and columns when using ,  or .  This pull request is to share the work, so a lot is missing still. Code PR  [x] I have read through the contributing notes and understand the structure of the package. In particular, if my PR modifies code of , my modifications concern the  files and not generated files. [ ] I have added tests (if submitting a new feature or correcting a bug) or   modified existing tests. [ ] For a new feature, I have added documentation examples in an existing or   new tutorial notebook (please see the doc checklist as well). [ ] I have added a CHANGELOG entry if fixing/changing/adding anything substantial. 
what a weird thing about this demo, it uses two blur shaders (h/v) each of them has a bunch of texture reads. normally this is slow on my old laptop, but this on is very fast. I wish I could understand why.
 Adds var  to theme masternpm run lint` and fix those errors before submitting in order to keep consistent code style. [x] Rebase before creating a PR to keep commit history clear. [x] Add some descriptions and refer relative issues for you PR. 
That's why we need automated testing! :angel: 
You could also create a discussion point at  
Also enables the object-concise-method transform for --harmony closes #1438 Tested with  (with this on clipboard):
Sorry, this is not going to happen at the time. There are multiple duplicate PRs, see #1567, #1751 
Was the bridge package created? 
Just chiming in here that I'd love to see this kind of thing in mainline D3.  I would use the version of d3 shown in this PR, but unfortunately it's too old for me now.  ;)
In general, I like having control over the behavior. With the current API you get a default behavior (H=0¬∫, S=0) by specifying RGB colors, or you can control the behavior by specifying HSL colors. If we change the interpolator to inherit hue and saturation from the other color as appropriate, then we also remove control because the interpolator cannot distinguish between when H or S is undefined (coming from an RGB color) and when H or S is zero. I suppose we could change d3.hsl so that  and  are undefined when you converted from black RGB. But I suspect that might break other things.
please review
closes #7511 Though having duplicated column names in a dataframe is never a good idea, it may happen, and that shouldn't confuse groupby() with a meaningless message. Currently This patch fixes that. Thanks.
Can you please provide a table of the browsers you tested, test cases, and the behavior before and after this change?
is correct, and I apologize for not realizing this sooner. The current implementation of the pack layout is operating as intended, in that the leaf nodes are comparable but the internal nodes are not. I misspoke in the documentation when I described the intended behavior. If you want to compare across levels of the hierarchy, a treemap is probably the better choice (though padding introduces the same distortion). It would be possible to have children of the same depth comparable, rather than designing for leaf nodes to be comparable. But this would need to be a configurable option, as it necessarily prevents accurate comparison of leaf nodes. 
Reverts tinygrad/tinygrad#1227 This change always make size 1 tensor a constant, which breaks #1273. Passing a size 1 tensor in JIT as input does not work because JIT only updates buffers. I recommend reverting this now and find a better way to spec constant tensors.
<!-- describe the changes you have made here: what, why, ...       Link issues by using the following pattern: #333 or koppor#49.      The title of the PR must not reference an issue, because GitHub does not support autolinking there. -- 1. Add the following compiler arguments for the  module:  Switch to Java 11 jdk Select "Intellj IDEA" in Settings 4. Use the provided run configuration.  Only problem is that I had to disable the error prone plugin. However, I would say that it is more important to have a simple compilation than this code checker.   [ ] Change in CHANGELOG.md described [ ] Tests created for changes [ ] Manually tested changed features in running JabRef [ ] Screenshots added in PR description (for bigger UI changes) [ ] Ensured that the git commit message is a good one [ ] Check documentation status (Issue created for outdated help page at help.jabref.org?) 
Don't apologize, these patches are awesome! Keep them coming :) 
I tested it with Chrome on Linux and the behavior occurs.  I tried my Macbook trackpad and it does not occur, but that's because it's a touch device.  As a test I plugged a (non-Apple) mouse into the Macbook and I also see the behavior. I hear what you're saying about the inconsistent behavior.  I hadn't considered touch devices.  A better solution might be something along the lines of getting the hypotenuse (sqrt(deltaY^2 + deltaX^2)) of the 2D delta.  I guess the question is, what should a 100% horizontal scroll do?  If I scroll exactly horizontally should it zoom?
Thanks for this! However, I'm not concerned about the linter errors here because any moderately intelligent static analysis tool could tell you that they're not a concern. So I don't think this patch provides any particular value to the project. Sorry!
Thanks for the contribution.
Thanks. Applied.
Ah I didn't know about that. I added it now.
Regarding request 3, what is the right place to follow the roadmap? 
AFAIK, there is no way to make it compatible, which is the purpose of targeting 5.0, since it's a major version, it is not expected to be perfectly compatible and it's the chance we have to make changes that will break existing servers :)
Mostly unrelated to this PR other than the note added to the changelog, but I'm :-1: on the requirement for Jinja2, on the basis that these templates are simple enough that they could be generated without it.  But I don't have the time to submit a change to that effect right now, so if I'm the only complaintant don't worry about it for now, I guess?  Unless someone else would like to make the change...
added code syntax to some of the keywords
Congrats! E-mail me with how you'd like to be paid.
<!-- Thank you for your contribution! --<!-- Unless your change is trivial, please create an issue to discuss the change before creating a PR --<!-- See  for help on Contributing -- Change Summary This PR adds support for configuring the  plugin in , as well as the previous  config file, enabling full compatibility with mypy.inipydantic-mypyValueErrormypymypychanges/<pull request or issue id  (see changes/README.md for details) * [x] My PR is ready to review, please add a comment including the phrase "please review" to assign reviewers
Pushed a commit that should fix the problem. The issue is that Conv3D and its gradient ops do not have BFLOAT16 kernel registered for Eigen CPU backend. So when the graph passes execute, the placer pass (?) throws an error when it sees Conv3D doesn't have a kernel registered in BFLOAT16 type. The placer runs even before AutoBFloat16Converter runs, and that leads to the problem.  Current mitigation is to register NoOp kernel for all of these operators in BFLOAT16 type that are not supported by Eigen CPU backend.
Ah, yes, I meant to do  -- could you do that instead? Or, do: (I hate that default blue)
Take a look at this commit/comment: . The question is how to communicate that a required value was not received for a field with multiple aliases. Sorry, my initial question was very vague üò¨  
py.test integration (even though it probably could have been done via tox too)
String values for representation now accepted.
PTAL
well there have been some flakiness with some gbq tests; I turned them off for now. We should have all green.  FYI we just have the fail fast to make the results appear quicker. We have LOTS of configurations to test. So allowed failures are really NOT allowed :
We are porting our MLIR-based dynamic shape compiler to tf community (From OP def, Patttern, to Optimization pass, etc). There will be 3 PRs to process memory allocation for dynamic shape. 1) Mark shape calculation Ops by Op attribute and insert D2H and H2D Op in mhlo dialect; 2) Add device type info to memref's address space in lmhlo dialect; 3) Convert for device alloc/dealloc with memref's address space. This PR mainly is to add device type info to memref's address space in lmhlo dialect. Related discussion is here.
Fix #5591  What kind of change does this PR introduce? (check at least one)  [x] Bugfix  Does this PR introduce a breaking change? (check one)  [x] No  The PR fulfills these requirements:  [x] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [x] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [x] All tests are passing:  [x] New/updated tests are included 
Yeah, I'm not sure either where  is missing. I'll close this for now; if this is still relevant, please come back to us.
Sorry about that, i did not realise that i was pushing over here.
can you take an other look now. The PR is ready.
thanks!
I believe the bug in the CI was not caused by changes in this PR. This PR fixed a simple but real bug. I managed to fix it in another way for my client, so I only did this PR if it can improve pandas, especially in those edges cases that can be really annoying.  I added a test, a whatsnew entry and answered your comments.  Could you please manage to merge it ?  Otherwise keep it close, it's too much an investment for such a minor improvment.
Thanks for the example! I'd prefer to keep the existing example as-is, mostly because I want the example to be as simple as possible (to use as a starting point). This would make a good example for the wiki. Though, I'd prefer if you implemented a center constraint (√† la Polymaps) rather than the stricter visible-area constraint. If you zoom all the way out in your implementation, and then zoom in on a point in Antarctica (for example), then you get temporarily weird zooming due some zoom levels being constrained, but other zoom levels not being constrained. The center constraint has the nice property that it the map's currently-visible center is valid at any zoom level, so it never swims while zooming. If you want to reopen this with a new example file, say, mercator-zoom-constrained.html, and implement the center constraint‚Ä¶ then I would be happy to pull this in!
PR Checklist Please check if your PR fulfills the following requirements:  [ ] The commit message follows our guidelines:  [ ] Tests for the changes have been added (for bug fixes / features) [x] Docs have been added / updated (for bug fixes / features)  PR Type What kind of change does this PR introduce? <!-- Please check the one that applies to this PR using "x". -- - [ ] Bugfix - [ ] Feature - [ ] Code style update (formatting, local variables) - [ ] Refactoring (no functional changes, no api changes) - [ ] Build related changes - [ ] CI related changes - [x] Documentation content changes - [ ] angular.io application / infrastructure changes - [ ] Other... Please describe: What is the current behavior? <!-- Please describe the current behavior that you are modifying, or link to a relevant issue. -- Issue Number: N/A What is the new behavior? Does this PR introduce a breaking change?  [ ] Yes [x] No  <!-- If this PR contains a breaking change, please describe the impact and migration path for existing applications below. -- Other information
Let me chat with folks.
7148
Fixes 
Thanks! All nits should have been resolved except for the error, that convention is used for other errors (in those files at least), so I'll hold off on that for moment unless you want me to correct all of them.
I haven't looked at the original issue in depth, but you got me curious on how to use  properly... played with it and looks like something like this would properly handle the double fallback from  to  to the built-in default. And it does it separately for both host and port values so you can specify one or the other or both: _host = '127.0.0.1' _port = 5000 server_name = self.config.get("SERVER_NAME") if server_name:     _sn_host, _, _sn_port = server_name.partition(':') host = host or _sn_host or _host port = int(port or _sn_port or _port)  Feel free to use as much or as little of this as you want. I just really liked the clean/linear way your original implementation walked through the configs, so I'd hate to see your solution get too cluttered up... 
Hello  I'm sorry I let this languish. Let's get these examples on expressjs.com . Looking over this and the other PR, I think it makes the most sense to just land  . My reasoning is that (1) the README here is not meant to be a list of all the examples, but just an index for the examples directory and (2) maintaining third-party links in a repository not tried to release versions of a software (i.e. is evergreen) is going to be easier in the long run. We would also need to add our standard third-party disclaimer above the links as well. If you don't see anything wrong with my thoughts, please let me know and we can convert  our of draft state and get it landed here in the next few days.
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [x] Bugfix [ ] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [ ] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [x] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [x] All tests are passing:  [x] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
Thanks  for reviewing.  is needed because it refactors the BibtexParser to confirm to the new  interface. But  is not really needed (I tried to implement the  method via  but it turned out to be to messy and unneeded). Will incorporate your feedback.
http://test/OCL:230818332:BASE:230818351:1548378384444:28a48373
Thanks so much .
is that for performance reasons? Seems a shame to limit this to B&W if we can do full color and videos. 
Please remove build files from this PR.
"bare" maybe? A bare event seems to make sense meaning nothing additional
Thanks  !
I think you mentioned that you had looked at the tests for round-tripping. Can you add that test to this PR? It's always good to test a new feature or a bug fix when it's implemented. Also, can you add an entry under "bug fixes" in the CHANGES.rst file?
Changes are noted in . Merging. :sparkles: :cake: :sparkles: 
I think the docs is fine as is, the fact that it it bit me today was absolutely my personal fault, thanks for the dicsussion and the comparison!
Nice keep them coming! And thanks for catching the documentation error
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [ ] Feature [ ] Code style update [x] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [x] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [x] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [x] All tests are passing:  [x] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
After running cmake on Linux with: the following file is left: This fix updates the .gitignore file so that cmake generated files is not added with git inadvertently. Signed-off-by: Yong Tang <>
Abso-fucking-lutely. ‚úåÔ∏è‚ù§Ô∏è
shitted
With this recursive approach you should be able to put all the Labeled nodes in the fxml files back into the hboxes. I think you can also make the new method  static. If you like to look a bit around in the JabRef sources, you could also think of moving this recursive search init stuff into a background task, if the preferences dialog takes too long to load now, and grey the search box out as long as the preferences are indexed (probably not much more than a fracture of a second). But maybe this too much for this PR. The most important thing is now that the issue has been fixed.
 [x] closes #49352  [x] Tests added and passed if fixing a bug or adding a new feature [x] All code checks passed. [x] Added type annotations to new arguments/methods/functions. [x] Added an entry in the latest  file if fixing a bug or adding a new feature. 
Does this actually work? Isn't PEP8 not happy with 2 spaces?
Right, but also no return statement returns , so how can you know that the function you called really returned a result? It's return value wasn't defined as something. Perhaps you accidentally though that an async function was actually sync? In general, JSON does always ignores , it doesn't turn it to . Consider Just the whole "make  turn into  in this weird specific case" has a bell smell to me, especially since it seems so out of line with how  vs  actually function within the JavaScript language.
<!-- Thank you for submitting a pull request! Here's a checklist you might find useful. * [ ] There is an associated issue that is labeled   'Bug' or 'help wanted' or is in the Community milestone * [ ] Code is up-to-date with the  branch * [ ] You've successfully run  locally * [ ] You've signed the CLA * [ ] There are new or updated unit tests validating the change Refer to CONTRIBUTING.MD for more details. -- Fixes #27716 This PR has a small side effect in autocomplete logic (which is visible in  changes): I think it's ok and in fact is a better behavior. Because it is more consistent with situation with no intersection types. But I may have missed some cons.
Thanks, and yup, that should be it.
Hmm, didn't check all of the tests beforehand, will investigate.
What kind of change does this PR introduce? (check at least one)  [x] Bugfix [ ] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [x] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [x] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [ ] All tests are passing:  [x] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information: Ref:  in  should always be the context. 
This PR was merged into the repository by commit d11f5d70d3904ed24de3e156c0e3992d3f705529.
Lovely test. :+1: 
Also I suspect we'll eventually want to support a way to specify explicitly what the name of a model/dataclass/enum/typeddict/etc. should be, and error if there is a conflict (though we don't support that today). I think it will make sense for that to be introduced if/when we replace use of  with a higher-level api (perhaps a classmethod of TypeAdapter, or similar). Given that, I don't think it's worth adding much complexity. (Again, open to an alternative implementation though if it is simple and better.)
I can follow up by removing  from these builds
Thank you sir :)
Well, more precisely, it isn‚Äôt that topojson.presimplify is introducing artifacts, it‚Äôs that this enables dynamic simplification in the client using your simplify transform (which is presumably based on my dynamic simplification example): So I assume what‚Äôs happening is that the dynamic simplification is introducing degenerate polygons, some of which are interpreted having the wrong winding order.
thanks!
Oh sorry, maybe I made a mistake. What I did was to take the values present in the grid.less file:
Superseded.
An alternative would be to use  in eslint 6.3.0, which doesn't fail the build. But I think it's better this way.
Testing of a few more methods in OOBibStyle.
Too much of a hit to speed right now, but will be fixed and 100s of lines will be deleted :)
Hello üëã, This is a PR to translate  to French, as told in the issue #1972. Sorry for the typo in the commit message. See the formatted document here Thanks for those who take the time to validate it.
This would likely be a solution to #4233 and #6127
Unfortunately this change is not backwards compatible, because the issue you describe is actually an intended feature. Can you instead add a new flag specifically to control the automatic 304s?
I take your point, I don't know the performance implications of doing this on Tensors for example. I will fall back to thinking that this technique should be applied for Graph or Session though, having said that if consistency is king then I can close this PR.
SUMMARY Fixes #31931 Straightforward- simply masking out the StackPolicy param. ISSUE TYPE  Bugfix Pull Request  COMPONENT NAME ANSIBLE VERSION devel ADDITIONAL INFORMATION .
Will deal with the unit test error tomorrow. Hold on.
I've rebased and squashed it down to 1 commit. I also sent around a message to matplotlib-devel trying to start a conversation about the general idea of stacked-ness. Please reply there if you interested in the more general issues of how to approach this problem.
So if we do order added then we'd have to do something else when we find the adapter  that would be akin to what 's last pull request did. So the benefit of ordering would make no difference. This just ensures that any adapters you have with freakishly long prefixes are matched first and returned.
No problem and thanks for the review comments! It appears the CircleCI "Details" links require you to authenticate with your GitHub account, even though you just want to see the build logs. This is rather cumbersome, especially since CircleCI requests quite a lot permissions<sup 1: Requested permissions: - "This application will be able to read and write all public repository data." - "This application will be able to read your organization, team membership, and private project boards."
I think you were the one that made this test xfail before. I'm thinking it got updated but just not .. fully updated, and it seems to be behaving as desired now, so I figured I'd just fix it up and drop the xfail. But if I'm missing something and this is actually misbehaving, we can leave it alone.
Is there some way I could help to move this PR further along?
UNACCEPTABLE
I don't know that  would really apply here though because there are more complex expressions with  blocks, etc.
I am using alpha-12.0.I don't specify concrete version,I just use ,and then the version is alpha-12.0(IIRC one or two weeks ago it is 11.0). No,only when I learn fiber in the fiber-debugger directory I will do that. Yea,don't worry,please trust that I am not blaming or complaining anyone or anything.I just want to experience fiber and some new features in advance.
+1  
Thanks for the tips. Function <em
Fixes #11766 
<!-- Thanks for submitting a pull request! Please provide enough information so that others can review your pull request. The two fields below are mandatory. -- <!-- Please remember to update CHANGELOG.md in the root of the project if you have not done so. -- Summary As the troubleshooting docs state, tests must be defined synchronously. This PR aims to prevent a class of errors where describe is used with an async function by printing a dedicated error message instead of "Your test suite must contain at least one test)", which usually appears if something is awaited before the  calls. Would have saved these people. Unfortunately does not protect against this one though, and we'd need static analysis to save people from top-level awaits. This could be considered breaking, especially if someone can think of a legitimate use case for returning a Promise (or anything at all) from . Or it could be considered non-breaking because returning a Promise (or anything at all) from  was never supported. Hopefully FB doesn't do it üòÖ  <!-- Explain the motivation for making this change. What existing problem does the pull request solve? -- Test plan New e2e test green with and without . <!-- Demonstrate the code is solid. Example: The exact commands you ran and their output, screenshots / videos if the pull request changes UI. --
i also remember that we were not buffering  in reporters, because if something goes terribly wrong, writes to  and blows up we wouldn't get any error printed 
My mistake. I remember now you telling me you were fixing the tests. I can get you a screenshot/a code snippet when I see it next time.
Sorry I didn't see this until now.  For future reference, best way to talk to core committers about modules is to use #ansible-devel on irc to get their attention.  (This includes just getting attention for reviewing a PR, not just for asking questions). Addressing some of the questions raised here for people who might want to work on something like this later: * yum_utils installing code has to stay.  This is the strategy for package management modules in general (although there's open quesitons about it such as whether the module should have a parameter to allow the user to enable/disable the behaviour). * docstrings should be in standard sphinx format.  (For instance, field lists for arguments) * Until we start working on Ansible-2.4, Ansible modules need to be compatible with python-2.4.  Modules also need to be compatible with python-3.5+.  If changes to a module aren't candidates for backporting to Ansible-2.3x and earlier, they can target Python-2.6+ as their Python2 minimum version. * Only use multiline stirngs for things that should be docstrings and that are used by the program.  Use real comments for code comments. * We can't get rid of list for backwards compatibility. * yes please, to having PRs in smaller chunks.  Changes targeted at specific chunks are much easier to review than large ones.  Especially when the starting point is complex and coded in some non-standard fashions. Once again, apologies.
Hi, I forgot about this sometime during having covid. Thanks for reminding me about this. I have a few questions: Assumptions (please correct me if I'm wrong): * A response can either be a native Pydantic model object(), OR a , OR a manual  type. * We have no control over a manual  type. * I'm assuming that  responses will want to be validated and turned into a  before serialised by default. There is cases where the user wants to say "trust me" and turn off validation, and we should allow this with a global setting. Questions: * Can we assume that a native  is already validated? (You have to jump through serious loops to build an unvalidated , and if you do that, one can argue that it's your perogative to ensure that things are correct). If so, can we safely skip the validation on 's by default? * Why did you replace the JSON encoder with your own one, instead of using the provided one from Pydantic:  ? It already seems to handle all the common data type conversions correctly? Based on quick tests, it appears to be faster too. Depending on the answer you provide, I can complete this PR. It would be lovely to have a faster response type for the cleaner code by default. Right now returning a  (which is the cleanest in code) will result in the slowest response type. 's are slightly faster, and  is the fastest. I would like making  perform better by default, skip validation and re-building of , so we can just go to serialisation directly? I would like to make the default  use the provided  if available so we can honour custom encoders on it. I would like to make the  allow skipping the datatype conversion by default, as it seems to handle all the common cases as well. BUT, I would like to limit breakage. So what would be safe behaviour be for  and  response types?
SUMMARY <!--- Describe the change below, including rationale and design decisions --Backport of #70847 for Ansible 2.10 (cherry picked from commit 7f0c84ea15) <!--- HINT: Include "Fixes #nnn" if you are fixing an existing issue -- ISSUE TYPE <!--- Pick one below and delete the rest --- Docs Pull Request COMPONENT NAME <!--- Write the short name of the module, plugin, task or feature below --
<!-- Thank you for submitting a pull request! Please verify that: * [ ] There is an associated issue in the  milestone (required) * [ ] Code is up-to-date with the  branch * [ ] You've successfully run  locally * [ ] There are new or updated unit tests validating the change Refer to CONTRIBUTING.MD for more details. ** Please don't send typo fixes! ** Please don't send a PR solely for the purpose of fixing a typo, unless that typo truly hurts understanding of the text. Each PR represents work for the maintainers, and that work should provide commensurate value. If you're interested in sending a PR, the issue tracker has many issues marked . Fixes #53290. I think The original fix for #52543 isn't in the correct order. In TypeScript 5.0 it became  instead of ;
Thanks !
Figured it'd be useful to have an example for the screenshot issues around. Chromium issue:  This is a workaround that creates a few screenshots. It doesn't stitch them together though folks have had success using sharp for that.   (Apologies for using a private API ;) Fixes #929, #926, #933, #359   2020 update:  handles this and also the vw/vh bug. seems pretty good.
LGTM. :+1: 
Thanks -- can you add a test that uses higher rank gradients to test that what you are doing is correct? , let me know if you want to review this in more detail since you are the main author of this code now :)
Hi guys, there are still projects on Vue 2, can someone merge this, please? It really became a problem with new versions of Google Lighthouse.
Still not working :(
Good point, probably not helpful remove info from the docs. Rewritten (approximately) as suggested.
And in the worst case - we can always revert it :-) Thanks   
I also like this feature, I built it into all of our iOS native test suites. üëç 
There are conflicts. Resolving them now
Old test_lib -Old test_lib_public - See #4512
from the looks of it this kinda of export needs a rework/redesign before it'll be accpted
replaces #1497, originally intended to fix the issue you already fixed in b57cdf2
Sorry , I miss some code .I will submit them soon.
6938
Hi Johann, I fixed the issue in new commit. The use of jquery event namespace worked in release 4.3.1 but not in the master branch. I replaced it with a named function.
Allow running phantom tests on Windows. These were relying on  at the top of runner.js, which doesn't work outside of a unix environment.
 The training of RNNT is conducted using SGD.  Added training mode to the iterator of librispeech to download training files. Added support for flac files.  Implemented the loss function of negative log-likelihood.  Enhanced the RNNT model to output softmax probabilities along with a sequence of characters. source of RNNT implementation :  To-do: Implemented beam search decoding as an alternative to greedy decoding. source :  To-do: Replace some numpy codes and functionalities with that of Tensor.   Hopefully, this is enough for locking up the bounty. 
Added a small intro to the README.md <!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [ ] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [ ] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [ ] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [ ] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [ ] All tests are passing:  [ ] New/updated tests are included  If adding a new feature, the PR's description includes: - [ ] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
Yeah, the RFC is consistent: We should have literal quotes there. Good spot!
Linked to this PR, when I do this kind of change, it confirms somehow that we'd need some utilities that switch colors in light/dark mode. We have  and  that stay black. We need something that is black in light mode and white in dark mode and could be named  or something else.
regression caused by #15943 closes #19934 PR Checklist Please check if your PR fulfills the following requirements:  [x] The commit message follows our guidelines:  [x] Tests for the changes have been added (for bug fixes / features) [ ] n/a Docs have been added / updated (for bug fixes / features)  PR Type What kind of change does this PR introduce? <!-- Please check the one that applies to this PR using "x". -- What is the current behavior? <!-- Please describe the current behavior that you are modifying, or link to a relevant issue. -- Issue Number: #19934 What is the new behavior? Works with OnPush change detection üéâ  Does this PR introduce a breaking change? <!-- If this PR contains a breaking change, please describe the impact and migration path for existing applications below. -- Other information
Not sure why that'd happen, but maybe simply removing the  should do the trick? But, after thinking about this some more, I don't think there's much benefit in this PR anyway. It might even be a step in the wrong direction üò¨   These scripts are rarely run (intentionally) and should 100% be working with the tests' raw output files. With this, the  suites still have their own generation code, which remain detached from these scripts. It's just more to remember & keep track of in future updates. Also, the updated scripts are certainly not avoiding work. They're trading 2x more  ops for fewer s ‚Äì and checking assertions isn't free either. And this doesn't include the fact that this is an extra  per sample (since the tests' results were recycled beforehand).
üß®   Incident report: I published  (with the correct  tag) to npm. So far so good, but the postpublish script  also pushed it as d3.v5.js and d3.v5.min.js to d3js.org ‚Äî and broke the internets. I struggled a bit to reinstate the files manually (just moving the commit to a different branch and force-pushing  didn't want to update the GH pages), so it was broken between 13:40 UTC and 13:51 UTC. I hope  avoids that trap next time.
Prevents pip from seeing the dist on unsupported Python versions.
My effect of problem In my case we dynamically create modal dialogs with a named router outlet in there. After the modal dialog and his components are destroyed, the named router outlet should be, too. Since I reuse the name if I create the dialog again, he uses the outlet name, get the outlet reference from the map and it throws this activated error. If I just delete my outlet from the map it works for my case: I understand the OutletContext needs to be still referenced for the use case of the NgIf for restoring. But in the case it is "valid" destroyed, shouldn't it be removed from the map? If it should not be removed from the map, how to get rid of the reference? For me as user this is first irritating: Especially because I explicitly call deactivate on my referenced RouterOutlet and it then says it is still activated? Then if you look, you see that the messages means the OutletContext and not the RouterOutlet. Here it sets the RouterOutlet on the parentContexts () which calls: Which then creates or gets a already existing OutletContext:  More investigation Maybe this is the wrong direction but I see the  method of the RouterOutlet called in exactly two places. 1# place: 2# place: First time my outlet is created it is not firing the activateWith in the ngOnInit method. Second time the outlet is created, it comes in the ngOnInit method and activates. Then this is called in the ActivateRoutes class (2# place:): ngOnInit Then I remembered this method:  Where following is called: Questions: Is this related:  from the activateRoutes method and  in the onChildOutletDestroyed method? Can someone into it provide information how the flow should be? Why do we need the activateWith call in the else block in the ngOnInit method? Possible solution If I just remove the activateWith call in the else block in the ngOnInit method of the RouterOutlet everything seems to work as expected in my application. Another side effect My Router Outlets from the URL aren't removed by refreshing in the browser. So I got problems also with this and wrote the following: This is then also working and the (outlet) urls queries are removed on refresh of the page. But before the Error was thrown again. But with the above suggestion it is also working.
Thanks , sorry I missed that earlier.
Companion 3.0.0 PR: #7963
Fixes #8582
I thought RFC2616 was considered obsolete. () And if I recall - IE had some issues when the content-type was lowercase.  ()  - may be outdated info though as checks are passing :) 
A rebased version of #73. Better git history.
can you remove the banner 
Make sense, I‚Äôll add one.
I have a problem with adding Appollo as a dependency, and the next reason is I am not sure that we need a special library to make HTTP request, cause in all other places we fetch data from web with the simple 
I'm thinking of leaving the title and subtitle out of the chart implementation. It should be easy enough to plug that in after adding the chart type, and since the text is static I don't see a strong value in baking it into the chart. Plus, this way it avoids the hard-coded "translate(120)", allowing more flexibility in how the titles are displayed. Does that sound reasonable?
PR Checklist Please check if your PR fulfills the following requirements:  [ ] The commit message follows our guidelines:  [ ] Tests for the changes have been added (for bug fixes / features) [x] Docs have been added / updated (for bug fixes / features)  PR Type What kind of change does this PR introduce? <!-- Please check the one that applies to this PR using "x". -- - [ ] Bugfix - [ ] Feature - [ ] Code style update (formatting, local variables) - [ ] Refactoring (no functional changes, no api changes) - [ ] Build related changes - [ ] CI related changes - [x] Documentation content changes - [ ] angular.io application / infrastructure changes - [ ] Other... Please describe: Other information it was wrong explanation of  decorator
Okay, I'll help with the other bugs I found!
AppVeyour was configured to use the latest versions of Node for major releases. To make builds more reproducible I've changed both Travis and AppVeyor to use the same fixed versions of Node 6 and Node 7 that AppVeyor is using at the moment.
Hi! ,  (as randomly selected active maintainer of namespace) could you please review this pull request?
For reference, here's the generated code: I believe  just outputs a placeholder, which gets replaced by Vite. I'm guessing it's ultimately coming from Vite's relative path support.  In SvelteKit, if I change: To: Then I get as output:
Thanks . Looks like there is a bug here (either in my test or in the code.) The issue is that  returns a time in localtime which I wasn't accounting for in my test. There are 2 ways to solve this problem: 1. Modify  to subtract  so that the resulting value represents UTC time. This will result in the value of  being the same on all systems regardless of timezone. 2. Modify  to subtract  so that the test always passes. The former solution seems correct to me, and I can't find anything in the code or RFCs to contradict this. Unfortunately this change would definitely impact users of this module so I'd like to hear others opinions on this. Thanks!
Thanks.
Is this meant as a solution for users, or just for speeding up mypy in our CI runs? If meant for users:¬†one possible downside to this approach ‚Äî¬†would users need to add the pydantic core skipping to their own mypy configs to not suffer the consequencies? If so, I have a feeling we will get people reporting issues about it being slow and need to find in the docs that they should be adding this section to their mypy config. And plenty of others would get annoyed and not say anything, but not realize they could speed things up. Either way, that's not to say that we shouldn't merge this now.
Thanks  for the review and suggestion. The PR has been updated. Please take a look.
I have misunderstand this with . Currently,  returns array including  both normal and categorical. So, the fixed categorical result should preserve  in codes and not in categories as below? 
Thanks a lot   for your time and opinions! :) I have added a new commit 75e5377 to this PR to introduce a new test case for this option.
:+1: shipit
Hi Szczepan, Thanks for the reply, I'll simplify the methods now - do I open a new pull request, or somehow edit this one?  Sorry - I'm new to GitHub and Git! I haven't used a custom VerificationMode in anger yet, I'm actually writing a tutorial on Mockito and wanted to show one as an example.  The one I wrote would verify that an invocation was the first invocation on a Mock, and I had a lot of hair pulling when the .equals() of my chunk and all invocations didn't evaluate to true, even though it was the same object! Regards, Hugh
Hi team! You might have seen that LGTM.com will go off-line later this month. The team that built LGTM (including me!) joined GitHub a couple of years ago, and we've natively integrated the CodeQL engine that powers LGTM into GitHub. This PR enables the CodeQL analysis for three.js. Just like with LGTM, alerts will show up in pull requests (but better). In addition, all alerts can be browsed on the "Security" tab of the repository. I tried to configure GitHub code scanning as similarly/closely as possible to the original LGTM configuration ‚Äî do feel free to tweak and adjust as you see fit. If you have any questions, check out the FAQ below, and I'm of course happy to help as well.  FAQ <details<summary How often will the code scanning analysis run? By default, code scanning will trigger a scan with the CodeQL engine on the following events: On every pull request ‚Äî to flag up potential security problems for you to investigate before merging a PR. On every push to your default branch and other protected branches ‚Äî this keeps the analysis results on your repository‚Äôs Security tab up to date. Once a week at a fixed time ‚Äî to make sure you benefit from the latest updated security analysis even when no code was committed or PRs were opened. What will this cost? Nothing! The CodeQL engine will run inside GitHub Actions, making use of your unlimited free compute minutes for public repositories. What types of problems does CodeQL find? The CodeQL engine that powers GitHub code scanning is the exact same engine that powers LGTM.com. The exact set of rules has been tweaked slightly, but you should see almost exactly the same types of alerts as you were used to on LGTM.com: we‚Äôve enabled the  query suite for you. How do I upgrade my CodeQL engine? No need! New versions of the CodeQL analysis are constantly deployed on GitHub.com; your repository will automatically benefit from the most recently released version. The analysis doesn‚Äôt seem to be working If you get an error in GitHub Actions that indicates that CodeQL wasn‚Äôt able to analyze your code, please follow the instructions here to debug the analysis. How do I disable LGTM.com? If you have LGTM‚Äôs automatic pull request analysis enabled, then you can follow these steps to disable the LGTM pull request analysis. You don‚Äôt actually need to remove your repository from LGTM.com; it will automatically be removed in the next few months as part of the deprecation of LGTM.com (more info here). Which source code hosting platforms does code scanning support? GitHub code scanning is deeply integrated within GitHub itself. If you‚Äôd like to scan source code that is hosted elsewhere, we suggest that you create a mirror of that code on GitHub. How do I know this PR is legitimate? This PR is filed by the official LGTM.com GitHub App, in line with the deprecation timeline that was announced on the official GitHub Blog. The proposed GitHub Action workflow uses the official open source GitHub CodeQL Action. If you have any other questions or concerns, please join the discussion here in the official GitHub community! I have another question / how do I get in touch? Please join the discussion here to ask further questions and send us suggestions! </details
This PR was merged into the repository by commit da58801f95c66c201e332189af25702bdd722f3f.
Fixes #4703. <!-- describe the changes you have made here: what, why, ...       Link issues by using the following pattern: #333 or koppor#49.      The title of the PR must not reference an issue, because GitHub does not support autolinking there. --   [ ] Change in CHANGELOG.md described [ ] Tests created for changes [ ] Manually tested changed features in running JabRef [ ] Screenshots added in PR description (for bigger UI changes) [ ] Ensured that the git commit message is a good one [ ] Check documentation status (Issue created for outdated help page at help.jabref.org?) 
Thanks for the feedback :)! Regarding the first  bullet point: One reason was that JabRef already knew how to parse such a file, making the implementation fairly easy. Additionally, the entries can easily be modified directly in JabRef. Therefore it was a straightforward choice. This certainly is not the most user-friendly variant, but this can and will be addressed by offering a GUI for the creation of this file in the future. Regarding the second bullet point: The reason for this is that this allows easy versioning of search sessions allowing to track new entries without reevaluating old entries. I do not see how this could reduce the number of use cases? Furthermore, if the user does not want to create a remote repository for pushing a local one will suffice. In case a remote repository is configured I do not see any use case where a search should not be documented? I agree that the UX is currently poor, however with the GUI implementation and the existing documentation for the feature it should suffice :).
I am sorry, but I started fixing this yesterday not realising this PR and issue were already open for 6 days. I am the maintainer of this module, but was not notified about this issue and PR by . In the meantime I added integration tests to ensure the mail module is working correctly, so that in the future changes won't break it anywhere in our test-matrix. So I prefer we continue with the more extensive PR. bot_broken
There is no formalized design for it. However, currently the compiler will preserve two types of comments: detached, pinned (the triple-slash is a bug). I think it is desirable to keep copy right comment even in emitted js. I make an issue #3878 for discussing design for removing comment in general.
I was discussing this with  and he said something very similar about expected vs. actual.  I've never seen this as confusing, but that may just be a privilege of being a native speaker üòÑ  added/missing sounds like a good idea for diffs.  For tests that aren't diff maybe  and ?
Yeah, I really like azimuthal too. Well, we're not going to make any immediate movements to the current projections in core. I just want to have a more discoverable home for the new ones. So let's start there!
The role of the loss scale is to prevent underflow, which is very common when doing many additions in float16 because of the lack of exponent bits (compared with float32). So we want to multiply all losses by a large number so we don't have to spend the precious few exponent bits we have on leading zeros. Doing so by an arbitrarily large number can overflow, though, but while underflow is silent, overflow is noisy (it generates inf / nan values), so we can detect it, and can use a line-search-like approach to find the largest loss scale possible such that we do not overflow, as this will underflow the least. So by this reasoning there's no point in ever having a loss scale less than 1, as that would increase the odds of underflow. Does this make sense? On Thu, Dec 5, 2019 at 8:04 PM x10000year < --   - Alex
Put test in test/extra, and can you add a couple integration tests that train models with these schedulers?
But still not when you build the docs, ?? Weird... Also, see #2412 for an attempted fix on the google failure.  , I'm not sure if that conflicts with this, but you can merge as you see fit (or just take that solution and close hte PR)
In general, I'm not a big fan of small refactorings like this when there are no obvious readability issues with the original code, which would make the history of the real logic changes harder to track.
<!-- Hey, Thanks for the contribution, this is awesome. As you may have read, project members have somehow an opinionated view on what and how should be Mockito, e.g. we don't want mockito to be a feature bloat. There may be a thorough review, with feedback ---<!-- If you have a suggestion for this template you can fix it in the .github/PULL_REQUEST_TEMPLATE.md file --## Checklist  [x] Read the contributing guide [x] PR should be motivated, i.e. what does it fix, why, and if relevant how [ ] If possible / relevant include an example in the description, that could help all readers        including project members to get a better picture of the change [x] Avoid other runtime dependencies [x] Meaningful commit history ; intention is important please rebase your commit history so that each        commit is meaningful and help the people that will explore a change in 2 years [x] The pull request follows coding style [x] Mention Fixes #<issue number 
I am unsure how this was ever supposed to work, as testDocument is guaranteed to be undefined at that point since beforeEach doesn't run synchronously. (I don't think there's any way to have beforeEach halt the tests, but let me know if you know differently.) The tests will fail now, but they should be failing because of #337. /cc 
Strange, <T
10991
I re-ran the kokoro test, and I think you can access and check the detail of the failure in the "" of the "Py+CPP Test Suite - Ubuntu CPU, Python 3.9 ‚Äî Internal CI build failed" Check. Please resolve these failures.  I believe you can also check the error message from  on the 2nd failure(pkg/pip_and_nonpip_tests) in the "". 
Oh yeah - missed the docs :P 
That is interesting indeed!
Jenkins, test this please.
Yeah, Jest should come with the node and jsdom environments by default, even if only one of them is used.
Certainly, it must not be considered. I just included that because it was unclear to me what causes the failure.
SUMMARY postgresql_set: improve CI tests 1. improve formatting 2. add additional checks by SQL queries ISSUE TYPE <!--- Pick one below and delete the rest --- Bugfix Pull Request COMPONENT NAME postgresql_set
I appreciate the effort to approach my original request, but am a bit skeptical against making a lot of changes to the current methods. In particular, making add use addAt as a helper may spare some lines of code, but the extra calls and checking may incur a computational/memory cost when one calls many add(object). I have similar concerns about some other changes, admitting that I haven't digged through the entire diff. Adding replace and replaceAt first seems much safer, less invasive.
I'm thinking what about a followup PR that has that checklist at the top of the reviewers guidelines? Also thanks for all your help!
Fixes #6820  If a vertical bar, allow a scalar height If a horizontal bar, allow a scalar width Test that doing the above works without errors 
<!-- Thank you for submitting a pull request! Please verify that: * [X] There is an associated issue in the  milestone (required) * [X] Code is up-to-date with the  branch * [ ] You've successfully run  locally * [ ] There are new or updated unit tests validating the change Refer to CONTRIBUTING.MD for more details. ** Please don't send typo fixes! ** Please don't send a PR solely for the purpose of fixing a typo, unless that typo truly hurts understanding of the text. Each PR represents work for the maintainers, and that work should provide commensurate value. If you're interested in sending a PR, the issue tracker has many issues marked . Fixes #50520  [ ] i don't know how the fourslash tests work or how to debug them. i'll take a closer look tomorrow [ ] should  be deleted and  be used for both  and  as suggested by  
What do you mean by "the right thing"? If I do , what would be plotted? What axis would be used? What happens if I do this: datetimetimedelta__add__relativedeltatimedeltadatetime` for the short-term expedience of being able to ignore the unit analysis.
Thanks for the interest ! :nerd_face:  I haven't seen any other request for this feature, and as you already solved it for your use case, I would be inclined to not have it in FastAPI. But if I saw a lot of users needing it, that could change my mind. Have you seen other users requesting this, maybe in an issue?  Sorry for the long delay! üôà  I wanted to personally address each issue/PR and they piled up through time, but now I'm checking each one in order. 
Does grad_rtol need to be further relaxed then? Having a test that passes every time with known accuracy expectations is better than one that passes sometimes with strict accuracy expectations. Or is there some other issue? I remember actually relaxing the grad tolerance for the GPU conv2d test to 1e-5 or 1e-4 before, but that change may have been clobbered by a recent PR by mistake. Or maybe I never pushed, not sure which.
It was unrelated I imagine‚ÄîTravis had some issues after patching those major vulnerabilities.
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [ ] Bugfix [x] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [ ] Yes [x] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [x] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [ ] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [x] All tests are passing:  [x] New/updated tests are included  If adding a new feature, the PR's description includes: - [x] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information: When exploring css-in-js solutions for vue, I came across the fact that some auto prefixed style objects (for example, by postcss-js) cannot be directly used as  option on elements, when they have an array as value, e.g. ...which happens when a rule value needs to be prefixed, other examples: This PR adds support for directly consuming such objects as  option.        
Thanks for the pull request. Currently, the layout‚Äôs size directly determines the gravitational center, and that‚Äôs pretty much it‚Äôs only purpose (aside from initializing node positions). Thus I don‚Äôt see a compelling need to add a separate gravitational center, especially since you can also apply a transform to the G element that contains the force layout if you like.
Closes #5972  I see three reasonable alternative choices for the behavior for leading- attributes on BaseModel classes:    raise an error, same as we would for public attributes  As this PR stands, I've made it so that they become a . Mostly because it was super easy to do. But that can be changed easily. However, in v1, these leading-underscore fields were always classvars, even when they had an annotation, which perhaps should be the preferred implementation to reduce backwards compatibility issues? I'm not sure why we changed to defaulting to setting as a PrivateAttr in v2; this has led to some confusion as noted in this comment  I'll also note there has been a feature request to be able to use leading- attributes as fields (e.g., for  for use with mongodb), which is another angle to the problem not yet resolved. do you remember the motivation behind making -attributes private automatically?
This ensures that we use sys.writeFile for baseline buildinfo so that buildInfo correctness is verified. It was missing when we started passing the writeFileCallback which didnt track written files.  This also baselines those differences so its easy to view, read and maintain. This is on top of #48703. Actual change is only 386786c and f45e9ca
Fixes #6487  [x] Change in  described in a way that is understandable for the average user (if applicable) [x] Tests created for changes (if applicable) [x] Manually tested changed features in running JabRef (always required) [x] Screenshots added in PR description (for UI changes) [x] Checked documentation: Is the information available and up to date? If not created an issue at < Video:  Use  as an example. Double-click it, and I got errors in console as the following: Therefore, the path was regarded as two files:  and . Start from  to backtrack the dataflow: |         Class          |            Method            |      Variable      | | :--------------------: | :--------------------------: | :----------------: | |          |                |        | |     |          |         | |             |         constructor          |              | |     |         constructor          |              | |  |  |           | |  |               |          | |  |                         |  | |              |              |          | Use logger to print the variable : And I got: So I think the problem is that when passing the argument , it will be considered as two arguments because there is a whitespace that serves as a delimiter. I noticed that  said that a path containing Chinese characters would cause the same error. So the problem is not just related to delimiter, probably about text encoding. Therefore I encoded the arguments in  and decoded them in . Then I created a binary and tested. Now it works well on my computer (Windows 10 1909).
Closes #21857, fixes #21650, and closes #21885 (dupe of #21650). The card image stretching affected , , and  as we utilize flexbox and  on . Intrinsic image sizing is basically borked with flex due to the default  value for aligning the content. There's no real way around this it seems other than  as no other flex property will address the aspect ratio.
Great, thanks for your contribution! :cake: 
Possible further taskbar stuff: (v=vs.85).aspx
Actually, we should indeed check if it still behaves like that with the latest upstream Numpy.
You probably use tabs instead of spaces, which causes the diff to be horrible. Personally I dont really see usage in this proposal, but then again I havent ever used Mockito in production. Is there really not a cleaner way to fix this on your side instead of altering Mockito with a public variable?
<!--  Describe the changes you have made here: what, why, ...  Link issues that are fixed, e.g. "Fixes #333". If you fixed a koppor issue, link it, e.g. "Fixes ". The title of the PR must not reference an issue, because GitHub does not support autolinking there. -- <!--  - Go through the list below. Please don't remove any items. - [x] done; [ ] not done / not applicable -- - [ ] Change in  described in a way that is understandable for the average user (if applicable) - [ ] Tests created for changes (if applicable) - [ ] Manually tested changed features in running JabRef (always required) - [ ] Screenshots added in PR description (for UI changes) - [ ] Checked developer's documentation: Is the information available and up to date? If not, I outlined it in this pull request. - [ ] Checked documentation: Is the information available and up to date? If not, I created an issue at <
<!-- Thanks for submitting a pull request! Please provide enough information so that others can review your pull request. The two fields below are mandatory. -- Summary Drop auto-including of  if available. Fixes #2693 Test plan jest
Sorry I'm slow to review I'm in the train, tethering and the car is shaking quite a bit. 
As discussed in  and . Note that this builds on my other two recent pull requests (#14/#15), which should probably be merged first. I've separated them out, since this is obviously more contentious, and the other two are valid and useful on their own. This allows for the following: which will return either successfully after 100ms, or fail as soon as  is invoked. This contrasts with the current behaviour for , which will either return instantly successfully if mock.method() has not yet been called, or fail after 100ms if it had already been called before this assertion was run. This fix both adds the above after() method, and also tweaks timeout so that it will now terminate successfully when a success is seen (as before), fail if the timeout runs out (as before), or fail early if the underlying verification is known to have definitely failed before the time runs out (as in this new after() implementation).
Patch to #7684  Before submitting the PR, please make sure you do the following  [x] It's really useful if your PR references an issue where it is discussed ahead of time. In many cases, features are absent for a reason. For large changes, please create an RFC:  [x] Prefix your PR title with , , , or . [x] This message body should clearly illustrate what problems it solves. [ ] Ideally, include a test that fails without this PR but passes with it.  Tests  [x] Run the tests with  and lint the project with  
As discussed here, and in continuation of this PR on pydantic-core. We add two new types, implementing constraining datetime values to either enforce or disallow timezone info. The implementation is simple and utilizes the 'aware' and 'naive' constraints from the underlying pydantic-core. Admittedly, I added the  comment just by looking at surrounding code, without looking deeper into how that works. Hopefully it just makes sense here too. (I'm guessing this is some sort of macro that is pre-processed? I'm intrigued!). Oh, and of course this PR depends on a new release of pydantic-core üôÇ
Thanks for the interest! In this case, the information that the attacker would get is only if a user exists or not, but no information about the password. And probably in most cases, the attacker could get that information more easily by trying to create a new account with that username, to detect when a username already exists. So I would think this would depend more on the particular application, I don't think it's strictly necessary to add it here. Also because adding it would require explaining what are timing attacks to the docs. And I'm already explaining it in another section. I wouldn't think it's necessary to add a long explanation about that for this section as there's no information about the password that can be exposed, only about the existence of users. Given that, I'll close this one. But thanks for the effort! :coffee: 
We can't and won't document every non-standard edge case that exists. We expect users to understand the services they're talking to and cater to them directly. No. It's not a good idea to change behaviour in completely backwards incompatible ways
, , , By replacing  with , you broke backward compatibility. After a minor update, all my headings got messed up. Why don't you mention that this commit breaks backward compatibility? Why are there changes within one version that break interfaces? I started my project on Atn three weeks ago, and there have been numerous API changes already. Are there any plans to follow semver to avoid being on a ticking time bomb?
Could you rebase / squash commits so the PR has a more meaningful semantic commit history ?
gh isn't showing me the line you are trying to mention. Could you please elaborate? Thanks!
nvm, unfortunately work around fails..
Whether keeping  on  or not is totally okay for me. I couldn't make the decision before which is the reason I replied in the original issue.  Thanks for pointing it out. I didn't consider the problem from this aspect.
Apparently they have a test for this exact thing.
has to be there, as  is only working on  while not having a context.
close #4787 
As discussed in koppor/jabref#25.
See coverage report:  This just removes a handful of unused functions.  LMK if some should be kept around just-in-case. Not included in the never-used group but worth mentioning: lib.fast_unique, lib.convert_timestamps, and lib.string_array_replace_from_nan_rep are each called exactly once in io.pytables, not covered in tests (io.pytables looks poorly covered, might have had a bunch of skipTests locally)  [ ] closes #xxxx [ ] tests added / passed [ ] passes  [ ] whatsnew entry 
Oh, it seems to be a hot topic! Although my implementation might be not the most elegant among available, I'll comment about motivation behind the request: I want to animate transition between two external SVGs (graphviz layouts). To do so, I load SVG XML, use it as data and call recursive Clone function, which navigates through XML layers and re-creates it in the current document. Therefore, for each level I do something like 
Or, if you prefer it, I can make two properties: spinStyleCointainer & spinStyleNestedCointainer.
About Laos: Laos is a landlocked country in South-east Asia on the Indochinese peninsula between Thailand and Vietnam and north of Cambodia.
Compilation with ngcc is now included in the CLI, so its no longer necessary to run in manually PR Checklist Please check if your PR fulfills the following requirements:  [ ] The commit message follows our guidelines:  [ ] Tests for the changes have been added (for bug fixes / features) [x] Docs have been added / updated (for bug fixes / features)  PR Type What kind of change does this PR introduce? <!-- Please check the one that applies to this PR using "x". -- - [ ] Bugfix - [ ] Feature - [ ] Code style update (formatting, local variables) - [ ] Refactoring (no functional changes, no api changes) - [ ] Build related changes - [ ] CI related changes - [x] Documentation content changes - [ ] angular.io application / infrastructure changes - [ ] Other... Please describe: What is the current behavior? <!-- Please describe the current behavior that you are modifying, or link to a relevant issue. -- Issue Number: N/A What is the new behavior? Does this PR introduce a breaking change?  [ ] Yes [x] No  <!-- If this PR contains a breaking change, please describe the impact and migration path for existing applications below. -- Other information
What I meant is that if we can achieve the auto focus capability with:  Is it really necessary to add an  prop? :)
Because, when I run  locally, the website is using the wrong base so it doesn't work.
-1 from me, the indirection is probably not worth it in this case, then we have to tell everyone how the currying works etc, vs just doing 
It looks like there is already a session option for "allow_redirects". This looks like it controls whether to attach a "history" attribute to the response (not actually control whether resolve_redirects gets called or not). Could this cache be an option to the session rather than an adapter? I'm not opposed to an adapter (though I would need help with the approach), but again, this is how both chrome and firefox operate with permanent redirects; they don't make requests up the whole chain each time.  That is why I thought the cache should be a first class citizen, even if it is made to be an opt-in.
¬Ø\_(„ÉÑ)_/¬Ø
add win32 fonts directory check PR Summary PR Checklist <!-- Please mark any checkboxes that do not apply to this PR as [N/A]. --Tests and Styling - [x] Has pytest style unit tests (and  passes). - [x] Is Flake 8 compliant (install  and run ). Documentation - [ ] New features are documented, with examples if plot related. - [ ] New features have an entry in  (follow instructions in README.rst there). - [ ] API changes documented in  (follow instructions in README.rst there). - [ ] Documentation is sphinx and numpydoc compliant (the docs should build without error). <!-- Thank you so much for your PR!  To help us review your contribution, please consider the following points:   A development guide is available at .   Help with git and github is available at   .   Do not create the PR out of main, but out of a separate branch.   The PR title should summarize the changes, for example "Raise ValueError on   non-numeric input to set_xlim".  Avoid non-descriptive titles such as   "Addresses issue #8576".   The summary should provide at least 1-2 sentences describing the pull request   in detail (Why is this change required?  What problem does it solve?) and   link to any relevant issues.   If you are contributing fixes to docstrings, please pay attention to   .  In particular,   note the difference between using single backquotes, double backquotes, and   asterisks in the markup.   We understand that PRs can sometimes be overwhelming, especially as the reviews start coming in.  Please let us know if the reviews are unclear or the recommended next step seems overly demanding, if you would like help in addressing a reviewer's comments, or if you have been waiting too long to hear back on your PR. --
unicode() was removed in Python 3 because all str are Unicode so this PR changes four calls to unicode() into calls to six.text_type().
I suggest we move on. We won't be able to automatically test how IDEs integrate with xUnit runners. Manual tests will be forgotten. We never had tests for this feature and it did not regress. Eventual regression will not be a blocker. If we encounter one, then we can prioritize a solution.
http://test/OCL:229307881:BASE:229307905:1547528246221:6725d55a
Summary matcher could not handle symbol based properties in array's, causing jest to throw: Minimal example: Throws: The cause of this issue is this line which assumes that all property names of arrays are strings and hence  can be called on them.  This assumption does not held for symbol based properties. If the property name is a symbol, it is never an index, so it should always be added to the  collection.  Test plan I added a unit test demonstrating that deep equality on arrays behaves correctly now, even in the presence of symbolic properties.
verifying this works as used by the offline compiler CLI
LGTM.
So, IIRC, NonUniformImage came about a few years ago when we realized that a limitation to UniformImage was apparently arbitrary (or maybe it was that NonUniformImage predates that work and we can now achieved using transforms and UniformImage?). Maybe the tests aren't obviously linked to NonUniformImage? On Mon, Jul 29, 2019 at 12:05 PM Jody Klymak <wrote:
Change Summary Allow element of  to update elements of a  Example of usage: Related issue number fix #2426 supersedes #2437 Questions  could this break any assumed existing behaviour? do any docs need to be updated? If so, what?  Checklist  [x] Unit tests for the changes exist [x] Tests pass on CI and coverage remains at 100% [ ] Documentation reflects the changes where applicable [x] `changes/<pull request or issue id 
Great! You can send your wechat to my gmail: . I will contact you later.
Yeah, handling a useless scale is precisely what I need because I'm creating scales dynamically based on the min/max values from database queries.  Here's an example for a single chart using a fixed number of ticks and different data.  notice when there is one domain value, no labels appear. In my application the charts need to handle arbitrary data so locking them to a fixed scale is not an option.  It seems like the best solution for correctly labeling the domain when n=1 is to pad the min and max values e.g.
Really weird, but setting  and then later , both on the pseudo-element, seems to fix it in IE9-11. Confirmed via Sauce testing. Credit: 
The get_db dependency causes a weird  `TypeError: <async_generator object get_db at 0x7ff6d9d9aa60issue on my project. Here's my code: db.py session.py
Mostly that's nit-picky stuff. Thanks for your work there :)
Issue Type: <!--- Please pick one and delete the rest: --- Docs Pull Request Summary: <!--- Please describe the change and the reason for it -- <!--- If you are fixing an existing issue, please include "Fixes #nnn" in your commit message and your description; but you should still explain what the change does. -- In essence, most people do not need to use the templates directly, getting them out of the way increases the signal-to-noise ratio of the root directory. Direct people to what they are looking for.
, I use VS Code with Pylance for type checking. I was using the following ugly : and then  This achieves the desired type inference:  otherwise, due to the dynamic import stuff, I end up with  I haven't tested it myself, but I expect this PR to supersede my ugly hack, so I'm happy about that. Thanks so much!!!
this.locals.settings = this.settings; the settings can be inherit from parent, so i think, the locals should too.
Current state: remote: error: File src/main/resources/journals/journalList.mv is 332.14 MB; this exceeds GitHub's file size limit of 100.00 MB  Ideas:  Make JabRef distribution size to 500 MB ^^(and enforce git-lfs) Re-add  in the repository and have JabRef generate the  files if the  file is older than any  file Switch back to "String" and have the Abbreviations in-memory 
GPU tests 9m 19s -> 6m 4s
OK, force-pushed a better fix.  I think this is actually more robust than special-casing ‚àû values, because I tried clamping to larger values such as 1e200 and this didn‚Äôt work.  Even clamping to a value as low as 1e20 still led to a slanted line in when drawing {type: "Sphere"} using Mercator (probably due to loss of precision because IEEE double can only represent around 16 significant decimal digits).
I mean, the np.where isn't great either.
Yeah. My mistake, thks!
 had only the most cursory of looks so far, and liked very much that for most of the code there is, as I would have hoped, absolutely no difference between what is done for  and for . This is duck-typing at its best!   The exceptions are the degree to radian conversions; my sense would be to not allow this. Effectively, this is equivalent to allowing some special units to be attached to , which is just what  is for. So, while I'm quite happy for plain numbers in an  to be considered to have dimension of radian (as this is equivalent to dimensionless, which is what a plain number should be), I don't like the idea of allowing plain numbers to really be degrees.
I really don't like an unconditional warning for this. For anyone besides someone who uses Flask for the first time and doesn't know that the server is only for development this is going to be incredibly annoying. Edit: Just noticed that I already commented in  - so I guess it's  better to keep discussions over there
When the race condition happen, it will return the error message(explanation) instead of redirecting user to other page without explaining - fixes #4099 Checklist: - [x] Add or update relevant docs, in the docs folder and in code. - [x] Add an entry in  summarizing the change and linking to the issue. - [x] Add  entries in any relevant code docs. - [x] Run  hooks and fix any issues. - [x] Run  and , no tests failed.
thanks  
I still don't think there should be a  even with your argument. It's too bad  exists that strips the port, because that's the , not the . The  is does not include the port while  does include the port. Adding the property as  where it includes the port would be wrong and then they'd be backwards. Perhaps this can be something fixed in . For now, from a request from  , I am actually moving the proxy stuff into a separate module, so you'll be able to do 
"Soon". For now you could try using the  branch directly (but keep in mind this is not officially supported): `
Sorry, I just don't think it's a preference worth putting up to the visitor. Personally I think it's not good design to simply add options for the sake of adding them. Hope that makes sense!
Thank you , I definitely misread the issue. I will look into look a fix for the overlap.
Thanks for the quick fix!
That's a very good point ! Thanks for idea. I just released version  that does exactly that. If there's no Content-Type header, it is now assumed as JSON. This still provides protection from CSRF because browsers automatically set Content-Type headers. And if an attacker removes the header explicitly, it triggers the CORS preflight, which provides the main protection using CORS. So, you should all be able to upgrade to  more easily now. :tada: 
/azp run
Hmm, did something go wrong with 
This is a warning. We have recently observed the presumably well-intentioned act of the author of this PR (-coding-bot), who has been spamming pull requests to many (~50) github repos, claiming to switch to gender neutral pronouns''. In reality, the bot performs a dictionary replace of gendered nouns and pronouns, and the outcome is questionable at best, and literally harmful at worst. See: - The bot did a terrible job at replacing these words - EbookFoundation/free-programming-books#6801 - The code fails to compile at rust-lang/rust#95508 - The bot ignores all context whatsoever at moby/moby#43441 - After initial PR being closed, the bot keeps sending PRs, effectly spamming the repos. For example, these 5 PRs were sent to the same repo within 2 days #1 #2 #3 #4 #5 We have reviewed the changes in this PR. Most of the changed words are "accidental gender pronouns" -  as a prefix of , or  as a suffix of , and both examples come from test cases where inline comments are used to split words (like ), and the PR wants to change them into  etc.. These changes are obviously not helpful at all. To save more time for the open-source community, we recommend the maintainers of this repo to close this PR and ban this bot from further spamming.
Hi , Now that we merged the  branch and release version 4, we'll need to update this branch to fix the merge conflicts. Basically, all of the files you modified have moved under the  directory.  I don't think there were any changes in these files other than the move, so you should be able to overwrite the current files in the new locations with your latest versions. If you run into trouble doing this as a merge resolution with git, feel free to start over and create a new pull request. Thanks!
Are you guys getting this error  as well? Maybe I overwrote the wrong file in a merge
Sorry, just noticed that #37253 was opened first, so closing in favour of that one
I see, so you‚Äôre temporarily overriding the touchstart listener while a gesture is active, too. That‚Äôs a bit clever but now that I understand what‚Äôs going on, it feels quite clean. It might be worth adding a brief comment just above the declaration of the touchstarted function saying that the closures persist for as long as at least one touch is active. I‚Äôm confused by calling  on touchend. What‚Äôs the purpose of this? That seems like the code that we had before that was likewise confusing and caused a bug where a touchend could be interpreted as a dbltap. My only guess is that you‚Äôre updating the state of the  hash, but I don‚Äôt think there would be any negative effect of keeping the expired touch in the hash (until the next touchstart, which likewise causes it to be recreated). Or if you just want to remove the ending touch from the hash, couldn‚Äôt you look at changedTouches and remove those touches?
Sorry for that!
is correct here. I'm afraid this will have to wait for a proper strict mode. 
Any reason why the traces in the  are by inverse aphabetical order? I'd rather have them by alphabetical order, or we can also change the order in the sphinx page, like if we want  and  to appear first.
Passing in  used to be fine, but started raising a  following the addition of the type check (#3365)
I tried to merge your work into my branch, but I have a hard time doing so with github's tools. I can only compare your last commits ( this one  ) and my branch, but cannot create a PR or export a diff. Probably because there's no branch referencing it anymore (was removed). I could manually copy the changes, but I'd prefer having a sane git history. Could you help me? Maybe restoring the branch?
I think it's not only convenient for requests to have frame properties, but it's consistent with Chrome DevTool Protocol because Network.requestWillBeSent event has frameId property. One problem I faced is that the frameId is optional, so the frame cannot always be accessed from request. I noticed that the property is empty for offline mode and when navigating to bad SSL pages. Fixes: 
I tried building the docs on master with this patch. There are a few errors, many of which may not be directly related to these changes: I've seen ValueErrors like this before.: It probably means that at least one of the values in "segments" is bad, perhaps new plot_directive uncovered an existing problem in doc/examples/units/artist_tests.rst? This line in particular looks suspect (although I am not familiar enough with units support to know for sure): Here are a few additional errors I see when I build the docs:
Hmm, this is strange, I can't reproduce the issue, I tried on different sizes but it seems to work correctly. What browser are you using? Have you tried on an incognito window? 
0.22 (latest version) works for sure, and I believe 0.21 does as well. If you can, it's probably best to update to the latest version of Bazel.
Note that the file you're editing is from a template, you will need to make the change here: I think your second approach is correct (or at least consistent) - in fact the current impl seems to handle it? edit: ok, actually it seem to be dumb luck the current version (which I had written) gives this answer - it has bounds issues, but just sometimes doesn't crash.  But, it is also what  would have done before this bug was introduced.
Thank you for contributing to Jest. To help interact on your contribution:  Can you say which version? Can you give a few examples of confusing tests that motivate the sentence? The wording might need to become more specific for which type of expected argument in the assertion.  For example,  assertion without argument works for values that are not instance of Error: This improvement in the report from #7621 in Jest 24.0.0 or later P.S. Yes, ignore  failure on CI When you edit Jest  files, you can run locally  before you commit the change
That's not how blueprints work already though, and IMO this should stay simply a way to nest those registrations. Otherwise, how would you solve things like running custom code at registration time without still having the recursion problem?
Merged, thanks!
Okay, let's do 1.1 then.
its weird why gpu is not found in test check  can u look into  
ok, will try to spend some time on this over the weekend On Wed, Nov 2, 2016 at 10:26 AM Adam Kulidjian  wrote:
-hesselmann-by you are correct unfortunately, this project is effectively abandoned
Sorry, I've used it for a private project, you can email me if you need it. And leave your GitHub name so I can add you as a collaborator to download code. 
please see there is banchmark test in this 1bec3a67b commit
can you provide an opinion on the way I've added errors in/around the dril-down error code? I'm not super happy with the way it works.
I've incorporated a variant of your xhr.post suggestion into #813. I'd like to punt on automatic encoding, so I think that about wraps everything up. Let me know if you have any more suggestions! And thank you!
 thank you for the comments!  Regarding moving the package, it would actually be quite simple to move it and maintain backward compatibility, so I think it's something we should seriously consider. I agree with   that having it under the vo namespace is actually misleading since it can be used without any actual VO infrastructure. I quite like astropy.samp...
Description Adds a new XRButton class which creates a  or a  session depending on availability. This allows making projects that run in passthrough headsets and also on vr headsets. Side note: I wonder if it was a mistake to call  to the session that mobile phones support. Maybe it should have been called ? /cc    
Yes, I ran  linked to local build. The  also contains SVG elements.   Is reading from a file which includes indentation only for repro or for your actual use case? Output from  plugin doesn‚Äôt look so good after it formats text nodes for white space.   Also for your info, something that had nothing to do with problem: when I checked the  element with W3C validator, it reported 8 occurrences of unescaped  in attributes.  
I have reverted this pull request using a force push to the 3.0 branch. Unfortunately, GitHub doesn't appear to let me reopen the pull request, but you should be able to send a new one along when your fix is ready.
I ran it from the Docker image directly. Here was the message: This was my fault. I removed it in this PR though am not sure where it's being used. Investigate later when not so tired. In the meantime, I pushed up a fix to master directly am now redeploying the site.
my mistake how do I pull three.js back into my fork?
Hey , it's great to see you pop up here. I agree it sucks when you pre compile your code that you couldn't use snapshots because those artifacts in a build folder would be ignored. I think your solution here is reasonable but I'm still hesitant and would like things to be less configurable rather than more. One of the problems is that all the tooling that we are building (for example Nuclide integration for Jest that can preview snapshots) will have to know about these configuration options. Can you walk me through how the reason compiler works? Is there any conceivable way that Reason could be just another transformer similar to babel-jest? That way snapshot files could simply be next to your  files. cc  To , the reason you are forced to use this is because that is the convention I decided on. I don't get paid to make things customizable because for some subjective reason you find double underscores ugly. If you would like to change this, I suggest you send a PR instead of continuing to whine about it here and in the other issue. Thank you.
Didn't search before sending that PR, my bad. It's a duplicate of #23330
PR Summary Adds the Gadfly plot theme that I wrote a blog post about a couple of years ago PR Checklist <!-- Please mark any checkboxes that do not apply to this PR as [N/A]. -- - [ ] Has pytest style unit tests (and  passes). N/A - [ ] Is Flake 8 compliant (run  on changed files to check). N/A - [ ] New features are documented, with examples if plot related. N/A - [ ] Documentation is sphinx and numpydoc compliant (the docs should [build] () without error). N/A - [ ] Conforms to Matplotlib style conventions (install  and run ). N/A - [x] New features have an entry in  (follow instructions in README.rst there). - [ ] API changes documented in  (follow instructions in README.rst there). N/A <!-- Thank you so much for your PR!  To help us review your contribution, please consider the following points:   A development guide is available at .   Help with git and github is available at   .   Do not create the PR out of master, but out of a separate branch.   The PR title should summarize the changes, for example "Raise ValueError on   non-numeric input to set_xlim".  Avoid non-descriptive titles such as   "Addresses issue #8576".   The summary should provide at least 1-2 sentences describing the pull request   in detail (Why is this change required?  What problem does it solve?) and   link to any relevant issues.   If you are contributing fixes to docstrings, please pay attention to   .  In particular,   note the difference between using single backquotes, double backquotes, and   asterisks in the markup.   We understand that PRs can sometimes be overwhelming, especially as the reviews start coming in.  Please let us know if the reviews are unclear or the recommended next step seems overly demanding, if you would like help in addressing a reviewer's comments, or if you have been waiting too long to hear back on your PR. --
Nice! :sparkles: I'll play with it in a bit, but the including the numbers in the array makes it even easier to use :)
Shall you guys take a look?    
I think it's only if the branches are merged in via a pull request? Not 100% sure.
OK, I will continue working on it.
No, actually they look identical to me.
This is really confusing‚Ä¶ tests are passing on my m1 (including the skipped ones), yet the ones in CI are failing left and right
/rebuild_failed
No...
Thanks, ! Looks like we already account for this in the 5.0 alpha, but we'll get this fix into the 4.x line as part of the upcoming 4.14 release.
The bug and fix were reported upstream. I will merge this patch meanwhile so we can proceed with the   PR. 
Sorry, I've no deep knowledge about regular expressions in particular and about the formatters in general.
Hmm, OK.
k
Not forgotten at all. Just I've been working on pydantic-core in preparation for pydantic V2. I promise to review this once I get working on pydantic v1.10.
Sorry for the delay, I spent a lot of time in  and finally all of the errors and requirements has fulfilled,   , Please feel free to review.
nice job with all the tests btw!
it's not slow :p pushing something to the client immediately will probably always be a factor but not the entire thing, if the initial content is small there's not much benefit in streaming it. with http 2.0 push-based stuff it mitigates the need for that as well
Awesome, thank you ! :bow: :cake:  And thanks for the reviews -coders and  :tada: 
I do agree that these changes keep confusing users. I could go either way on whether the reloader is controlled by  or .
I am not fixing the streaming tests as streaming support is already being phased out and will eventually be unsupported iirc. The stream fails occur often anyways because of server errors. Note that this PR  will hopefully fix the intermittent server errors that are one reason streaming tests fail sometimes. does this sound correct to you?
777
+1
Disclaimer:  The following is a cornercase, not a best practice.  I wouldn't encourage anyone to do this but the rest of the code seems to allow it so I suppose there's a case to be made for handling it here (for now... until/unless we make it an error elsewhere). The "name" parameter to add_hosts does not appear to be a true DNS name.  Instead it is a name that ansible uses to reference a host.  If the "name" does not also contain an ansible_ssh_hostname parameter than the name would have to be valid as an ip address or a DNS hostname.  This is the common case.  However, a cornercase exists when an inventory does specify an ansible_ssh_hostname.  In that case, the hostname does not have to be valid in DNS because ansible_ssh_hostname is used instead.  That means that the user could specify something like this: Stupid thing to do?  Yes.  Does someone out there want to do it?  Probably so.  We get some really weird bug reports sometimes.  How far should we go to support this silly cornercase?  I'm not sure I'd go too far but I do think it would be good for the code to do a little bit more checking to prevent someone doing that from masquerading as valid ipv6 addresses.  So for instance, if someone passes in "[one:two]:90" we shouldn't parse that into "one:two", 90.  We should either return "[one:two]:90", None  or "[one:two]", 90 (I lean slightly towards the former to give the user flexibility). So maybe enhance the regex to search for four sets of  in order to decide that the value is an ipv6 address. Does that make sense?
Yea I think this is a little arbitrary. From the linked issue I get the problem we are trying to solve is that the headers aren't visible while scrolling through. Wouldn't it be possible to just pin the headers then with appropriate CSS? cc  for insights
Sorry about that! Yes, I think we should keep this PR for the remaining changes.
I looked at my usual corpora [1] to see which strategy is best. I started by considering three options:  Exclude the whole comment for comments containing a / and no  or  tags. (Strategy 1 proposed by ) Exclude the whole comment for comments containing only ,  and perhaps a small set of associated tags. Exclude the whole comment for comments containing a (OR only) / if a newline separated the comment from the next element in the source. (Strategy 2 proposed by )  I found all comments containing  and dumped the list of tags from each comment. .ts files .ts files had almost 300 , about 250 single . The remaining typedefs were in 3 projects: - openfin and google-gax used ,  and  to explain the typedef further. - protobufjs used a -like variant of  that Typescript doesn't parse: this Also, notably, in protobufjs, the  are often immediately followed with a Typescript declaration for the same thing. I think the .d.ts files were generated from Closure . .js files .js files had more than 8000 , 7500 single . The remaining typedefs fell into 4 categories:  embellishments for documentation or structure like , , , , , , , , , . There was a lot of variety here. 'local' typedefs that were immediately used with a  and  tag (the typedefs are not actually local to the declaration) -variants like the protobuf example above, which also used  and  tags. (and , once or twice)  6 projects use the unsupported callback-like typedefs compared to 3 projects that use local typedefs. Additionally, I observed plenty of unassociated  comments that were not separated by a newline from the next element, though the median next element was another comment. Analysis The best rule for excluding typedefs in quickinfo is (1). Except for local typedefs, all typedef-containing comments that I saw were exclusively about that typedef. And, although both local typedefs and callback-like typedefs are rare, it's better to show a few callback-like typedefs than to hide local typedefs that were intentionally defined in-place. (2) won't work well because there it's too hard to capture the set of associated tags -- we would end up showing any unforeseen variants needlessly. And the data show that (3) is both unnecessary and ineffective. In the future, if we decide to support callback-like typedefs, then (1) would stop incorrectly showing the callback-like typedefs. The code to implement this wouldn't be large, although I think there isn't much demand. [1] A full install of Definitely Typed, using /dtslint-runner to  every package inside , then . The same for the user tests in the TS repo.
CC:   
<!-- First of all, thank you for your contribution! üòÑ For requesting to pull a new feature or bugfix, please send it from a feature/bugfix branch based on the  branch. Before submitting your pull request, please make sure the checklist below is confirmed. Your pull requests will be merged after one of the collaborators approve. Thank you! -- [‰∏≠ÊñáÁâàÊ®°Êùø / Chinese template] ü§î This is a ...  [ ] New feature [ ] Bug fix [ ] Site / documentation update [ ] Demo update [ ] Component style update [ ] TypeScript definition update [ ] Bundle size optimization [ ] Performance optimization [ ] Enhancement feature [ ] Internationalization [x] Refactoring [ ] Code style optimization [ ] Test Case [ ] Branch merge [ ] Other (about what?)  üîó Related issue link <!-- 1. Put the related issue or discussion links here. -- üí° Background and solution <!-- 1. Describe the problem and the scenario. 2. GIF or snapshot should be provided if includes UI/interactive modification. 3. How to fix the problem, and list the final API implementation and usage sample if that is a new feature. -- üìù Changelog <!-- Describe changes from the user side, and list all potential break changes or other risks.  | Language   | Changelog | | ---------- | --------- | | üá∫üá∏ English | refactor: CC =| üá®üá≥ Chinese | refactor: CC = ‚òëÔ∏è Self-Check before Merge ‚ö†Ô∏è Please check all items below before requesting a reviewing. ‚ö†Ô∏è  [x] Doc is updated/provided or not needed [x] Demo is updated/provided or not needed [x] TypeScript definition is updated/provided or not needed [x] Changelog is provided or not needed 
/cc 
yes, sorry, I have the tested fix now. Thanks for the pointers. PR in #4226 
<!-- First of all, thank you for your contribution! üòÑ For requesting to pull a new feature or bugfix, please send it from a feature/bugfix branch based on the  branch. Before submitting your pull request, please make sure the checklist below is confirmed. Your pull requests will be merged after one of the collaborators approve. Thank you! -- [‰∏≠ÊñáÁâàÊ®°Êùø / Chinese template] ü§î This is a ...  [X] New feature [ ] Bug fix [ ] Site / documentation update [ ] Demo update [ ] Component style update [ ] TypeScript definition update [ ] Bundle size optimization [ ] Performance optimization [ ] Enhancement feature [ ] Internationalization [ ] Refactoring [ ] Code style optimization [ ] Test Case [ ] Branch merge [ ] Workflow [ ] Other (about what?)  üîó Related issue link  close #43495  <!-- 1. Put the related issue or discussion links here. 2. close #xxxx or fix #xxxx for instance. -- üí° Background and solution <!-- 1. Describe the problem and the scenario. 2. GIF or snapshot should be provided if includes UI/interactive modification. 3. How to fix the problem, and list the final API implementation and usage sample if that is a new feature. -- üìù Changelog <!-- Describe changes from the user side, and list all potential break changes or other risks.  | Language   | Changelog | | ---------- | --------- | | üá∫üá∏ English | TreeSelect support customize clear button | | üá®üá≥ Chinese | Ê†ëÈÄâÊã©ÁªÑ‰ª∂ÊîØÊåÅËá™ÂÆö‰πâÊ∏ÖÈô§ÊåâÈíÆ  | ‚òëÔ∏è Self-Check before Merge ‚ö†Ô∏è Please check all items below before requesting a reviewing. ‚ö†Ô∏è  [X] Doc is updated/provided or not needed [X] Demo is updated/provided or not needed [X] TypeScript definition is updated/provided or not needed [X] Changelog is provided or not needed   <!-- Below are template for copilot to generate CR message. Please DO NOT modify it. -- üöÄ Summary <!-- copilot:summary --### <samp Enhanced the  property of the  component to support custom clear icons. Updated the English and Chinese documentation files  and  accordingly. üîç Walkthrough <!-- copilot:walkthrough --### <samp * Enhance  property of  component to accept object type with  property for customizing clear icon (link, link)
Thanks! I just updated the docs set up, so now there's no need to keep updating these  files üéâ  Given that, I'll close this one, but thanks for the help! ‚òï 
I don't like this change. On OS X,  returns  The idea of using /tmp is to make it easy to find.
Merging bc I need it :D
Maybe you can create a PR which target my branch  with your unit test ? ‚ò∫Ô∏è
-bot perf test
Actually, i'm having second thoughts about this.  Will explain later.
here is how it looks: , it takes space from the error message, and the information it provides is not useful, specially that we do not have any online documentation to pack these codes.
This fixes the failing test I brought up here. 4dfe7a4 removed the  param from  in favor of calling  in the method. The test wasn't updated though, so the request param is being assigned to  which should be a boolean. This is causing the  test to fail. Edit: Sorry, I overlooked that this was addressed in 4dfe7a4 but accidentally reverted in 18b26d2.
Hi , Could you please explain what problem are you going to fix with this patch? With  the  would be  for example  and the `MYPY_VERSION_TUPLE 
Hi -Rath it looks like you and one other member were lost in the shuffle adding triagers when the process was in flux and changed hands. If you are still interested in being added, please ping me and I'll get you added ASAP,. Appologies.
Doing s in s does not feel right.  Just to note why the only situation we do that now in  is for when  is a  (like , , ...) and the reason for that is to allow for expressions like: (for the case when  is not yet defined, so it is effectively ) In the above example  is not called, only  is called on  and  is stored into whatever  returned. So if we just return , a new  would be created and  would be stored into the  key. But the problem is that the new dict would be lost since it isn't stored on the . So we also need to do  in the . This program demonstrates the above: a patch for  to see which methods are called: and the output:
Likely a mistake, especially with no response. Welcome!
The docs show the folder  as the folder to find user defined style sheets but the result from: indicates that the folder should be: () This PR just fix this in the docs () I followed the process of the docs to make this PR but it is the first time so if there is somethiing wrong, please, let me know. If I am wrong about the PR just discard it and sorry for the noise.
We wouldn't be having 16 processes because haste processes execute and finish before test execution. So it's 8 + 8 serially, which is fine.
Ah okay, thanks! I couldn't really interpret the CI error :sweat_smile:  I think we intend to drop it in the next major after the EOL as well, so that should be fine. cc  
Hi , any update on this?  No pressure, just I would love to get it merged. If you don't have time I'm very happy to take it over but of course it's yours if you want to work on it.
It's my fault, not the bot's. I got behind reviewing community PRs.  The bot doesn't check source issues for updates yet, although I plan to improve it at some point.
*Note that the first commit in this branch is to alpha-sort the exports for entry points to make it easier to compare between them when reviewing which file exports which APIs. The following APIs have been added to the  stable entry point: *  *  *  *  *  *  The following APIs have been added or removed from the  stable entry point: *  *  (removed) The following APIs have been added to the  stable entry point: *  *  The following feature flags have been changed from experimental to true: *  *  *  Todo  [x] Update tests once artifacts are built 
Pardon my ignorance but what's the benefit of this?  Before: Swagger can infer that the response is going to be . I only have to specify what type of response it is once.  After Now Swagger defaults to thinking it's  and I have to type  twice.  Yes, I'm a still a FastAPI newbie but I use it in a production project and was intrigued to see if this is something I should change to.
ok merged #9415  I just wanted you to be familiar with the perf testing.... try  (it should just be somewhat stable), e.g. a rerun of this should be roughy the same. you can use  to make the runs shorter (this is a regex to select on the name of the benchmarks'. note there are very few period specific benchmarks. adding more of these would be good.
Fixes #5485  Changed the query parameter  (which is deprecated) to . <!-- describe the changes you have made here: what, why, ...       Link issues by using the following pattern: #333 or koppor#49.      The title of the PR must not reference an issue, because GitHub does not support autolinking there. --   [ ] Change in CHANGELOG.md described [ ] Tests created for changes [ ] Manually tested changed features in running JabRef [ ] Screenshots added in PR description (for bigger UI changes) [ ] Ensured that the git commit message is a good one [ ] Check documentation status (Issue created for outdated help page at help.jabref.org?) 
From previous PR we have submitted there is no automatic merge. An Ansible maintainer will have to merge it. On my part what I can do is to use the following ansibullbot command to approve. Let's try all 3 forms: LGTM +1 shipit
looks like it would work, but reproducing the error is a pain. I don't yet know why it only failed on travis on certain python versions. Does some package need to be importable for it to get to this code? What special conditions are required? I don't like magic importing and monkeypatching code in utility libraries, especially when it makes me chase phantom bugs like this. (I'm not even using SSL let alone SNI!) Maybe I can reproduce by referencing this commit id in my install_requires and poking travis.
SUMMARY Add AWS Direct Connect virtual interface module and fix the DirectConnectError exception wrapper to be compatible with fail_json_aws() so AnsibleAWSModule can be used. ISSUE TYPE  Feature Pull Request  COMPONENT NAME lib/ansible/modules/cloud/amazon/aws_direct_connect_virtual_interface.py ANSIBLE VERSION
I like this, it's cool for simple metrics (needed something like this sometime ago). But wouldn't be better to put the result in the returned  object? That way we can use it like the code below and keep track of the request time for every request made. Also,  is the best name for this? Property vs method? (I'm not familiar with requests internal code standards). :+1: 
Sorry forget to answer. With azure you can track whatever events you are interested in. So if this information is really valuable to you, you can add an event for "recommendations tab opened" and one for "recommendations shown". That should give you a valid basis to gauge whether the recommendation creation takes too much time.
The only place where I've left non-updated xfail tests is in , which I'm not quite sure what we're going to do with yet, but clearly it's going to get an overhaul. I was able to fix at least a handful of tests along the way here. There was one place where I changed an error message to make things a little more clear, in a way that I felt was good enough to change a test from xfailing to passing. (I'll point this out below.) Selected Reviewer: 
For non published things, we ask for install and feedback by providing instructions to install from a branch in the repo. We can merge this into a http2 branch and tell folks to npm install expressjs/express#http2 as well.
Just run  to update snapshot referred to 
What happens if you change  to ? It looks like when loading json it doesn't stick it into the registry cache (since it returns before line 884), so maybe it's loading the same json twice, and therefore we're getting two different objects.
You can preview 02fd3f5 at .
Can you show me what is test renderer using from ?
Could you write a short personal email so that I have your contact data?
Backport PR #14057: Improve Gradient bar example
-bot pack this
651
Currently we have a common utility method for running commands in a child process. This method pipes all stdout and stderr, but sets the  to . This seemed to work as expected in terms of allowing interactive commands being executed, but it messes with the TTY in Windows (and potentially other platforms) so that colors and prompts no longer work properly. It's unclear how this causes the TTY to no longer support colors; but I guess it's the mix of inherit and pipe. See attached screenshot.  We fix this by not inheriting the stdin by default; but exposing a dedicated method for interactive commands. This results in more readable and obvious code too, so it's worth making this change regardless of the TTY issues.
I cleaned up the loader after your first PR. Do you mind updating first? Sorry about that...
<!-- Please make sure to read the Pull Request Guidelines: -- <!-- PULL REQUEST TEMPLATE --<!-- (Update "[ ]" to "[x]" to check a box) -- What kind of change does this PR introduce? (check at least one)  [x] Bugfix [ ] Feature [ ] Code style update [ ] Refactor [ ] Build-related changes [ ] Other, please describe:  Does this PR introduce a breaking change? (check one)  [x] Yes [ ] No  If yes, please describe the impact and migration path for existing applications: The PR fulfills these requirements:  [x] It's submitted to the  branch for v2.x (or to a previous version branch), not the  branch [ ] When resolving a specific issue, it's referenced in the PR's title (e.g. , where "xxx" is the issue number) [x] All tests are passing:  [ ] New/updated tests are included  If adding a new feature, the PR's description includes: - [x] A convincing reason for adding this feature (to avoid wasting your time, it's best to open a suggestion issue first and wait for approval before working on it) Other information:
 Renamed Gauss -- In , changed xsigma, xcen -- In , changed xsigma, ysigma -- In all files, made any abbreviation for 'parameters' = 'param': psets -  - paramdim -  - parnames -- In , removed the 'ratio' parameter -- too many ways to specify the same thing. Is this really necessary? In , added x_fwhm and y_fwhm to be consistent...but I would be in favor of removing the fwhm option entirely from both models and just requiring the standard deviation. Added a 'cov_matrix' option to , but this is kind of klugy...I think the more general way to think about Gaussians is as a quadratic form -- it naturally generalizes to many dimensions -- so I think the definition in  should change. But then there's the issue of how to treat the covariance matrix as a  (see notes below).  Notes:  When I added the cov_matrix option I realized that there is room here for a single  object that accepts a scalar or vector , and either  or .  could be a scalar or vector, in which case the Gaussian is assumed to be aligned with the coordinates, e.g. sqrt of each value along the diagonal of the covariance matrix. This would be a good way to support N-dimensional Gaussians. I started implementing the above, but got stuck on some weirdness that was going on with the  class. I made the covariance matrix 2-dimensional, but it ends up becoming a list of arrays, so::  array([[0.2,0.],          [0.,0.3]]) becomes when I define it as a ...Then the fitting all fails because obviously you can't treat the cov. matrix like other parameters when feeding in to a NL fitting algorithm. We should think about this a bit more...
Should probably adjust the forward projection so it respects the same extents as the inverse. It might be nice to stream points to each sub-projection and use clipExtent when have support for it, so projecting the whole world and graticule will just work (although of course separate graticules are probably advisable due to differences in scale).
Finish #6622. Generate the binding params of the event handler. Only effect the Weex platform within the  component.
imo you shouldn't even use  if you're not sending a body. just do .
Thank you for answering. My use-case: The  part is the key -- I want to make sure each BaseEvent's subclass won't be instantiated with an incorrect EventType (I only need to remember to include the  on each subclass). I tried different combinations of ,  and . I tried multiple other approaches, including using Pydantic's validators. In each case, something came up that made the whole thing incorrect, broken, or badly designed (e.g. mypy was complaining, there was a runtime issue, it was incompatible with pydantic, or the code was not DRY, etc.). When I saw this PR I thought something like this might be the solution: Another thing is aliasing it --  field won't work in Pydantic, as I've mentioned above.
 ,  and their large counterparts' animation timing change and  checkbox/radio position fix payment card icons added as components 
Yeah, but that's really just for validation: it covers the set of rules that already exist (as well as the legacy rules from scikits.timeseries, etc). (since you only end up with #s in the string for WOM) If we wanted to add some crazy additional rule_code, you'd change the regex to make it pass the validation.
Why are there now two proposed fixes for this that use practically twice as much computing power as they need to? The sqrt function is not addition or modulo, it's trigonometry that only needs to be analyzed once. It's puzzling that the js community is so prone to sloppy code given the exposure to low powered devices; each Joule matters, you know, and laziness here will hard-wire crappy responsiveness in the library. Please take the time to rewrite your fix Jason, the way I did it was not that much different from yours. Best -dru On Jun 7, 2013 2:12 PM, "Jason Davies"  wrote:
Someone please correct me if I'm wrong here but I think... 1) yes 2) I'm not sure ...in the code there is a comment  // NOTE (not in spec): assignment to enum members should not be allowed which originally made me think it wasn't explicitly in the spec but in section 3.8.4 Assignment Compatibility one of the conditions for assignment compatibility is S or T is an enum type and the other is the primitive type Number. which makes me think this behavior is actually allowed but I'm curious if that was intentional or if the actual intent was to only allow assigning to an Enum type within an Enum declaration? 
Hmm, looks like r737027 corresponds to version 81.0.4044.0. I guess that was a typo. I'll amend the commit message.
<!-- First of all, thank you for your contribution! üòÑ For requesting to pull a new feature or bugfix, please send it from a feature/bugfix branch based on the  branch. Before submitting your pull request, please make sure the checklist below is confirmed. Your pull requests will be merged after one of the collaborators approve. Thank you! -- [‰∏≠ÊñáÁâàÊ®°Êùø / Chinese template] ü§î This is a ...  [ ] New feature [ ] Bug fix [ ] Site / documentation update [ ] Demo update [ ] Component style update [ ] TypeScript definition update [ ] Bundle size optimization [ ] Performance optimization [ ] Enhancement feature [ ] Internationalization [ ] Refactoring [ ] Code style optimization [ ] Test Case [ ] Branch merge [ ] Workflow [ ] Other (about what?)  üîó Related issue link <!-- 1. Put the related issue or discussion links here. 2. close #xxxx or fix #xxxx for instance. -- üí° Background and solution <!-- 1. Describe the problem and the scenario. 2. GIF or snapshot should be provided if includes UI/interactive modification. 3. How to fix the problem, and list the final API implementation and usage sample if that is a new feature. -- üìù Changelog <!-- Describe changes from the user side, and list all potential break changes or other risks.  | Language   | Changelog | | ---------- | --------- | | üá∫üá∏ English |      -     | | üá®üá≥ Chinese |  -         | ‚òëÔ∏è Self-Check before Merge ‚ö†Ô∏è Please check all items below before requesting a reviewing. ‚ö†Ô∏è  [ ] Doc is updated/provided or not needed [ ] Demo is updated/provided or not needed [ ] TypeScript definition is updated/provided or not needed [ ] Changelog is provided or not needed   <!-- Below are template for copilot to generate CR message. Please DO NOT modify it. -- üöÄ Summary <!-- copilot:summary --### <samp Improved the site-deploy workflow to support manual triggers and ignore non-relevant tags. Fixed a bug that caused the workflow to fail on manual triggers. üîç Walkthrough <!-- copilot:walkthrough --### <samp * Change the workflow trigger to allow manual deployment and limit automatic deployment to  tags (link) * Fix the condition for the  job to use the correct variables for both  and  events (link)
there was a typo in the comment, also made a sentence out of it.
Fixed some typos. Added the ghost button type. Made the 'type' column of the API table a little more consistent, with strings represented with code tags. I don't know where the interactive examples are located, but the ghost type needs to be added to the part about button types. Also, there are some minor typos in the examples. Note, the ghost type is different from the ghost prop which inverts button colors.
Altering  imports isn't making any difference for me. For some reason the log for  seems to always include importing , even though there's no visible "import inspect..": Logs: see the  branch for what I changed.  ~~Update: This is very weird, but it doesn't seem to happen when compiled with cython, so add the  changes here.~~ ignore that, it was a mistake.